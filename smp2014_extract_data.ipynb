{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPgcv8LtMzHALc1pcteKEBE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lizaoh/smp_program_data/blob/main/smp2014_extract_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Top of Script"
      ],
      "metadata": {
        "id": "KBXc6uieLC6Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DW0MLlXyhw5G",
        "outputId": "d3a64ac6-4ff4-4638-c4e4-fd2abc26b460"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymupdf\n",
        "!pip install pymupdf-layout\n",
        "!pip install pymupdf4llm\n",
        "!pip install wordfreq\n",
        "# !pip install rapidfuzz\n",
        "import glob\n",
        "import os\n",
        "import pathlib\n",
        "import pymupdf\n",
        "import pymupdf.layout\n",
        "import pymupdf4llm\n",
        "import re\n",
        "import pandas as pd\n",
        "import unicodedata\n",
        "import wordfreq\n",
        "# from rapidfuzz import process, fuzz"
      ],
      "metadata": {
        "id": "iwaO2sqpib2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a931de55-a2c5-4c91-cb23-99088b0c7b22"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymupdf\n",
            "  Downloading pymupdf-1.26.7-cp310-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
            "Downloading pymupdf-1.26.7-cp310-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m123.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymupdf\n",
            "Successfully installed pymupdf-1.26.7\n",
            "Collecting pymupdf-layout\n",
            "  Downloading pymupdf_layout-1.26.6-cp310-abi3-manylinux_2_28_x86_64.whl.metadata (2.8 kB)\n",
            "Collecting PyMuPDF==1.26.6 (from pymupdf-layout)\n",
            "  Downloading pymupdf-1.26.6-cp310-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from pymupdf-layout) (6.0.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from pymupdf-layout) (2.0.2)\n",
            "Collecting onnxruntime (from pymupdf-layout)\n",
            "  Downloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from pymupdf-layout) (3.6.1)\n",
            "Collecting coloredlogs (from onnxruntime->pymupdf-layout)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime->pymupdf-layout) (25.9.23)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from onnxruntime->pymupdf-layout) (25.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime->pymupdf-layout) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime->pymupdf-layout) (1.14.0)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime->pymupdf-layout)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime->pymupdf-layout) (1.3.0)\n",
            "Downloading pymupdf_layout-1.26.6-cp310-abi3-manylinux_2_28_x86_64.whl (12.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m134.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pymupdf-1.26.6-cp310-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m128.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m147.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDF, humanfriendly, coloredlogs, onnxruntime, pymupdf-layout\n",
            "  Attempting uninstall: PyMuPDF\n",
            "    Found existing installation: PyMuPDF 1.26.7\n",
            "    Uninstalling PyMuPDF-1.26.7:\n",
            "      Successfully uninstalled PyMuPDF-1.26.7\n",
            "Successfully installed PyMuPDF-1.26.6 coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.23.2 pymupdf-layout-1.26.6\n",
            "Collecting pymupdf4llm\n",
            "  Downloading pymupdf4llm-0.2.8-py3-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: pymupdf>=1.26.6 in /usr/local/lib/python3.12/dist-packages (from pymupdf4llm) (1.26.6)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (from pymupdf4llm) (0.9.0)\n",
            "Downloading pymupdf4llm-0.2.8-py3-none-any.whl (68 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.6/68.6 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymupdf4llm\n",
            "Successfully installed pymupdf4llm-0.2.8\n",
            "Collecting wordfreq\n",
            "  Downloading wordfreq-3.1.1-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ftfy>=6.1 (from wordfreq)\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting langcodes>=3.0 (from wordfreq)\n",
            "  Downloading langcodes-3.5.1-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting locate<2.0.0,>=1.1.1 (from wordfreq)\n",
            "  Downloading locate-1.1.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.7 in /usr/local/lib/python3.12/dist-packages (from wordfreq) (1.1.2)\n",
            "Requirement already satisfied: regex>=2023.10.3 in /usr/local/lib/python3.12/dist-packages (from wordfreq) (2025.11.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from ftfy>=6.1->wordfreq) (0.2.14)\n",
            "Downloading wordfreq-3.1.1-py3-none-any.whl (56.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 MB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langcodes-3.5.1-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.1/183.1 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading locate-1.1.1-py3-none-any.whl (5.4 kB)\n",
            "Installing collected packages: locate, langcodes, ftfy, wordfreq\n",
            "Successfully installed ftfy-6.3.1 langcodes-3.5.1 locate-1.1.1 wordfreq-3.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pdfs_path = '/content/drive/MyDrive/math_psych_work/Conference Programs/'"
      ],
      "metadata": {
        "id": "9TqNj0OYhzgb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions\n",
        "Created with help from GPT 5.2, but some are my own code just turned into a function."
      ],
      "metadata": {
        "id": "cK6Itu79JGuf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "AFFILIATION_KEYWORDS = [\n",
        "    \"University\", \"College\", \"Department\", \"Center\", \"Institute\",\n",
        "    \"Laboratory\", \"School\", \"Hospital\", \"UC\", \"Centre\", \"Research\",\n",
        "    \"Corporation\", \"Defence\", \"Université\", \"Universite\", \"Universiy\",\n",
        "    \"Universidad\", \"Univeristy\", \"KU\", \"Irvine\", \"Canada\", \"Universität\"\n",
        "]\n",
        "\n",
        "AFF_SPLIT_RE = re.compile(\n",
        "    r'_(?P<aff>.*?)_(?=\\s(?!,))',\n",
        "    re.DOTALL\n",
        ")\n",
        "\n",
        "def split_after_last_affiliation(text: str):\n",
        "    last_match = None\n",
        "\n",
        "    for m in AFF_SPLIT_RE.finditer(text):\n",
        "        aff = m.group(\"aff\")\n",
        "        if any(k in aff for k in AFFILIATION_KEYWORDS):\n",
        "            last_match = m\n",
        "\n",
        "    if last_match:\n",
        "        split_idx = last_match.end()\n",
        "        info = text[:split_idx].strip()\n",
        "        abstract = text[split_idx:].strip()\n",
        "        return info, abstract\n",
        "\n",
        "    return None, text.strip()"
      ],
      "metadata": {
        "id": "t0fWgJSqXKPJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_whitespace(s: str) -> str:\n",
        "    return \" \".join(s.replace(\"\\n\", \"\").split())"
      ],
      "metadata": {
        "id": "W6PGuwc6e3jZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_affiliations(entry: str) -> str:\n",
        "    return re.sub(\n",
        "        r'(University of California)\\s*,?\\s*'\n",
        "        r'(Irvine|Davis|Berkeley|Los Angeles|San Diego|Santa Barbara|Santa Cruz|Riverside|Merced)',\n",
        "        r'\\1, \\2',\n",
        "        entry\n",
        "    )"
      ],
      "metadata": {
        "id": "ilIOFaZ8ArV9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LOCATIONS = [\n",
        "    'United States of America', 'Switzerland', 'Japan', 'Bremen',\n",
        "    'Berlin, Germany', 'Germany', 'Berlin', 'Norway', 'Turkey',\n",
        "    'Belgium', 'Italy', 'Israel', 'New Brunswick, New Jersey',\n",
        "    'Australia', 'The Netherlands', 'USA', 'Netherlands, The', 'Netherlands',\n",
        "    'United Kingdom', 'Singapore', 'France', 'Dayton OH', 'Dayton',\n",
        "    'Taiwan, Republic of China', 'Austria', 'Canada',\n",
        "    'Edmonton', 'Bloomington, Indiana', 'Indiana', 'Russian Federation',\n",
        "    'University Park, Pennsylvania', 'California', 'San Francisco, California',\n",
        "    'Taipei, Taiwan', 'Charlottesville, Virginia', 'New York, New York',\n",
        "    'Toronto, Ontario', 'New Haven, Connecticut', 'Ann Arbor, Michigan', 'Ohio',\n",
        "    'Ottawa, Ontario', 'Houston, Texas', 'UK', 'New Brunswick, Piscataway, NJ'\n",
        "]\n",
        "\n",
        "# compile once\n",
        "LOCATION_RE = re.compile(\n",
        "    r',\\s*(?:' + '|'.join(map(re.escape, LOCATIONS)) + r')\\b',\n",
        "    re.I\n",
        ")\n",
        "\n",
        "def remove_locations(entry: str) -> str:\n",
        "    return LOCATION_RE.sub('', entry).strip()"
      ],
      "metadata": {
        "id": "lvG2RkeJsiPV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_authors_affiliations(entry: str) -> tuple[str, str]:\n",
        "    entry = normalize_whitespace(entry)\n",
        "    entry = normalize_affiliations(entry)\n",
        "\n",
        "    # split only on commas WITH SPACES\n",
        "    tokens = re.split(r'\\s+,\\s+(?=[A-Z])', entry)\n",
        "\n",
        "    authors = []\n",
        "    affiliations = []\n",
        "\n",
        "    for token in tokens:\n",
        "        token = token.strip()\n",
        "\n",
        "        # if token is one word and we already have an affiliation then attach\n",
        "        if len(token.split()) == 1 and affiliations and token[0].isupper():\n",
        "            affiliations[-1] = affiliations[-1] + \", \" + token\n",
        "            continue\n",
        "\n",
        "        if looks_like_affiliation(token):\n",
        "            affiliations.append(token)\n",
        "        else:\n",
        "            authors.append(token)\n",
        "\n",
        "    if len(set(affiliations)) == 1:\n",
        "        affiliations = affiliations[0]\n",
        "    else:\n",
        "      affiliations = \"; \".join(affiliations)\n",
        "\n",
        "    return (\n",
        "        \", \".join(authors),\n",
        "        affiliations\n",
        "    )"
      ],
      "metadata": {
        "id": "1DuX4taa_qAo"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_trailing_text(text):\n",
        "  no_trailing_junk = entry.split(\".\")[:-1]\n",
        "\n",
        "  return \".\".join(no_trailing_junk)"
      ],
      "metadata": {
        "id": "-SNzmnUOw5td"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text, words_to_hyphenate=None):\n",
        "    if not text:\n",
        "        return text\n",
        "\n",
        "    if words_to_hyphenate:\n",
        "        for word, hyphenated_word in words_to_hyphenate:\n",
        "            text = text.replace(word, hyphenated_word)\n",
        "\n",
        "    text = re.sub(r' \\n\\n\\d{1,3} \\n\\n', ' ', text)  # Remove page breaks with page number\n",
        "    text = re.sub(r'\\s*\\n\\s*', ' ', text)    # Replace newlines with spaces\n",
        "\n",
        "\n",
        "    text = re.sub(r'-\\s+(?!\\b(?:and|or)\\b)', '', text)  # Get rid of - and space after\n",
        "                                                        # unless word after is\n",
        "                                                        # \"and\" or \"or\"\n",
        "\n",
        "    text = re.sub(r'\\s{2}', ' ', text)       # Collapse two adjacent spaces into one\n",
        "\n",
        "    text = re.sub(r'\\.\\s*##.*$', '.', text,\\\n",
        "                  flags=re.DOTALL)           # Gets rid of extraneous text after\n",
        "                                             # last sentence\n",
        "    text = text.strip()\n",
        "    text = fix_ligatures(text)\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "aq4f3JE9IgHD"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LIGATURE_MAP = {\n",
        "    \"ﬁ\": \"fi\",\n",
        "    \"ﬂ\": \"fl\",\n",
        "    \"ﬃ\": \"ffi\",\n",
        "    \"ﬄ\": \"ffl\",\n",
        "    \"ﬀ\": \"ff\",\n",
        "    \"ﬅ\": \"ft\",\n",
        "    \"ﬆ\": \"st\",\n",
        "    \"Æ\": \"ffi\",\n",
        "    \"¨u\": \"ü\",\n",
        "    \"¨a\": \"ä\",\n",
        "    \"´e\": \"é\",\n",
        "    \"`e\": \"è\",\n",
        "    \"`a\": \"à\",\n",
        "    \"¨o\": \"ö\",\n",
        "    \"˚a\": \"å\",\n",
        "    \"c¸\": \"ç\",\n",
        "    '“': '\"',\n",
        "    '”': '\"',\n",
        "    \"’\": \"'\",\n",
        "    '˜n': 'ñ',\n",
        "    'ˇs': 'š'\n",
        "}\n",
        "\n",
        "def fix_ligatures(text):\n",
        "    # Replace known ligatures\n",
        "    for bad, good in LIGATURE_MAP.items():\n",
        "        text = text.replace(bad, good)\n",
        "\n",
        "    # Replace any private-use ligature (common in PDFs)\n",
        "    cleaned_chars = []\n",
        "    for ch in text:\n",
        "        name = unicodedata.name(ch, \"\")\n",
        "        if \"LIGATURE\" in name.upper():\n",
        "            # Try to break it apart: remove spaces and lowercase\n",
        "            base = name.split(\"LIGATURE\")[-1]\n",
        "            base = base.replace(\" \", \"\").lower()\n",
        "            cleaned_chars.append(base)\n",
        "        else:\n",
        "            cleaned_chars.append(ch)\n",
        "\n",
        "    return \"\".join(cleaned_chars)"
      ],
      "metadata": {
        "id": "WLDsGBzsFnSz"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checks if valid word using Zipf frequency\n",
        "def is_probably_valid(word, threshold=2.5):\n",
        "    return wordfreq.zipf_frequency(word, \"en\") > threshold  # smaller number cuts off\n",
        "                                                            # more words, bigger is\n",
        "                                                            # more lenient"
      ],
      "metadata": {
        "id": "7DrUdRHGgTrp"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Program\n",
        "\n",
        "127 entries total (3 keynote talks, 2 plenary talks, 20 symposium talks, 70 talks, and 32 posters)\n",
        "\n",
        "Markdown shows bold and italic text here.\n"
      ],
      "metadata": {
        "id": "EzyoCbvJK6js"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Grab text from the pdf"
      ],
      "metadata": {
        "id": "NY0NZXAh696-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "year = '2014'\n",
        "program = pymupdf.open(pdfs_path + f'smp{year}_program.pdf')"
      ],
      "metadata": {
        "id": "-iaeTkOjqA3-"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "program_text = pymupdf4llm.to_markdown(program)"
      ],
      "metadata": {
        "id": "GB3Wc1MBHp8X"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "program_text[13_500:15_000]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "7-jva4kegu_-",
        "outputId": "75c96d03-ec05-4a02-cc05-33ce4114aad4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'s** \\n\\n**Saturday, 9:00** Palais Chair: Zigmunt Pizlo \\n\\n**Symmetry and the computational goals that underlie perception** Horace Barlow, _University of Cambridge, United Kingdom_ Although I am (or was) a neurophysiologist, I do not think records of impulse trains from neurons in perceptual systems can be interpreted properly until we answer the question ”What are the goals of the computations these systems and their neurons are performing?” This is simply because you cannot test whether a system does the job you think it may do unless you have ideas about what that job is. The proposition I like the sound of, and shall argue for here, is that the two main computations in early vision are cross-correlation of patches of the image with fixed templates, and auto-correlations of pairs of image patches related by some specified transformations. One definition of symmetry is ”invariance under transformation”, so is symmetry detection the main computational goal of early vision? This is the first point to be discussed, and I think it turns out that the answer is ”Yes”, but perhaps this applies only to some, not all, of the transformations you might wish to include in the definition of symmetry. The second question is ”How does detecting symmetry help?” Symmetries are forms of regularity or redundancy, and if you know about them you can make more reliable and \\n\\nsensitive predictions than if you don’t, and you will have potentially serious cognitive advantages over your competitors. Th'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split text into presentation entries"
      ],
      "metadata": {
        "id": "1QnRE7dQuaDC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_abstracts = program_text.split('**Abstracts For Keynote Talks**')[1] # this is where abstracts start\n",
        "split_abstracts = re.split(r'\\n\\n\\*\\*', all_abstracts)\n",
        "abstract_entries = ['**' + entry.strip() for entry in split_abstracts if len(entry) > 200][:-14]\n",
        "abstract_entries[-1] = abstract_entries[-1].split('\\n\\n77', 1)[0].strip()"
      ],
      "metadata": {
        "id": "0xNg5F-Vn1kF"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "abstract_entries[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWkxOy-_N2h_",
        "outputId": "e3a91b45-5e2d-4f41-88f2-83a99432faae"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['**Symmetry and the computational goals that underlie perception** Horace Barlow, _University of Cambridge, United Kingdom_ Although I am (or was) a neurophysiologist, I do not think records of impulse trains from neurons in perceptual systems can be interpreted properly until we answer the question ”What are the goals of the computations these systems and their neurons are performing?” This is simply because you cannot test whether a system does the job you think it may do unless you have ideas about what that job is. The proposition I like the sound of, and shall argue for here, is that the two main computations in early vision are cross-correlation of patches of the image with fixed templates, and auto-correlations of pairs of image patches related by some specified transformations. One definition of symmetry is ”invariance under transformation”, so is symmetry detection the main computational goal of early vision? This is the first point to be discussed, and I think it turns out that the answer is ”Yes”, but perhaps this applies only to some, not all, of the transformations you might wish to include in the definition of symmetry. The second question is ”How does detecting symmetry help?” Symmetries are forms of regularity or redundancy, and if you know about them you can make more reliable and \\n\\nsensitive predictions than if you don’t, and you will have potentially serious cognitive advantages over your competitors. There are some ancient observations on the way that damage to the visual cortex interferes with the orienting response that tend to support these views. It should be possible to allocate specific types of symmetry detection to specific cortical areas neurophysiologically, or possibly using fMRI. Some preliminary psychophysical experiments capable of measuring the absolute efficiencies for detecting non-random or non-independent positioning of dots in otherwise random arrays have already given encouraging preliminary results. I think the view that symmetry detection is the main new trick of the cerebral cortex deserves closer examination.',\n",
              " '**Reinforcement Learning and Psychology: A Personal Story** Richard S. Sutton, _University Of Alberta, Edmonton_ The modern field of reinforcement learning (RL) has a long, intertwined relationship with psychology. Almost all the powerful ideas of RL came originally from psychology, and today they are recognized as having significantly increased our ability to solve difficult engineering problems such as playing \\n\\n8 \\n\\nbackgammon, flying helicopters, and optimal placement of internet advertisements. Psychology should celebrate this and take credit for it! RL has also begun to give something back to the study of natural minds, as RL algorithms are providing insights into classical conditioning, the neuroscience of brain reward systems, and the role of mental replay in thought. I have been working in the field of RL for much of this journey, back and forth between nature and engineering, and have played a role in some of the key steps. In this talk I tell the story as it seemed to happen from my point of view, summarizing it in four things that I think every psychologist should know about RL: 1) that it is a formalization of learning by trial and error, with engineering uses, 2) that it is a formalization of the propagation of reward predictions which closely matches behavioral and neuroscience data, 3) that it is a formalization of thought as learning from replayed experience that again matches data from natural systems, and 4) that there is a beautiful confluence of psychology, neuroscience, and computational theory on common ideas and elegant algorithms. \\n\\n## **Monday, 11:30** Palais Chair: Mark Steyvers']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Find words to re-hyphenate"
      ],
      "metadata": {
        "id": "kLz8RAOqBM9Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pattern = re.compile(r'([A-Za-z]+)-\\n\\s*([A-Za-z]+)')\n",
        "possible_hyphenated_words = []\n",
        "\n",
        "counter = 0\n",
        "for p, page in enumerate(program[10:104]):  # these are the pages with abstracts only\n",
        "  text = fix_ligatures(page.get_text('text'))\n",
        "  matches = pattern.findall(text)\n",
        "\n",
        "  for left, right in matches:\n",
        "    word = f\"{left}{right}\"\n",
        "    hyphenated_word = f\"{left}-{right}\"\n",
        "    if not is_probably_valid(word, threshold=1.6):\n",
        "      possible_hyphenated_words.append([word, hyphenated_word])\n",
        "\n",
        "      print(f\"{counter:>3}: Page {p+7:<3} {hyphenated_word:<30} {word}\")\n",
        "      counter += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2D7shYjBMP8",
        "outputId": "e9e1e4f7-c47b-447d-b9aa-896a403db732"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  0: Page 8   neuro-physiologically          neurophysiologically\n",
            "  1: Page 9   hypochon-driacal               hypochondriacal\n",
            "  2: Page 14  human-made                     humanmade\n",
            "  3: Page 14  Smith-Kettlewell               SmithKettlewell\n",
            "  4: Page 15  group-theoretic                grouptheoretic\n",
            "  5: Page 15  one-dimensional                onedimensional\n",
            "  6: Page 15  out-there                      outthere\n",
            "  7: Page 16  multi-class                    multiclass\n",
            "  8: Page 16  skeleton-based                 skeletonbased\n",
            "  9: Page 19  Dzhafarov-Kujala               DzhafarovKujala\n",
            " 10: Page 19  Fischer-Hilbert                FischerHilbert\n",
            " 11: Page 19  Abramsky-Brandenburger         AbramskyBrandenburger\n",
            " 12: Page 19  by-default                     bydefault\n",
            " 13: Page 19  con-textuality                 contextuality\n",
            " 14: Page 20  Neuro-Engineering              NeuroEngineering\n",
            " 15: Page 20  post-iconic                    posticonic\n",
            " 16: Page 21  Breit-meyer                    Breitmeyer\n",
            " 17: Page 21  well-known                     wellknown\n",
            " 18: Page 21  same-different                 samedifferent\n",
            " 19: Page 21  same-different                 samedifferent\n",
            " 20: Page 21  same-different                 samedifferent\n",
            " 21: Page 21  fast-same                      fastsame\n",
            " 22: Page 22  functional-form                functionalform\n",
            " 23: Page 22  Ke-jkaew                       Kejkaew\n",
            " 24: Page 23  Discrete-State                 DiscreteState\n",
            " 25: Page 23  Continuous-strength            Continuousstrength\n",
            " 26: Page 24  two-stage                      twostage\n",
            " 27: Page 24  Nosof-sky                      Nosofsky\n",
            " 28: Page 26  in-tertrial                    intertrial\n",
            " 29: Page 26  parietal-occipital             parietaloccipital\n",
            " 30: Page 28  non-decision                   nondecision\n",
            " 31: Page 29  homo-logical                   homological\n",
            " 32: Page 30  actively-A                     activelyA\n",
            " 33: Page 30  Speeken-brink                  Speekenbrink\n",
            " 34: Page 32  Bidirectional-ity              Bidirectionality\n",
            " 35: Page 32  well-known                     wellknown\n",
            " 36: Page 33  bidi-rectionality              bidirectionality\n",
            " 37: Page 33  continuous-state               continuousstate\n",
            " 38: Page 34  Chia-Chien                     ChiaChien\n",
            " 39: Page 34  Pan-telis                      Pantelis\n",
            " 40: Page 34  moment-to                      momentto\n",
            " 41: Page 37  Univer-sit                     Universit\n",
            " 42: Page 38  Fal-magne                      Falmagne\n",
            " 43: Page 38  Vu-covich                      Vucovich\n",
            " 44: Page 38  neurocomputa-tional            neurocomputational\n",
            " 45: Page 39  macro-structure                macrostructure\n",
            " 46: Page 40  psychodi-agnostic              psychodiagnostic\n",
            " 47: Page 41  semi-partial                   semipartial\n",
            " 48: Page 42  non-equivalent                 nonequivalent\n",
            " 49: Page 42  the-crowd                      thecrowd\n",
            " 50: Page 42  Kr-uschke                      Kruschke\n",
            " 51: Page 42  Nosof-sky                      Nosofsky\n",
            " 52: Page 42  Reinforcement-Learning         ReinforcementLearning\n",
            " 53: Page 43  Bottom-up                      Bottomup\n",
            " 54: Page 43  non-social                     nonsocial\n",
            " 55: Page 44  Van-paemel                     Vanpaemel\n",
            " 56: Page 45  p-value                        pvalue\n",
            " 57: Page 45  ro-vide                        rovide\n",
            " 58: Page 46  Jas-trzembski                  Jastrzembski\n",
            " 59: Page 49  multi-attribute                multiattribute\n",
            " 60: Page 49  Ornstein-Uhlenbeck             OrnsteinUhlenbeck\n",
            " 61: Page 50  Ludwigs-Universit              LudwigsUniversit\n",
            " 62: Page 50  Ludwigs-Universit              LudwigsUniversit\n",
            " 63: Page 50  Nosof-sky                      Nosofsky\n",
            " 64: Page 52  noncom-pensatory               noncompensatory\n",
            " 65: Page 53  Wa-genmakers                   Wagenmakers\n",
            " 66: Page 53  closed-form                    closedform\n",
            " 67: Page 54  non-trivially                  nontrivially\n",
            " 68: Page 54  task-dependent                 taskdependent\n",
            " 69: Page 55  Instantiat-ing                 Instantiating\n",
            " 70: Page 56  Non-Stationary                 NonStationary\n",
            " 71: Page 56  non-stationary                 nonstationary\n",
            " 72: Page 56  non-stationary                 nonstationary\n",
            " 73: Page 57  Univer-sit                     Universit\n",
            " 74: Page 57  location-dispersion            locationdispersion\n",
            " 75: Page 58  heteroscedac-ticity            heteroscedacticity\n",
            " 76: Page 61  side-by                        sideby\n",
            " 77: Page 61  side-by                        sideby\n",
            " 78: Page 61  side-by                        sideby\n",
            " 79: Page 61  persepctive-taking             persepctivetaking\n",
            " 80: Page 63  Albert-Ludwigs                 AlbertLudwigs\n",
            " 81: Page 63  Ludwigs-Universit              LudwigsUniversit\n",
            " 82: Page 64  Heck-hausen                    Heckhausen\n",
            " 83: Page 66  constituent-order              constituentorder\n",
            " 84: Page 66  constituent-order              constituentorder\n",
            " 85: Page 66  No-Order                       NoOrder\n",
            " 86: Page 66  noun-pairs                     nounpairs\n",
            " 87: Page 67  order-memory                   ordermemory\n",
            " 88: Page 67  recognition-memory             recognitionmemory\n",
            " 89: Page 67  confidence-rating              confidencerating\n",
            " 90: Page 67  model-comparison               modelcomparison\n",
            " 91: Page 68  Perug-gia                      Peruggia\n",
            " 92: Page 71  to-moment                      tomoment\n",
            " 93: Page 74  Uni-versit                     Universit\n",
            " 94: Page 74  between-groups                 betweengroups\n",
            " 95: Page 77  speed-accuracy                 speedaccuracy\n",
            " 96: Page 87  Top-down                       Topdown\n",
            " 97: Page 88  Same-Different                 SameDifferent\n",
            " 98: Page 88  risk-seeking                   riskseeking\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pick indices of words to rehyphenate\n",
        "indices = [(2, 12), 14, 15, 17, 18, 21, 22, (24, 26), 29, 30, 32, 35, 37, 38, 40, (47, 49), (52, 54), 56, (59, 61), (66, 68), 70, 71, 74, (78, 81), 83, (85, 90), 92, (94, 98)]\n",
        "words_to_hyphenate = [\n",
        "    possible_hyphenated_words[i]\n",
        "    for item in indices\n",
        "    for i in ([item] if isinstance(item, int) else range(*item))\n",
        "]"
      ],
      "metadata": {
        "id": "9SiZxnFeRsPA"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word, hyphenated_word in words_to_hyphenate:\n",
        "  print(f'{word:<30} {hyphenated_word}')"
      ],
      "metadata": {
        "id": "o7piQmxhVV4-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48262d80-a9ec-4753-d99d-7c9ba64b448c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "humanmade                      human-made\n",
            "SmithKettlewell                Smith-Kettlewell\n",
            "grouptheoretic                 group-theoretic\n",
            "onedimensional                 one-dimensional\n",
            "outthere                       out-there\n",
            "multiclass                     multi-class\n",
            "skeletonbased                  skeleton-based\n",
            "DzhafarovKujala                Dzhafarov-Kujala\n",
            "FischerHilbert                 Fischer-Hilbert\n",
            "AbramskyBrandenburger          Abramsky-Brandenburger\n",
            "NeuroEngineering               Neuro-Engineering\n",
            "posticonic                     post-iconic\n",
            "wellknown                      well-known\n",
            "samedifferent                  same-different\n",
            "fastsame                       fast-same\n",
            "functionalform                 functional-form\n",
            "DiscreteState                  Discrete-State\n",
            "Continuousstrength             Continuous-strength\n",
            "parietaloccipital              parietal-occipital\n",
            "nondecision                    non-decision\n",
            "activelyA                      actively-A\n",
            "wellknown                      well-known\n",
            "continuousstate                continuous-state\n",
            "ChiaChien                      Chia-Chien\n",
            "momentto                       moment-to\n",
            "semipartial                    semi-partial\n",
            "nonequivalent                  non-equivalent\n",
            "ReinforcementLearning          Reinforcement-Learning\n",
            "Bottomup                       Bottom-up\n",
            "pvalue                         p-value\n",
            "multiattribute                 multi-attribute\n",
            "OrnsteinUhlenbeck              Ornstein-Uhlenbeck\n",
            "closedform                     closed-form\n",
            "nontrivially                   non-trivially\n",
            "NonStationary                  Non-Stationary\n",
            "nonstationary                  non-stationary\n",
            "locationdispersion             location-dispersion\n",
            "sideby                         side-by\n",
            "persepctivetaking              persepctive-taking\n",
            "AlbertLudwigs                  Albert-Ludwigs\n",
            "constituentorder               constituent-order\n",
            "NoOrder                        No-Order\n",
            "nounpairs                      noun-pairs\n",
            "ordermemory                    order-memory\n",
            "recognitionmemory              recognition-memory\n",
            "confidencerating               confidence-rating\n",
            "tomoment                       to-moment\n",
            "betweengroups                  between-groups\n",
            "speedaccuracy                  speed-accuracy\n",
            "Topdown                        Top-down\n",
            "SameDifferent                  Same-Different\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sort authors, affiliations, title, and abstract"
      ],
      "metadata": {
        "id": "hvO659m7ufLG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parsed_entries = []\n",
        "\n",
        "for entry in abstract_entries:\n",
        "  cleaned_entry = clean_text(entry, words_to_hyphenate)\n",
        "  if '_' in cleaned_entry:\n",
        "    info_text, abstract = split_after_last_affiliation(cleaned_entry)\n",
        "    info_text = info_text + '_'   # add back last '_'\n",
        "  else:\n",
        "    parsed_entries.append({\n",
        "        'year': '',\n",
        "        'author(s)': '',\n",
        "        'affiliation(s)': '',\n",
        "        'title': '',\n",
        "        'type': '',\n",
        "        'abstract': cleaned_entry\n",
        "    })\n",
        "    continue\n",
        "\n",
        "  # Extracts title\n",
        "  title_parts = re.findall(r'\\*\\*(.*?)\\*\\*', info_text)\n",
        "  title = ' '.join(a.strip() for a in title_parts) if title_parts else None\n",
        "\n",
        "  # Extracts all affiliations in entry\n",
        "  affiliation_parts = re.findall(r'_(.*?)_', info_text)\n",
        "  affiliations = '; '.join(a.strip()\\\n",
        "                           for a in affiliation_parts)\\\n",
        "                           if affiliation_parts else None\n",
        "\n",
        "  # Removes title and affiliation from info_text to get authors\n",
        "  authors_text = info_text\n",
        "\n",
        "  for t in title_parts:\n",
        "    authors_text = authors_text.replace(f'**{t}**', '')\n",
        "\n",
        "  for a in affiliation_parts:\n",
        "    authors_text = authors_text.replace(f'_{a}_', '')\n",
        "\n",
        "  # Cleans up punctuation & whitespace\n",
        "  authors = authors_text.strip().split(',')\n",
        "  list_authors = [a.strip() for a in authors if a.strip() and a.strip() != '_']\n",
        "  cleaned_authors = ', '.join(list_authors)\n",
        "\n",
        "  if len(set(affiliation_parts)) == 1:\n",
        "    affiliations = affiliation_parts[0]\n",
        "  else:\n",
        "    affiliations = '; '.join(affiliation_parts)\n",
        "\n",
        "  affiliations = remove_locations(affiliations)\n",
        "\n",
        "  parsed_entries.append({\n",
        "    'year': year,\n",
        "    'author(s)': cleaned_authors,\n",
        "    'affiliation(s)': affiliations,\n",
        "    'title': title.strip('.'),\n",
        "    'type': '',\n",
        "    'abstract': abstract.strip()\n",
        "  })"
      ],
      "metadata": {
        "id": "rYSctzOMshAh"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parsed_entries[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Q6ocLO1sha_",
        "outputId": "2b7e79ae-efe4-4e62-d98e-cb197e14711f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'year': '2014',\n",
              "  'author(s)': 'Horace Barlow',\n",
              "  'affiliation(s)': 'University of Cambridge',\n",
              "  'title': 'Symmetry and the computational goals that underlie perception',\n",
              "  'type': '',\n",
              "  'abstract': 'Although I am (or was) a neurophysiologist, I do not think records of impulse trains from neurons in perceptual systems can be interpreted properly until we answer the question \"What are the goals of the computations these systems and their neurons are performing?\" This is simply because you cannot test whether a system does the job you think it may do unless you have ideas about what that job is. The proposition I like the sound of, and shall argue for here, is that the two main computations in early vision are cross-correlation of patches of the image with fixed templates, and auto-correlations of pairs of image patches related by some specified transformations. One definition of symmetry is \"invariance under transformation\", so is symmetry detection the main computational goal of early vision? This is the first point to be discussed, and I think it turns out that the answer is \"Yes\", but perhaps this applies only to some, not all, of the transformations you might wish to include in the definition of symmetry. The second question is \"How does detecting symmetry help?\" Symmetries are forms of regularity or redundancy, and if you know about them you can make more reliable and sensitive predictions than if you don\\'t, and you will have potentially serious cognitive advantages over your competitors. There are some ancient observations on the way that damage to the visual cortex interferes with the orienting response that tend to support these views. It should be possible to allocate specific types of symmetry detection to specific cortical areas neurophysiologically, or possibly using fMRI. Some preliminary psychophysical experiments capable of measuring the absolute efficiencies for detecting non-random or non-independent positioning of dots in otherwise random arrays have already given encouraging preliminary results. I think the view that symmetry detection is the main new trick of the cerebral cortex deserves closer examination.'},\n",
              " {'year': '2014',\n",
              "  'author(s)': 'Richard S. Sutton',\n",
              "  'affiliation(s)': 'University Of Alberta',\n",
              "  'title': 'Reinforcement Learning and Psychology: A Personal Story',\n",
              "  'type': '',\n",
              "  'abstract': 'The modern field of reinforcement learning (RL) has a long, intertwined relationship with psychology. Almost all the powerful ideas of RL came originally from psychology, and today they are recognized as having significantly increased our ability to solve difficult engineering problems such as playing backgammon, flying helicopters, and optimal placement of internet advertisements. Psychology should celebrate this and take credit for it! RL has also begun to give something back to the study of natural minds, as RL algorithms are providing insights into classical conditioning, the neuroscience of brain reward systems, and the role of mental replay in thought. I have been working in the field of RL for much of this journey, back and forth between nature and engineering, and have played a role in some of the key steps. In this talk I tell the story as it seemed to happen from my point of view, summarizing it in four things that I think every psychologist should know about RL: 1) that it is a formalization of learning by trial and error, with engineering uses, 2) that it is a formalization of the propagation of reward predictions which closely matches behavioral and neuroscience data, 3) that it is a formalization of thought as learning from replayed experience that again matches data from natural systems, and 4) that there is a beautiful confluence of psychology, neuroscience, and computational theory on common ideas and elegant algorithms.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create df and convert to csv"
      ],
      "metadata": {
        "id": "nKNl4pKw44lP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(parsed_entries, columns=[\"year\", \"author(s)\", \"affiliation(s)\", \"title\", \"type\", \"abstract\"])"
      ],
      "metadata": {
        "id": "5IEUDPyalsYH"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "AZRpkwpEJ6ut",
        "outputId": "022c8b79-5d61-4d5b-9e68-087f4c34ecaf"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   year               author(s)                    affiliation(s)  \\\n",
              "0  2014           Horace Barlow           University of Cambridge   \n",
              "1  2014       Richard S. Sutton             University Of Alberta   \n",
              "2  2014          Wolf Vanpaemel                         KU Leuven   \n",
              "3  2014  Joachim Vandekerckhove  University of California, Irvine   \n",
              "4  2014     Richard M. Shiffrin                Indiana University   \n",
              "\n",
              "                                               title type  \\\n",
              "0  Symmetry and the computational goals that unde...        \n",
              "1  Reinforcement Learning and Psychology: A Perso...        \n",
              "2          Five routes to better models of cognition        \n",
              "3  A crowd-sourced scheduling system for academic...        \n",
              "4  Moving past BMS and MDL: Making model evaluati...        \n",
              "\n",
              "                                            abstract  \n",
              "0  Although I am (or was) a neurophysiologist, I ...  \n",
              "1  The modern field of reinforcement learning (RL...  \n",
              "2  An important goal in cognitive science is to b...  \n",
              "3  I will present preliminary results of a crowd-...  \n",
              "4  I present a generalization of Bayesian Model S...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f3ddd097-c547-4c68-885e-2ca4b329d851\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>author(s)</th>\n",
              "      <th>affiliation(s)</th>\n",
              "      <th>title</th>\n",
              "      <th>type</th>\n",
              "      <th>abstract</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2014</td>\n",
              "      <td>Horace Barlow</td>\n",
              "      <td>University of Cambridge</td>\n",
              "      <td>Symmetry and the computational goals that unde...</td>\n",
              "      <td></td>\n",
              "      <td>Although I am (or was) a neurophysiologist, I ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2014</td>\n",
              "      <td>Richard S. Sutton</td>\n",
              "      <td>University Of Alberta</td>\n",
              "      <td>Reinforcement Learning and Psychology: A Perso...</td>\n",
              "      <td></td>\n",
              "      <td>The modern field of reinforcement learning (RL...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2014</td>\n",
              "      <td>Wolf Vanpaemel</td>\n",
              "      <td>KU Leuven</td>\n",
              "      <td>Five routes to better models of cognition</td>\n",
              "      <td></td>\n",
              "      <td>An important goal in cognitive science is to b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2014</td>\n",
              "      <td>Joachim Vandekerckhove</td>\n",
              "      <td>University of California, Irvine</td>\n",
              "      <td>A crowd-sourced scheduling system for academic...</td>\n",
              "      <td></td>\n",
              "      <td>I will present preliminary results of a crowd-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2014</td>\n",
              "      <td>Richard M. Shiffrin</td>\n",
              "      <td>Indiana University</td>\n",
              "      <td>Moving past BMS and MDL: Making model evaluati...</td>\n",
              "      <td></td>\n",
              "      <td>I present a generalization of Bayesian Model S...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f3ddd097-c547-4c68-885e-2ca4b329d851')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f3ddd097-c547-4c68-885e-2ca4b329d851 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f3ddd097-c547-4c68-885e-2ca4b329d851');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-04c1b6e5-add4-4ddc-98ef-d8b02b2c45aa\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-04c1b6e5-add4-4ddc-98ef-d8b02b2c45aa')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-04c1b6e5-add4-4ddc-98ef-d8b02b2c45aa button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 123,\n  \"fields\": [\n    {\n      \"column\": \"year\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"\",\n          \"2014\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"author(s)\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 121,\n        \"samples\": [\n          \"Russell Golman, George Loewenstein\",\n          \"Peter C. Pantelis, Timothy Gerstner, Kevin Sanik, Ari Weinstein, Steven A. Cholewiak, Gaurav Kharkwal, Chia-Chien Wu, Jacob Feldman, Daniel P. Kennedy\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"affiliation(s)\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"Universit\\u00e9 du Qu\\u00e9bec A[`] Montr\\u00e9al\",\n          \"Laurentian University\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 123,\n        \"samples\": [\n          \"What is complementarity and compatibility in quantum cognition?\",\n          \"Curiosity, Information Gaps, and the Utility of Knowledge\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"type\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"abstract\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 123,\n        \"samples\": [\n          \"One of the most important differences between Kolmogorov and quantum probability theories is the introduction of the property of compatibility/incompatibility in the latter. Psychologically, two measurements are compatible if they can be considered simultaneously, one does not interfere with the other, and order of evaluation does not matter; otherwise they are incompatible. Formally, two measurements are compatible if they can be represented within the same basis, and so their projectors commute; otherwise they are incompatible. If all of the measures commute, then Kolmogorov and quantum theories are equivalent. How can we determine a priori whether or not two measurements are incompatible? And if they are, how can we determine the change in basis for these incompatible events? We consider an example of measurement for \\\"self\\\" (e.g., do you like this object?) versus \\\"other\\\" (do you think your friend will like this object?) by the same person, and we argue that these questions are incompatible. We empirically demonstrate that they produce strong order effects, and we develop and test a quantitative model that describes the change in basis when judgments are made from the different perspectives of \\\"self\\\" versus \\\"other.\\\" ## **Sunday, 9:38** Port-Neuf & Ste-Foy\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(f\"/content/drive/MyDrive/math_psych_work/csv/smp{year}_program.csv\", index=False)"
      ],
      "metadata": {
        "id": "65YB5d8WESQZ"
      },
      "execution_count": 29,
      "outputs": []
    }
  ]
}