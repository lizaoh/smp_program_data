{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lizaoh/smp_program_data/blob/main/smp2021_extract_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBXc6uieLC6Y"
      },
      "source": [
        "# Top of Script"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DW0MLlXyhw5G",
        "outputId": "35d2ca8e-346b-416b-f6cd-84b4c9b87097"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iwaO2sqpib2d"
      },
      "outputs": [],
      "source": [
        "# Suppresses output from pip installs\n",
        "%%capture\n",
        "\n",
        "!pip install pymupdf\n",
        "!pip install pymupdf-layout\n",
        "!pip install pymupdf4llm\n",
        "!pip install wordfreq\n",
        "!pip install rapidfuzz\n",
        "import glob\n",
        "import os\n",
        "import pathlib\n",
        "import pymupdf\n",
        "import pymupdf.layout\n",
        "import pymupdf4llm\n",
        "import re\n",
        "import regex\n",
        "import pandas as pd\n",
        "import unicodedata\n",
        "import wordfreq\n",
        "from rapidfuzz import process, fuzz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9TqNj0OYhzgb"
      },
      "outputs": [],
      "source": [
        "pdfs_path = '/content/drive/MyDrive/math_psych_work/Conference Programs/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cK6Itu79JGuf"
      },
      "source": [
        "# Functions\n",
        "Created with help from GPT 5.2, but some are my own code just turned into a function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xXzXB83HNC3z"
      },
      "outputs": [],
      "source": [
        "LOCATIONS = [\n",
        "    'United States of America', 'United States', 'Switzerland', 'Japan', 'Bremen',\n",
        "    'Berlin, Germany', 'Heidelberg, Germany', 'Germany', 'Berlin', 'Norway',\n",
        "    'Turkey', 'Belgium', 'Italy', 'Israel', 'New Brunswick, New Jersey',\n",
        "    'Australia', 'The Netherlands', 'USA', 'US', 'Netherlands, The', 'Netherlands',\n",
        "    'United Kingdom', 'Singapore', 'France', 'Dayton OH', 'Dayton', 'India',\n",
        "    'Taiwan, Republic of China', 'Austria', 'Canada', 'Denmark', 'Spain',\n",
        "    'Edmonton', 'Bloomington, Indiana', 'Indiana', 'Russian Federation',\n",
        "    'University Park, Pennsylvania', 'California', 'San Francisco, California',\n",
        "    'Taipei, Taiwan', 'Charlottesville, Virginia', 'New York, New York',\n",
        "    'Toronto, Ontario', 'New Haven, Connecticut', 'Ann Arbor, Michigan', 'Ohio',\n",
        "    'Ottawa, Ontario', 'Houston, Texas', 'UK', 'New Brunswick, Piscataway, NJ',\n",
        "    'Finland', 'Iceland', 'Mexico', 'South Korea'\n",
        "]\n",
        "\n",
        "# compile once\n",
        "LOCATION_RE = re.compile(\n",
        "    r',\\s*(?:' + '|'.join(map(re.escape, LOCATIONS)) + r')\\b',\n",
        "    re.I\n",
        ")\n",
        "\n",
        "def remove_locations(entry: str) -> str:\n",
        "    return LOCATION_RE.sub('', entry).strip()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def reorder_author(author: str) -> str:\n",
        "    \"\"\"\n",
        "    Convert 'Last, First Middle' → 'First Middle Last'\n",
        "    \"\"\"\n",
        "    last, given = author.split(\",\", 1)\n",
        "    return f\"{given.strip()} {last.strip()}\""
      ],
      "metadata": {
        "id": "GksuBFM2A1nC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cut_affiliation_at_author(affil: str) -> str | None:\n",
        "    \"\"\"\n",
        "    Keep affiliation text up to (but not including) the next author.\n",
        "    \"\"\"\n",
        "    m = AUTHOR_ONLY_RE.search(affil)\n",
        "    if m:\n",
        "        affil = affil[:m.start()]\n",
        "\n",
        "    affil = affil.strip(\" ;,-\")\n",
        "    return affil or 'none'"
      ],
      "metadata": {
        "id": "v8wyYeRartoA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LAST_NAME = r\"\"\"\n",
        "(?:\n",
        "    (?:van|de)\\s+\\p{L}+(?:-\\p{L}+)*(?:\\s+\\p{L}+)?  # van/de X or de la X\n",
        "    |\n",
        "    \\p{L}+(?:-\\p{L}+)*                             # single-word last name\n",
        ")\n",
        "\"\"\"\n",
        "\n",
        "GIVEN_NAMES = rf\"\"\"\n",
        "(?:\\p{{L}}+(?:-\\p{{L}}+)*|\\p{{L}}\\.)               # first given token\n",
        "(?:\n",
        "    \\s+\n",
        "    (?!{LAST_NAME}\\s*,)                            # STOP before next author\n",
        "    (?:\\p{{L}}+(?:-\\p{{L}}+)*|\\p{{L}}\\.)\n",
        ")*\n",
        "\"\"\"\n",
        "\n",
        "ALT_NAME = r\"\"\"\n",
        "(?:\\s*\\([^)]*\\))?                                  # optional alt name\n",
        "\"\"\"\n",
        "\n",
        "AUTHOR_CORE = rf\"\"\"\n",
        "(?P<author>\n",
        "    {LAST_NAME}\n",
        "    ,\\s*\n",
        "    {GIVEN_NAMES}\n",
        "    {ALT_NAME}\n",
        ")\n",
        "\"\"\"\n",
        "\n",
        "AUTHOR_ONLY_RE = regex.compile(\n",
        "    rf\"\"\"\n",
        "    {AUTHOR_CORE}\n",
        "    \"\"\",\n",
        "    regex.VERBOSE | regex.IGNORECASE,\n",
        ")\n",
        "\n",
        "def parse_authors_affiliations(text: str):\n",
        "    \"\"\"\n",
        "    Returns:\n",
        "        authors: list[str]            # \"First Last\"\n",
        "        affiliations: list[str|None]  # aligned with authors\n",
        "    \"\"\"\n",
        "\n",
        "    authors = []\n",
        "    affiliations = []\n",
        "\n",
        "    # Split ONLY on en dashes\n",
        "    chunks = [c.strip() for c in text.split(\"–\")]\n",
        "\n",
        "    for i, chunk in enumerate(chunks):\n",
        "        # Find ALL authors in this chunk\n",
        "        matches = list(AUTHOR_ONLY_RE.finditer(chunk))\n",
        "        if not matches:\n",
        "            continue\n",
        "\n",
        "        for j, m in enumerate(matches):\n",
        "            raw_author = m.group(\"author\")\n",
        "            author = reorder_author(raw_author)\n",
        "\n",
        "            # Only the LAST author before a dash gets the affiliation\n",
        "            if j == len(matches) - 1 and i + 1 < len(chunks):\n",
        "                raw_affil = chunks[i + 1].strip()\n",
        "                affil = cut_affiliation_at_author(raw_affil)\n",
        "            else:\n",
        "                affil = 'none'\n",
        "\n",
        "            if author not in authors:\n",
        "                authors.append(author)\n",
        "                affiliations.append(affil)\n",
        "\n",
        "    return authors, affiliations"
      ],
      "metadata": {
        "id": "QSvY9U3JSjbE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "CxB8mawESnT_"
      },
      "outputs": [],
      "source": [
        "def remove_page_break_text(text: str) -> str:\n",
        "    if not text:\n",
        "        return text\n",
        "\n",
        "    # Replaces with nothing for the rest\n",
        "    text = re.sub(r'\\n\\n\\d{1,3} \\n\\n', '\\n\\n', text)\n",
        "\n",
        "    return text.strip()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_picture_text(text: str) -> str:\n",
        "    if not text:\n",
        "        return text\n",
        "\n",
        "    text = re.sub(\n",
        "        r'''\n",
        "        \\n\\n\\*\\*==>\\spicture\\s\\[\\d{2}\\sx\\s\\d{2}\\]\\sintentionally\\somitted\\s<==\\*\\*\\n\\n\n",
        "        ''',\n",
        "        '\\n\\n',\n",
        "        text,\n",
        "        flags=re.VERBOSE\n",
        "    )\n",
        "\n",
        "    text = re.sub(\n",
        "        r'''\n",
        "        \\*\\*-----\\sStart\\sof\\spicture\\stext\\s-----\\*\\*\n",
        "        <br>\\n[A-Z][A-Z]<br>\n",
        "        ''',\n",
        "        '',\n",
        "        text,\n",
        "        flags=re.VERBOSE\n",
        "    )\n",
        "\n",
        "    text = re.sub(\n",
        "        r'''\n",
        "        \\*\\*-----\\sEnd\\sof\\spicture\\stext\\s-----\\*\\*<br>\\n\\n\\n#?#?\n",
        "        ''',\n",
        "        '##',\n",
        "        text,\n",
        "        flags=re.VERBOSE\n",
        "    )\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "OlRvTsrPqbPZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type_labels = ['MT', 'FT', 'PO', 'PA']\n",
        "\n",
        "def remove_label(text: str) -> str:\n",
        "  if not text:\n",
        "      return text\n",
        "\n",
        "  label_patt = \"|\".join(type_labels)\n",
        "  pattern = rf\"\\*\\*(?:{label_patt})\\*\\*\"\n",
        "\n",
        "  text = re.sub(pattern, '', text)\n",
        "\n",
        "  return text"
      ],
      "metadata": {
        "id": "DZGJJkEmatoK"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "aq4f3JE9IgHD"
      },
      "outputs": [],
      "source": [
        "def clean_text(text, fix_whitespace=False, delete_whitespace=False):\n",
        "    if not text:\n",
        "        return text\n",
        "\n",
        "    text = fix_ligatures(text)\n",
        "    text = remove_page_break_text(text)\n",
        "    text = remove_picture_text(text)\n",
        "    text = remove_label(text)\n",
        "\n",
        "    # Gets rid of breaks in titles\n",
        "    text = re.sub(r'\\*\\*\\s\\n\\n##\\s\\*\\*', ' ', text)\n",
        "\n",
        "    text = text.replace('||\\n|---|---|\\n|', ' ')\n",
        "    text = text.replace('||\\n|', ' ')\n",
        "\n",
        "    if fix_whitespace:\n",
        "      text = re.sub(r'\\n\\s+', '\\n\\n', text)\n",
        "\n",
        "    if delete_whitespace:\n",
        "      text = re.sub(r'\\s{2,}', ' ', text)\n",
        "\n",
        "    text = text.strip()\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "WLDsGBzsFnSz"
      },
      "outputs": [],
      "source": [
        "LIGATURE_MAP = {\n",
        "    \"ﬁ\": \"fi\", \"ﬂ\": \"fl\", \"ﬃ\": \"ffi\", \"ﬄ\": \"ffl\", \"ﬀ\": \"ff\", \"ﬅ\": \"ft\", \"ﬆ\": \"st\",\n",
        "    \"Æ\": \"ffi\", \"¨u\": \"ü\", \"¨a\": \"ä\", \"´e\": \"é\", \"`e\": \"è\", \"`a\": \"à\", \"¨o\": \"ö\",\n",
        "    \"˚a\": \"å\", \"c¸\": \"ç\", '“': '\"', '”': '\"', \"’\": \"'\", '˜n': 'ñ', 'ˇs': 'š',\n",
        "    \"âĂŸ\": \"'\", \"``\": '\"', \"↵\": \"ff\", \"✏\": \"ffl\", \"‘\": \"'\"\n",
        "}\n",
        "\n",
        "def fix_ligatures(text):\n",
        "    # Replace known ligatures\n",
        "    for bad, good in LIGATURE_MAP.items():\n",
        "        text = text.replace(bad, good)\n",
        "\n",
        "    # Replace any private-use ligature (common in PDFs)\n",
        "    cleaned_chars = []\n",
        "    for ch in text:\n",
        "        name = unicodedata.name(ch, \"\")\n",
        "        if \"LIGATURE\" in name.upper():\n",
        "            # Try to break it apart: remove spaces and lowercase\n",
        "            base = name.split(\"LIGATURE\")[-1]\n",
        "            base = base.replace(\" \", \"\").lower()\n",
        "            cleaned_chars.append(base)\n",
        "        else:\n",
        "            cleaned_chars.append(ch)\n",
        "\n",
        "    return \"\".join(cleaned_chars)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def rehyphenate_words(text, words_to_hyphenate):\n",
        "    for word, hyphenated_word in words_to_hyphenate:\n",
        "        text = text.replace(word, hyphenated_word)\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "hNTyPQzW06Ko"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checks if valid word using Zipf frequency\n",
        "def is_probably_valid(word, threshold=2.5):\n",
        "    return wordfreq.zipf_frequency(word, \"en\") > threshold  # smaller number cuts off\n",
        "                                                            # more words, bigger is\n",
        "                                                            # more lenient"
      ],
      "metadata": {
        "id": "BZn089Q_06l2"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzyoCbvJK6js"
      },
      "source": [
        "# Program\n",
        "\n",
        "204 entries total (4 keynote talks,  symposium talks,  talks,  fast talks, and  posters)\n",
        "\n",
        "Has justified text so need to check hyphenated words at line breaks, affiliations are listed after names after an en dash. Some authors don't have affiliation listed.\n",
        "\n",
        "This one has a keynote by Prof. Allen :)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "-iaeTkOjqA3-"
      },
      "outputs": [],
      "source": [
        "year = '2021'\n",
        "file_path = pdfs_path + f'smp{year}_program.pdf'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NY0NZXAh696-"
      },
      "source": [
        "## Grab text from the pdf\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "program = pymupdf.open(file_path)   # original PDF\n",
        "program_text = pymupdf4llm.to_markdown(program)"
      ],
      "metadata": {
        "id": "UC8tgNIEt3yJ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "program_text[73_600:75_000]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "bjapdcOFt7BZ",
        "outputId": "2c5dfda7-d489-42c8-936c-c414bb9dca05"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'AM EDT|||\\n|**July 9**<br>12:00PM EDT|SE|Friday mixer|\\n\\n\\n\\n49 \\n\\n**Abstracts** \\n\\n_MT: MathPsych Talk, FT: MathPsych Fast talk, PO: ICCM Poster, PA: ICCM Paper_ Abstracts are printed in alphabetical order by title. \\n\\n## **A predictive processing implementation of the common model of cognition** \\n\\n**PO** \\n\\nKelly, Alex – Carleton University Ororbia, Alex \\n\\nSession: _ICCM: Poster session_ – live on Thursday, July 8, at 10:00AM EDT \\n\\nWe present how a cognitive architecture can be built from the neural circuit models proposed under the frameworks of holographic memory and neural generative coding. Specifically, we draw inspiration from well-known cognitive architectures such as ACT-R, Soar, Leabra, and Nengo, as well as the common model of cognition, to propose the kernel that might drive a complex, modular system that would prove useful for developing intelligent agents that tackle statistical learning tasks, as well as for answering questions and testing hypotheses in cognitive science and computational neuroscience. \\n\\n## **A Bayesian account of two-factor theory of emotion process** \\n\\nYing, Lance – University of Michigan - Ann Arbor Zhang, Jun – University of Michigan **FT** \\n\\nSession: _Fast Talk session_ – live on Wednesday, July 7, at 01:00PM EDT \\n\\nBayesian inference has been used in the past to model visual perception (Kerson et al., 2004), accounting for the Helmholtz principle o'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Find words to re-hyphenate"
      ],
      "metadata": {
        "id": "kLz8RAOqBM9Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pattern = re.compile(r'([A-Za-z]+)-\\n\\s*([A-Za-z]+)')\n",
        "possible_hyphenated_words = []\n",
        "\n",
        "counter = 0\n",
        "for p, page in enumerate(program[50:]):  # these are the pages with abstracts only\n",
        "  text = fix_ligatures(page.get_text('text'))\n",
        "  matches = pattern.findall(text)\n",
        "\n",
        "  for left, right in matches:\n",
        "    word = f\"{left}{right}\"\n",
        "    hyphenated_word = f\"{left}-{right}\"\n",
        "    if not is_probably_valid(word, threshold=2.8):\n",
        "      possible_hyphenated_words.append([word, hyphenated_word])\n",
        "\n",
        "      print(f\"{counter:>3}: Page {p+51:<3} {hyphenated_word:<30} {word}\")\n",
        "      counter += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMdLe69U7GMm",
        "outputId": "a77d4343-3301-4d9b-c2c8-c517cdf75ad8"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  0: Page 51  physiologi-cally               physiologically\n",
            "  1: Page 51  Schachter-Singer               SchachterSinger\n",
            "  2: Page 52  dis-cards                      discards\n",
            "  3: Page 55  semi-Markov                    semiMarkov\n",
            "  4: Page 58  laten-cies                     latencies\n",
            "  5: Page 60  nonnega-tivity                 nonnegativity\n",
            "  6: Page 69  informationally-equivalent     informationallyequivalent\n",
            "  7: Page 71  co-occurrence                  cooccurrence\n",
            "  8: Page 78  non-decision                   nondecision\n",
            "  9: Page 80  frequen-tist                   frequentist\n",
            " 10: Page 86  computa-tions                  computations\n",
            " 11: Page 94  sampling-based                 samplingbased\n",
            " 12: Page 94  mechanis-tic                   mechanistic\n",
            " 13: Page 96  mus-cimol                      muscimol\n",
            " 14: Page 100 intertempo-ral                 intertemporal\n",
            " 15: Page 105 noncon-textuality              noncontextuality\n",
            " 16: Page 107 neurocompu-tational            neurocomputational\n",
            " 17: Page 109 synchronization-continuation   synchronizationcontinuation\n",
            " 18: Page 109 high-dimensional               highdimensional\n",
            " 19: Page 111 granu-larity                   granularity\n",
            " 20: Page 112 Associa-tiveMemory             AssociativeMemory\n",
            " 21: Page 115 model-inferred                 modelinferred\n",
            " 22: Page 117 within-category                withincategory\n",
            " 23: Page 118 physiologically-based          physiologicallybased\n",
            " 24: Page 118 modu-late                      modulate\n",
            " 25: Page 120 lotter-ies                     lotteries\n",
            " 26: Page 120 heuristic-based                heuristicbased\n",
            " 27: Page 120 Py-BEAM                        PyBEAM\n",
            " 28: Page 124 trial-level                    triallevel\n",
            " 29: Page 129 Dellav-igna                    Dellavigna\n",
            " 30: Page 131 non-symbolic                   nonsymbolic\n",
            " 31: Page 133 externaliz-ing                 externalizing\n",
            " 32: Page 133 inter-nalizing                 internalizing\n",
            " 33: Page 139 psychophysi-cal                psychophysical\n",
            " 34: Page 140 the-best                       thebest\n",
            " 35: Page 141 predici-tion                   predicition\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pick indices of words to rehyphenate\n",
        "indices = [1, 3, (6,8), 11, 17, 18, (21,23), 28, 30, 34]\n",
        "words_to_hyphenate = [\n",
        "    possible_hyphenated_words[i]\n",
        "    for item in indices\n",
        "    for i in ([item] if isinstance(item, int) else range(*item))\n",
        "]"
      ],
      "metadata": {
        "id": "9SiZxnFeRsPA"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word, hyphenated_word in words_to_hyphenate:\n",
        "  print(f'{word:<30} {hyphenated_word}')"
      ],
      "metadata": {
        "id": "o7piQmxhVV4-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec1a6717-6dcd-44ec-f067-7c9c69d38e7e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SchachterSinger                Schachter-Singer\n",
            "semiMarkov                     semi-Markov\n",
            "informationallyequivalent      informationally-equivalent\n",
            "cooccurrence                   co-occurrence\n",
            "samplingbased                  sampling-based\n",
            "synchronizationcontinuation    synchronization-continuation\n",
            "highdimensional                high-dimensional\n",
            "modelinferred                  model-inferred\n",
            "withincategory                 within-category\n",
            "triallevel                     trial-level\n",
            "nonsymbolic                    non-symbolic\n",
            "thebest                        the-best\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split up into talk entries"
      ],
      "metadata": {
        "id": "ROGXQjnEA01_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "program_abstracts_start = program_text.split('title. \\n\\n## ')[1]\n",
        "\n",
        "# Rehyphenate words that need hyphen at line breaks\n",
        "program_abstracts_start = rehyphenate_words(program_abstracts_start, words_to_hyphenate)\n",
        "\n",
        "# Gets rid of page break and pictured omitted text\n",
        "program_abstracts_start = clean_text(program_abstracts_start, fix_whitespace=True)\n",
        "\n",
        "# Splits each abstract entry\n",
        "abstract_entries = re.split(r'\\s\\n\\n##\\s(?=\\*\\*)', program_abstracts_start)[:-4]\n",
        "# abstract_entries = [entry for entry in abstract_entries if len(entry) > 300]"
      ],
      "metadata": {
        "id": "9e6YaskncXBU"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "abstract_entries[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uoyCEDQV541s",
        "outputId": "2a9b1c1e-6e3f-4903-85ff-e3b836dc7fdc"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['**A predictive processing implementation of the common model of cognition** \\n\\nKelly, Alex – Carleton University Ororbia, Alex \\n\\nSession: _ICCM: Poster session_ – live on Thursday, July 8, at 10:00AM EDT \\n\\nWe present how a cognitive architecture can be built from the neural circuit models proposed under the frameworks of holographic memory and neural generative coding. Specifically, we draw inspiration from well-known cognitive architectures such as ACT-R, Soar, Leabra, and Nengo, as well as the common model of cognition, to propose the kernel that might drive a complex, modular system that would prove useful for developing intelligent agents that tackle statistical learning tasks, as well as for answering questions and testing hypotheses in cognitive science and computational neuroscience.',\n",
              " '**A Bayesian account of two-factor theory of emotion process** \\n\\nYing, Lance – University of Michigan - Ann Arbor Zhang, Jun – University of Michigan  \\n\\nSession: _Fast Talk session_ – live on Wednesday, July 7, at 01:00PM EDT \\n\\nBayesian inference has been used in the past to model visual perception (Kerson et al., 2004), accounting for the Helmholtz principle of perception of \"unconscious inference.\" In this paper, we adapt the Bayesian framework to model emotion in accordance with Schachter-Singer\\'s Two-Factor theory, which argued that emotion is the outcome of cognitive labeling or attribution of a diffuse pattern of autonomic arousal (Schachter & Singer, 1962). In analogous to visual perception, we conceptualize the emotion process, in which emotional labels are constructed, as an instance of unconscious Bayesian inference combining the contextual information with a person\\'s physiological arousal patterns. We develop a drift-diffusion model to simulate Schachter-Singer\\'s experimental findings. There, participants who were physiologically aroused (via drug injection but were not informed of arousal) later reported different emotions (i.e., labeled their arousal pattern differently) based on the nature of their interaction with a experimental confederate they encountered post-injection. In our drift-diffusion modeling, the decision boundaries correspond to the euphoric and anger state experienced by the participants in the experiment, and boundary-crossing constitutes \"labeling\" in Schachter-Singer\\'s sense. Response time (RT) in the drift-diffusion model is used as a surrogate measure of the self-rated intensity of the emotional state, where high intensity corresponds to a shorter response time. We propose two model scenarios (versions). In the first version, arousal pattern is used as the prior and the likelihood function for evidence accumulation is models the interaction with the confederate (context). We adopt an unbiased prior, while allowing the drift-rate (and its sign) to capture the nature of interaction with the confederate. In the second setup, we use the context as the prior and physiological arousal patterns as the likelihood function. We expect an initial bias depending on the polarity of the interactive experience with the confederate, but the drift-rate is of zero-mean (diffuse but polarity-neutral arousal pattern). The comparison between the simulations of the two versions of the Bayesian drift-diffusion models and the original Schachter & Singer (1962) experimental data will be reported.']"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvO659m7ufLG"
      },
      "source": [
        "## Sort authors, affiliations, title, and abstract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "rYSctzOMshAh"
      },
      "outputs": [],
      "source": [
        "parsed_entries = []\n",
        "\n",
        "for e, entry in enumerate(abstract_entries):\n",
        "  entry_info, abstract = re.split(r'EDT(?: |\\|\\|)\\n\\n', entry, maxsplit=1)\n",
        "\n",
        "  # Title is the only bolded text\n",
        "  title = re.search(r'\\*\\*(.*?)\\*\\*', entry_info).group().strip('**')\n",
        "\n",
        "  no_session = re.split(r'(?:\\s|\\|\\|\\n\\||\\n\\n##|\\n\\n-\\s)Session:', entry_info)[0].strip()\n",
        "  auth_aff = re.split(r'\\n\\n', no_session)[-1]\n",
        "  no_loc_auth_aff = remove_locations(auth_aff)\n",
        "\n",
        "  authors, affiliations = parse_authors_affiliations(no_loc_auth_aff)\n",
        "\n",
        "  parsed_entries.append({\n",
        "      'year': year,\n",
        "      'author(s)': ', '.join(authors),\n",
        "      'affiliation(s)': '; '.join(affiliations),\n",
        "      'title': title,\n",
        "      'type': '',\n",
        "      'abstract': clean_text(abstract, delete_whitespace=True)\n",
        "  })"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parsed_entries[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AiS86P0CzCwv",
        "outputId": "f35e32b2-9cbe-4f91-f27d-ad2bd061d9f0"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'year': '2021',\n",
              "  'author(s)': 'Alex Kelly, Alex Ororbia',\n",
              "  'affiliation(s)': 'Carleton University; none',\n",
              "  'title': 'A predictive processing implementation of the common model of cognition',\n",
              "  'type': '',\n",
              "  'abstract': 'We present how a cognitive architecture can be built from the neural circuit models proposed under the frameworks of holographic memory and neural generative coding. Specifically, we draw inspiration from well-known cognitive architectures such as ACT-R, Soar, Leabra, and Nengo, as well as the common model of cognition, to propose the kernel that might drive a complex, modular system that would prove useful for developing intelligent agents that tackle statistical learning tasks, as well as for answering questions and testing hypotheses in cognitive science and computational neuroscience.'},\n",
              " {'year': '2021',\n",
              "  'author(s)': 'Lance Ying, Jun Zhang',\n",
              "  'affiliation(s)': 'University of Michigan - Ann Arbor; University of Michigan',\n",
              "  'title': 'A Bayesian account of two-factor theory of emotion process',\n",
              "  'type': '',\n",
              "  'abstract': 'Bayesian inference has been used in the past to model visual perception (Kerson et al., 2004), accounting for the Helmholtz principle of perception of \"unconscious inference.\" In this paper, we adapt the Bayesian framework to model emotion in accordance with Schachter-Singer\\'s Two-Factor theory, which argued that emotion is the outcome of cognitive labeling or attribution of a diffuse pattern of autonomic arousal (Schachter & Singer, 1962). In analogous to visual perception, we conceptualize the emotion process, in which emotional labels are constructed, as an instance of unconscious Bayesian inference combining the contextual information with a person\\'s physiological arousal patterns. We develop a drift-diffusion model to simulate Schachter-Singer\\'s experimental findings. There, participants who were physiologically aroused (via drug injection but were not informed of arousal) later reported different emotions (i.e., labeled their arousal pattern differently) based on the nature of their interaction with a experimental confederate they encountered post-injection. In our drift-diffusion modeling, the decision boundaries correspond to the euphoric and anger state experienced by the participants in the experiment, and boundary-crossing constitutes \"labeling\" in Schachter-Singer\\'s sense. Response time (RT) in the drift-diffusion model is used as a surrogate measure of the self-rated intensity of the emotional state, where high intensity corresponds to a shorter response time. We propose two model scenarios (versions). In the first version, arousal pattern is used as the prior and the likelihood function for evidence accumulation is models the interaction with the confederate (context). We adopt an unbiased prior, while allowing the drift-rate (and its sign) to capture the nature of interaction with the confederate. In the second setup, we use the context as the prior and physiological arousal patterns as the likelihood function. We expect an initial bias depending on the polarity of the interactive experience with the confederate, but the drift-rate is of zero-mean (diffuse but polarity-neutral arousal pattern). The comparison between the simulations of the two versions of the Bayesian drift-diffusion models and the original Schachter & Singer (1962) experimental data will be reported.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKNl4pKw44lP"
      },
      "source": [
        "# Create df and convert to csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "5IEUDPyalsYH"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(parsed_entries, columns=[\"year\", \"author(s)\", \"affiliation(s)\", \"title\", \"type\", \"abstract\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "AZRpkwpEJ6ut",
        "outputId": "ece2ec4e-e157-413c-bf45-7888af4b351a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   year                                          author(s)  \\\n",
              "0  2021                           Alex Kelly, Alex Ororbia   \n",
              "1  2021                              Lance Ying, Jun Zhang   \n",
              "2  2021          Jeff Coon, Irvine California, Michael Lee   \n",
              "3  2021  Sabina J Sloman, Robert Goldstone, Cleotilde (...   \n",
              "4  2021          James Yearsley, University of London City   \n",
              "\n",
              "                                      affiliation(s)  \\\n",
              "0                          Carleton University; none   \n",
              "1  University of Michigan - Ann Arbor; University...   \n",
              "2                 University of; none; University of   \n",
              "3  Carnegie Mellon University; none; Carnegie Mel...   \n",
              "4                                         none; none   \n",
              "\n",
              "                                               title type  \\\n",
              "0  A predictive processing implementation of the ...        \n",
              "1  A Bayesian account of two-factor theory of emo...        \n",
              "2  A Bayesian method for measuring risk propensit...        \n",
              "3  A cognitive computational model of collective ...        \n",
              "4  A computational model of the IEDS task helps s...        \n",
              "\n",
              "                                            abstract  \n",
              "0  We present how a cognitive architecture can be...  \n",
              "1  Bayesian inference has been used in the past t...  \n",
              "2  The Balloon Analogue Risk Task (BART) is widel...  \n",
              "3  Many of the decisions we make in day-to-day li...  \n",
              "4  The Intra-Extra-dimensional set shift task (IE...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-df08a458-c374-4fd0-adb0-d1638e208099\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>author(s)</th>\n",
              "      <th>affiliation(s)</th>\n",
              "      <th>title</th>\n",
              "      <th>type</th>\n",
              "      <th>abstract</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021</td>\n",
              "      <td>Alex Kelly, Alex Ororbia</td>\n",
              "      <td>Carleton University; none</td>\n",
              "      <td>A predictive processing implementation of the ...</td>\n",
              "      <td></td>\n",
              "      <td>We present how a cognitive architecture can be...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021</td>\n",
              "      <td>Lance Ying, Jun Zhang</td>\n",
              "      <td>University of Michigan - Ann Arbor; University...</td>\n",
              "      <td>A Bayesian account of two-factor theory of emo...</td>\n",
              "      <td></td>\n",
              "      <td>Bayesian inference has been used in the past t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021</td>\n",
              "      <td>Jeff Coon, Irvine California, Michael Lee</td>\n",
              "      <td>University of; none; University of</td>\n",
              "      <td>A Bayesian method for measuring risk propensit...</td>\n",
              "      <td></td>\n",
              "      <td>The Balloon Analogue Risk Task (BART) is widel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021</td>\n",
              "      <td>Sabina J Sloman, Robert Goldstone, Cleotilde (...</td>\n",
              "      <td>Carnegie Mellon University; none; Carnegie Mel...</td>\n",
              "      <td>A cognitive computational model of collective ...</td>\n",
              "      <td></td>\n",
              "      <td>Many of the decisions we make in day-to-day li...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021</td>\n",
              "      <td>James Yearsley, University of London City</td>\n",
              "      <td>none; none</td>\n",
              "      <td>A computational model of the IEDS task helps s...</td>\n",
              "      <td></td>\n",
              "      <td>The Intra-Extra-dimensional set shift task (IE...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-df08a458-c374-4fd0-adb0-d1638e208099')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-df08a458-c374-4fd0-adb0-d1638e208099 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-df08a458-c374-4fd0-adb0-d1638e208099');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 196,\n  \"fields\": [\n    {\n      \"column\": \"year\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"2021\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"author(s)\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 193,\n        \"samples\": [\n          \"Kai Preuss, Nele Russwinkel\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"affiliation(s)\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 178,\n        \"samples\": [\n          \"University of Basel; University of Hamburg; University of Basel\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 196,\n        \"samples\": [\n          \"Parameter correlations in the predictive performance equation: Implications and solutions\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"type\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"abstract\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 196,\n        \"samples\": [\n          \"Research of mathematical models of learning and retention have focused on accounting for an individual's performance across a variety of learning schedules (i.e., spaced and massed). The attempted goal of such research is to develop a model which can adequately predict human performance across a range of learning scenarios. However, little attention of this model development has focused on the interpretation of a model's best fitting parameters given the structure of a model's equations and its predicted performance values. The effect of this can lead to the development of models where the parameter values are correlated hindering a theoretical interpretation of performance. Here we examine the structure of the Predictive Performance Equation (PPE) and highlight portions of PPE's equations that lead to correlations across its free parameters. We propose a fix for these issues (Modified PPE) and conduct a formal model comparison showing the Modified PPE is simpler, has less parameter correlation and its best fitting parameters map on to identifiable aspects of an individual's performance.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "65YB5d8WESQZ"
      },
      "outputs": [],
      "source": [
        "df.to_csv(f\"/content/drive/MyDrive/math_psych_work/csv/smp{year}_program.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNBCNAEgyWf2PXfHCsAcO+u",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}