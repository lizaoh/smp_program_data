{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMElxCfXgYEIrR4oO5mdv7t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lizaoh/smp_program_data/blob/main/smp2016_extract_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Top of Script"
      ],
      "metadata": {
        "id": "KBXc6uieLC6Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DW0MLlXyhw5G",
        "outputId": "a1160208-1fbd-41d3-ada4-b863d3c14299"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymupdf\n",
        "!pip install pymupdf-layout\n",
        "!pip install pymupdf4llm\n",
        "!pip install wordfreq\n",
        "# !pip install rapidfuzz\n",
        "import glob\n",
        "import os\n",
        "import pathlib\n",
        "import pymupdf\n",
        "import pymupdf.layout\n",
        "import pymupdf4llm\n",
        "import re\n",
        "import pandas as pd\n",
        "import unicodedata\n",
        "import wordfreq\n",
        "# from rapidfuzz import process, fuzz"
      ],
      "metadata": {
        "id": "iwaO2sqpib2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c265c86-7fa5-45a6-d7e0-15aab5d830bd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymupdf\n",
            "  Downloading pymupdf-1.26.7-cp310-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
            "Downloading pymupdf-1.26.7-cp310-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/24.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/24.1 MB\u001b[0m \u001b[31m158.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m17.8/24.1 MB\u001b[0m \u001b[31m380.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m351.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m149.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymupdf\n",
            "Successfully installed pymupdf-1.26.7\n",
            "Collecting pymupdf-layout\n",
            "  Downloading pymupdf_layout-1.26.6-cp310-abi3-manylinux_2_28_x86_64.whl.metadata (2.8 kB)\n",
            "Collecting PyMuPDF==1.26.6 (from pymupdf-layout)\n",
            "  Downloading pymupdf-1.26.6-cp310-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from pymupdf-layout) (6.0.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from pymupdf-layout) (2.0.2)\n",
            "Collecting onnxruntime (from pymupdf-layout)\n",
            "  Downloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from pymupdf-layout) (3.6.1)\n",
            "Collecting coloredlogs (from onnxruntime->pymupdf-layout)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime->pymupdf-layout) (25.9.23)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from onnxruntime->pymupdf-layout) (25.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime->pymupdf-layout) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime->pymupdf-layout) (1.14.0)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime->pymupdf-layout)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime->pymupdf-layout) (1.3.0)\n",
            "Downloading pymupdf_layout-1.26.6-cp310-abi3-manylinux_2_28_x86_64.whl (12.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m83.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pymupdf-1.26.6-cp310-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m88.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m113.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDF, humanfriendly, coloredlogs, onnxruntime, pymupdf-layout\n",
            "  Attempting uninstall: PyMuPDF\n",
            "    Found existing installation: PyMuPDF 1.26.7\n",
            "    Uninstalling PyMuPDF-1.26.7:\n",
            "      Successfully uninstalled PyMuPDF-1.26.7\n",
            "Successfully installed PyMuPDF-1.26.6 coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.23.2 pymupdf-layout-1.26.6\n",
            "Collecting pymupdf4llm\n",
            "  Downloading pymupdf4llm-0.2.8-py3-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: pymupdf>=1.26.6 in /usr/local/lib/python3.12/dist-packages (from pymupdf4llm) (1.26.6)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (from pymupdf4llm) (0.9.0)\n",
            "Downloading pymupdf4llm-0.2.8-py3-none-any.whl (68 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.6/68.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymupdf4llm\n",
            "Successfully installed pymupdf4llm-0.2.8\n",
            "Collecting wordfreq\n",
            "  Downloading wordfreq-3.1.1-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ftfy>=6.1 (from wordfreq)\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting langcodes>=3.0 (from wordfreq)\n",
            "  Downloading langcodes-3.5.1-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting locate<2.0.0,>=1.1.1 (from wordfreq)\n",
            "  Downloading locate-1.1.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.7 in /usr/local/lib/python3.12/dist-packages (from wordfreq) (1.1.2)\n",
            "Requirement already satisfied: regex>=2023.10.3 in /usr/local/lib/python3.12/dist-packages (from wordfreq) (2025.11.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from ftfy>=6.1->wordfreq) (0.2.14)\n",
            "Downloading wordfreq-3.1.1-py3-none-any.whl (56.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langcodes-3.5.1-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.1/183.1 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading locate-1.1.1-py3-none-any.whl (5.4 kB)\n",
            "Installing collected packages: locate, langcodes, ftfy, wordfreq\n",
            "Successfully installed ftfy-6.3.1 langcodes-3.5.1 locate-1.1.1 wordfreq-3.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pdfs_path = '/content/drive/MyDrive/math_psych_work/Conference Programs/'"
      ],
      "metadata": {
        "id": "9TqNj0OYhzgb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions\n",
        "Created with help from GPT 5.2, but some are my own code just turned into a function."
      ],
      "metadata": {
        "id": "cK6Itu79JGuf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Authors are always [last name], [first name, sometimes middle initial] and\n",
        "# separated by commas, with last author having \", and\" before it\n",
        "AUTHOR_LINE_RE = re.compile(\n",
        "    r\"\"\"\n",
        "    ^\n",
        "    # First author\n",
        "    (?:[a-z]{2,}\\s+)*[A-Z][a-zA-Z'-]+,      # last name (with lowercase particles)\n",
        "    \\s+\n",
        "    (?:[A-Z][a-zA-Z'-]+|[A-Z]\\.)            # first name OR initial\n",
        "    (?:\\s+(?:[A-Z][a-zA-Z'-]+|[A-Z]\\.))*    # middle names / initials\n",
        "\n",
        "    # Additional authors\n",
        "    (?:,\\s+\n",
        "        (?:[a-z]{2,}\\s+)*[A-Z][a-zA-Z'-]+,\n",
        "        \\s+\n",
        "        (?:[A-Z][a-zA-Z'-]+|[A-Z]\\.)\n",
        "        (?:\\s+(?:[A-Z][a-zA-Z'-]+|[A-Z]\\.))*\n",
        "    )*\n",
        "\n",
        "    # Optional \", and Last, First\"\n",
        "    (?:,\\s+and\\s+\n",
        "        (?:[a-z]{2,}\\s+)*[A-Z][a-zA-Z'-]+,\n",
        "        \\s+\n",
        "        (?:[A-Z][a-zA-Z'-]+|[A-Z]\\.)\n",
        "        (?:\\s+(?:[A-Z][a-zA-Z'-]+|[A-Z]\\.))*\n",
        "    )?\n",
        "\n",
        "    \\.?\n",
        "    $\n",
        "    \"\"\",\n",
        "    re.VERBOSE\n",
        ")\n",
        "\n",
        "def is_author_only_line(line: str) -> bool:\n",
        "    return bool(AUTHOR_LINE_RE.match(line.strip()))"
      ],
      "metadata": {
        "id": "d_W6lTIjSMLE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_authors(line: str) -> list[str]:\n",
        "    line = line.strip()\n",
        "    line = re.sub(r',?\\s*and\\s*$', '', line)\n",
        "    line = line.replace(', and ', ', ')\n",
        "\n",
        "    parts = [p.strip() for p in line.split(',') if p.strip()]\n",
        "\n",
        "    if len(parts) % 2 != 0:\n",
        "        # optional: log or inspect these cases\n",
        "        parts = parts[:-1]\n",
        "\n",
        "    return [\n",
        "        f\"{parts[i+1]} {parts[i]}\"\n",
        "        for i in range(0, len(parts), 2)\n",
        "    ]"
      ],
      "metadata": {
        "id": "QSvY9U3JSjbE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_authors_and_abstract_fallback(text: str):\n",
        "    \"\"\"\n",
        "    Handles cases where authors and abstract are on the same line.\n",
        "    \"\"\"\n",
        "    for match in AUTHOR_LINE_RE.finditer(text):\n",
        "        end = match.end()\n",
        "        authors = text[:end].strip()\n",
        "        abstract = text[end:].strip()\n",
        "        return authors, abstract\n",
        "    return None, None"
      ],
      "metadata": {
        "id": "VC0F2d2XPBvM"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rehyphenate_words(text, words_to_hyphenate):\n",
        "    for word, hyphenated_word in words_to_hyphenate:\n",
        "        text = text.replace(word, hyphenated_word)\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "npwIxgb9Yo2U"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_trailing_text(text):\n",
        "  no_trailing_junk = text.split(\".\")[:-1]\n",
        "\n",
        "  return \".\".join(no_trailing_junk) + \".\""
      ],
      "metadata": {
        "id": "GGh2K2HPGXMF"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text, words_to_hyphenate=None):\n",
        "    if not text:\n",
        "        return text\n",
        "\n",
        "    if words_to_hyphenate:\n",
        "      text = rehyphenate_words(text, words_to_hyphenate)\n",
        "\n",
        "    text = re.sub(r'`\"`\\s(.*?)\\s`\"`', r'\"\\1\"', text)  # Replace `\"` with \"\n",
        "                                                      # and getting rid of extra\n",
        "                                                      # space between the quotes\n",
        "                                                      # and the first and last words\n",
        "\n",
        "    text = re.sub(r' \\n\\n\\d{1,3} \\n\\n', ' ', text)  # Remove page breaks with page number\n",
        "    text = re.sub(r'\\n\\n\\d{2}', '', text)\n",
        "\n",
        "    text = re.sub(r'-\\s+(?!\\b(?:and|or)\\b)', '', text)  # Get rid of - and space after\n",
        "                                                        # unless word after is\n",
        "                                                        # \"and\" or \"or\"\n",
        "\n",
        "    text = text.strip()\n",
        "    text = fix_ligatures(text)\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "aq4f3JE9IgHD"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LIGATURE_MAP = {\n",
        "    \"ﬁ\": \"fi\", \"ﬂ\": \"fl\", \"ﬃ\": \"ffi\", \"ﬄ\": \"ffl\", \"ﬀ\": \"ff\", \"ﬅ\": \"ft\", \"ﬆ\": \"st\",\n",
        "    \"Æ\": \"ffi\", \"¨u\": \"ü\", \"¨a\": \"ä\", \"´e\": \"é\", \"`e\": \"è\", \"`a\": \"à\", \"¨o\": \"ö\",\n",
        "    \"˚a\": \"å\", \"c¸\": \"ç\", '“': '\"', '”': '\"', \"’\": \"'\", '˜n': 'ñ', 'ˇs': 'š',\n",
        "    \"âĂŸ\": \"'\", \"``\": '\"'\n",
        "}\n",
        "\n",
        "def fix_ligatures(text):\n",
        "    # Replace known ligatures\n",
        "    for bad, good in LIGATURE_MAP.items():\n",
        "        text = text.replace(bad, good)\n",
        "\n",
        "    # Replace any private-use ligature (common in PDFs)\n",
        "    cleaned_chars = []\n",
        "    for ch in text:\n",
        "        name = unicodedata.name(ch, \"\")\n",
        "        if \"LIGATURE\" in name.upper():\n",
        "            # Try to break it apart: remove spaces and lowercase\n",
        "            base = name.split(\"LIGATURE\")[-1]\n",
        "            base = base.replace(\" \", \"\").lower()\n",
        "            cleaned_chars.append(base)\n",
        "        else:\n",
        "            cleaned_chars.append(ch)\n",
        "\n",
        "    return \"\".join(cleaned_chars)"
      ],
      "metadata": {
        "id": "WLDsGBzsFnSz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checks if valid word using Zipf frequency\n",
        "def is_probably_valid(word, threshold=2.5):\n",
        "    return wordfreq.zipf_frequency(word, \"en\") > threshold  # smaller number cuts off\n",
        "                                                            # more words, bigger is\n",
        "                                                            # more lenient"
      ],
      "metadata": {
        "id": "7DrUdRHGgTrp"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Program\n",
        "\n",
        "138 entries total (4 plenary talks, 24 symposium talks, 88 talks, and 22 posters)\n",
        "\n",
        "Markdown shows bold and italic text here, but the extracted text doesn't show the authors. Author names are \"last name, first name.\" Also no affiliations listed.\n"
      ],
      "metadata": {
        "id": "EzyoCbvJK6js"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Grab text from the pdf"
      ],
      "metadata": {
        "id": "NY0NZXAh696-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "year = '2016'\n",
        "program = pymupdf.open(pdfs_path + f'smp{year}_program.pdf')"
      ],
      "metadata": {
        "id": "-iaeTkOjqA3-"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "program_text = pymupdf4llm.to_markdown(program)"
      ],
      "metadata": {
        "id": "GB3Wc1MBHp8X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d5a9438-788c-4ea4-ac89-441a842b9b85"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Document parser messages ===\n",
            "Full-page OCR on page.number=0/1.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "program_text[6_400:8_000]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "7-jva4kegu_-",
        "outputId": "33a04a8f-1616-4328-aca5-ab545f4b7b84"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'s section is automatically generated from the submission website and may not reflect recent updates, such as withdrawn contributions or changes in authorship. \\n\\nFirst appear the keynote addresses, then the symposium presentations, then the regular submitted presentations, and finally the posters. \\n\\n## Keynote Addresses \\n\\n## Digging Deeper into the Temporal Structure of the Mind \\n\\nAnderson, John R. \\n\\nNeural imaging can be used to identify the stages of mental processes.   We have used a combination of hidden semi-Markov models and multivariate pattern matching (HSMM-MVPA) to analyze MEG data from memory experiments.   The HSMM-MVPA methods are able to reveal brief bumps in the sensor data that mark the onset of different stages of processing. We used these bumps to isolate encoding, retrieval, decision, and response stages within single memory trials. The temporal distributions of these stages as well as the brain regions engaged indicate that the same stages occur in two rather different experiments (associative recognition of word pairs versus recall of arithmetic facts).  This new technique allows the retrieval stage to be isolated from the rest of a trial. This in turn allows us to test theoretical claims concerning the distribution of retrieval times and how they vary with condition. \\n\\n## Informing Cognitive Abstractions with Neurophysiology \\n\\nTurner, Brandon (William K. Estes Early Career Award Recipient) \\n\\nOur understanding of cognition has been advanced by two traditionally non-overlapping and noninteracting groups. Mathematical psychologists rely on behavioral data '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split text into presentation entries"
      ],
      "metadata": {
        "id": "1QnRE7dQuaDC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_abstracts = program_text.split('\\n\\n## Keynote Addresses ')[1] # this is where abstracts start\n",
        "split_abstracts = re.split(r'\\n\\n##', all_abstracts)\n",
        "abstract_entries = [entry.strip() for entry in split_abstracts if entry.strip()][:-1]"
      ],
      "metadata": {
        "id": "0xNg5F-Vn1kF"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "abstract_entries[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWkxOy-_N2h_",
        "outputId": "6841bfcb-80fb-4f54-c29f-02233eeb8ea7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Digging Deeper into the Temporal Structure of the Mind \\n\\nAnderson, John R. \\n\\nNeural imaging can be used to identify the stages of mental processes.   We have used a combination of hidden semi-Markov models and multivariate pattern matching (HSMM-MVPA) to analyze MEG data from memory experiments.   The HSMM-MVPA methods are able to reveal brief bumps in the sensor data that mark the onset of different stages of processing. We used these bumps to isolate encoding, retrieval, decision, and response stages within single memory trials. The temporal distributions of these stages as well as the brain regions engaged indicate that the same stages occur in two rather different experiments (associative recognition of word pairs versus recall of arithmetic facts).  This new technique allows the retrieval stage to be isolated from the rest of a trial. This in turn allows us to test theoretical claims concerning the distribution of retrieval times and how they vary with condition.',\n",
              " 'Informing Cognitive Abstractions with Neurophysiology \\n\\nTurner, Brandon (William K. Estes Early Career Award Recipient) \\n\\nOur understanding of cognition has been advanced by two traditionally non-overlapping and noninteracting groups. Mathematical psychologists rely on behavioral data to evaluate formal models of cognition, whereas cognitive neuroscientists rely on statistical models to understand patterns of neural activity, often without any attempt to make a connection to the mechanism supporting the computation. Both approaches suffer from critical limitations as a direct result of their focus on data at one level of analysis (cf. Marr, 1982), and these limitations have inspired researchers to attempt to combine both neural and behavioral measures in a cross-level integrative fashion. The importance of solving this problem has spawned several entirely new theoretical and statistical frameworks developed by both mathematical psychologists and cognitive neuroscientists. In this talk, I will discuss a recent approach called joint modeling that mutually constrains what we learn about the cognitive process from both the computational model and the neurophysiology. The central idea of this approach is to use the information in the neurophysiology to enhance or guide what the cognitive model says about the cognitive process of interest. I will highlight the utility of this approach in a variety of applications. \\n\\n7']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Find words to re-hyphenate"
      ],
      "metadata": {
        "id": "kLz8RAOqBM9Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pattern = re.compile(r'([A-Za-z]+)-\\n\\s*([A-Za-z]+)')\n",
        "possible_hyphenated_words = []\n",
        "\n",
        "counter = 0\n",
        "for p, page in enumerate(program[6:]):  # these are the pages with abstracts only\n",
        "  text = fix_ligatures(page.get_text('text'))\n",
        "  matches = pattern.findall(text)\n",
        "\n",
        "  for left, right in matches:\n",
        "    word = f\"{left}{right}\"\n",
        "    hyphenated_word = f\"{left}-{right}\"\n",
        "    if not is_probably_valid(word, threshold=2.8):\n",
        "      possible_hyphenated_words.append([word, hyphenated_word])\n",
        "\n",
        "      print(f\"{counter:>3}: Page {p+7:<3} {hyphenated_word:<30} {word}\")\n",
        "      counter += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMdLe69U7GMm",
        "outputId": "af579132-9351-4265-b7e1-a54d1694bf23"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  0: Page 7   non-interacting                noninteracting\n",
            "  1: Page 10  long-term                      longterm\n",
            "  2: Page 12  high-contrast                  highcontrast\n",
            "  3: Page 14  mind-wandering                 mindwandering\n",
            "  4: Page 19  long-range                     longrange\n",
            "  5: Page 21  well-recovered                 wellrecovered\n",
            "  6: Page 21  spatially-driven               spatiallydriven\n",
            "  7: Page 26  third-person                   thirdperson\n",
            "  8: Page 28  by-Default                     byDefault\n",
            "  9: Page 33  Long-Term                      LongTerm\n",
            " 10: Page 34  double-detection               doubledetection\n",
            " 11: Page 34  rate-distortion                ratedistortion\n",
            " 12: Page 36  single-region                  singleregion\n",
            " 13: Page 37  Multi-Attribute                MultiAttribute\n",
            " 14: Page 44  eye-movements                  eyemovements\n",
            " 15: Page 46  pre-programmed                 preprogrammed\n",
            " 16: Page 46  socio-cognitive                sociocognitive\n",
            " 17: Page 48  well-known                     wellknown\n",
            " 18: Page 49  spectro-temporal               spectrotemporal\n",
            " 19: Page 54  real-valued                    realvalued\n",
            " 20: Page 54  hill-climbing                  hillclimbing\n",
            " 21: Page 56  Garg-type                      Gargtype\n",
            " 22: Page 63  well-known                     wellknown\n",
            " 23: Page 64  Decision-Making                DecisionMaking\n",
            " 24: Page 71  by-moment                      bymoment\n",
            " 25: Page 72  discrete-state                 discretestate\n",
            " 26: Page 72  receiver-operating             receiveroperating\n",
            " 27: Page 77  non-alphabetic                 nonalphabetic\n",
            " 28: Page 78  decision-making                decisionmaking\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pick indices of words to rehyphenate\n",
        "indices = [(0, 14), 17, (19, 28)]\n",
        "words_to_hyphenate = [\n",
        "    possible_hyphenated_words[i]\n",
        "    for item in indices\n",
        "    for i in ([item] if isinstance(item, int) else range(*item))\n",
        "]"
      ],
      "metadata": {
        "id": "9SiZxnFeRsPA"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word, hyphenated_word in words_to_hyphenate:\n",
        "  print(f'{word:<30} {hyphenated_word}')"
      ],
      "metadata": {
        "id": "o7piQmxhVV4-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ecdf1d2-b9e1-4a76-90f5-6958f237fcd7"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noninteracting                 non-interacting\n",
            "longterm                       long-term\n",
            "highcontrast                   high-contrast\n",
            "mindwandering                  mind-wandering\n",
            "longrange                      long-range\n",
            "wellrecovered                  well-recovered\n",
            "spatiallydriven                spatially-driven\n",
            "thirdperson                    third-person\n",
            "byDefault                      by-Default\n",
            "LongTerm                       Long-Term\n",
            "doubledetection                double-detection\n",
            "ratedistortion                 rate-distortion\n",
            "singleregion                   single-region\n",
            "MultiAttribute                 Multi-Attribute\n",
            "wellknown                      well-known\n",
            "realvalued                     real-valued\n",
            "hillclimbing                   hill-climbing\n",
            "Gargtype                       Garg-type\n",
            "wellknown                      well-known\n",
            "DecisionMaking                 Decision-Making\n",
            "bymoment                       by-moment\n",
            "discretestate                  discrete-state\n",
            "receiveroperating              receiver-operating\n",
            "nonalphabetic                  non-alphabetic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sort authors, affiliations, title, and abstract"
      ],
      "metadata": {
        "id": "hvO659m7ufLG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parsed_entries = []\n",
        "temp_title = None\n",
        "\n",
        "for entry in abstract_entries:\n",
        "  number_of_splits = 1 if temp_title else 2\n",
        "  cleaned_entry = clean_text(entry, words_to_hyphenate)\n",
        "  entry_parts = cleaned_entry.split('\\n\\n', number_of_splits)\n",
        "\n",
        "  # If no split happened, maybe it's a title separated from authors and abstract\n",
        "  if len(entry_parts) == 1:\n",
        "    temp_title = cleaned_entry\n",
        "    continue\n",
        "\n",
        "  # If only 2 parts, maybe previous element was the title and this is just authors\n",
        "  # and abstract\n",
        "  if len(entry_parts) == 2:\n",
        "    if temp_title is None:\n",
        "        # Maybe no new lines between authors and abstract\n",
        "        authors, abstract = split_authors_and_abstract_fallback(entry_parts[1])\n",
        "        if authors is None:\n",
        "            continue\n",
        "        title = entry_parts[0].strip()\n",
        "    else:\n",
        "        title = temp_title\n",
        "        temp_title = None\n",
        "        authors, abstract = entry_parts\n",
        "\n",
        "  # Otherwise sort title, authors, abstract (no affiliations in this program)\n",
        "  elif len(entry_parts) == 3:\n",
        "    title, authors, abstract = entry_parts\n",
        "\n",
        "  cleaned_authors = parse_authors(authors.strip())\n",
        "  cleaned_authors = ', '.join(cleaned_authors)\n",
        "\n",
        "  cleaned_abstract = re.sub(r'\\s+', ' ', abstract.strip())\n",
        "  cleaned_abstract = remove_trailing_text(cleaned_abstract)\n",
        "\n",
        "  parsed_entries.append({\n",
        "    'year': year,\n",
        "    'author(s)': cleaned_authors,\n",
        "    'affiliation(s)': '',\n",
        "    'title': title.strip(),\n",
        "    'type': '',\n",
        "    'abstract': cleaned_abstract\n",
        "  })"
      ],
      "metadata": {
        "id": "rYSctzOMshAh"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parsed_entries[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Q6ocLO1sha_",
        "outputId": "1bd6881c-0d0a-4bc7-8b50-11f79c5e14fb"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'year': '2016',\n",
              "  'author(s)': 'John R. Anderson',\n",
              "  'affiliation(s)': '',\n",
              "  'title': 'Digging Deeper into the Temporal Structure of the Mind',\n",
              "  'type': '',\n",
              "  'abstract': 'Neural imaging can be used to identify the stages of mental processes. We have used a combination of hidden semi-Markov models and multivariate pattern matching (HSMM-MVPA) to analyze MEG data from memory experiments. The HSMM-MVPA methods are able to reveal brief bumps in the sensor data that mark the onset of different stages of processing. We used these bumps to isolate encoding, retrieval, decision, and response stages within single memory trials. The temporal distributions of these stages as well as the brain regions engaged indicate that the same stages occur in two rather different experiments (associative recognition of word pairs versus recall of arithmetic facts). This new technique allows the retrieval stage to be isolated from the rest of a trial. This in turn allows us to test theoretical claims concerning the distribution of retrieval times and how they vary with condition.'},\n",
              " {'year': '2016',\n",
              "  'author(s)': 'Brandon (William K. Estes Early Career Award Recipient) Turner',\n",
              "  'affiliation(s)': '',\n",
              "  'title': 'Informing Cognitive Abstractions with Neurophysiology',\n",
              "  'type': '',\n",
              "  'abstract': 'Our understanding of cognition has been advanced by two traditionally non-overlapping and non-interacting groups. Mathematical psychologists rely on behavioral data to evaluate formal models of cognition, whereas cognitive neuroscientists rely on statistical models to understand patterns of neural activity, often without any attempt to make a connection to the mechanism supporting the computation. Both approaches suffer from critical limitations as a direct result of their focus on data at one level of analysis (cf. Marr, 1982), and these limitations have inspired researchers to attempt to combine both neural and behavioral measures in a cross-level integrative fashion. The importance of solving this problem has spawned several entirely new theoretical and statistical frameworks developed by both mathematical psychologists and cognitive neuroscientists. In this talk, I will discuss a recent approach called joint modeling that mutually constrains what we learn about the cognitive process from both the computational model and the neurophysiology. The central idea of this approach is to use the information in the neurophysiology to enhance or guide what the cognitive model says about the cognitive process of interest. I will highlight the utility of this approach in a variety of applications.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create df and convert to csv"
      ],
      "metadata": {
        "id": "nKNl4pKw44lP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(parsed_entries, columns=[\"year\", \"author(s)\", \"affiliation(s)\", \"title\", \"type\", \"abstract\"])"
      ],
      "metadata": {
        "id": "5IEUDPyalsYH"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "AZRpkwpEJ6ut",
        "outputId": "718db2a2-6b1a-42d7-ac2f-34a8aef3f594"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   year                                          author(s) affiliation(s)  \\\n",
              "0  2016                                   John R. Anderson                  \n",
              "1  2016  Brandon (William K. Estes Early Career Award R...                  \n",
              "2  2016  Chris (William K. Estes Early Career Award Rec...                  \n",
              "3  2016                                                                     \n",
              "4  2016                                       Sam Gershman                  \n",
              "\n",
              "                                               title type  \\\n",
              "0  Digging Deeper into the Temporal Structure of ...        \n",
              "1  Informing Cognitive Abstractions with Neurophy...        \n",
              "2  A Less Simple, but More Complete Model of Choi...        \n",
              "3  **Symposium:** _**Integrating Prior Knowledge ...        \n",
              "4                               Memory and Structure        \n",
              "\n",
              "                                            abstract  \n",
              "0  Neural imaging can be used to identify the sta...  \n",
              "1  Our understanding of cognition has been advanc...  \n",
              "2  Brown & Heathcote's (2008) Linear Ballistic Ac...  \n",
              "3  Jacobs, Robert Visual working memory (VWM) hel...  \n",
              "4  When do we modify old memories, and when do we...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e39b12d6-dbd0-4fbe-9338-8020228b5a53\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>author(s)</th>\n",
              "      <th>affiliation(s)</th>\n",
              "      <th>title</th>\n",
              "      <th>type</th>\n",
              "      <th>abstract</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2016</td>\n",
              "      <td>John R. Anderson</td>\n",
              "      <td></td>\n",
              "      <td>Digging Deeper into the Temporal Structure of ...</td>\n",
              "      <td></td>\n",
              "      <td>Neural imaging can be used to identify the sta...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2016</td>\n",
              "      <td>Brandon (William K. Estes Early Career Award R...</td>\n",
              "      <td></td>\n",
              "      <td>Informing Cognitive Abstractions with Neurophy...</td>\n",
              "      <td></td>\n",
              "      <td>Our understanding of cognition has been advanc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2016</td>\n",
              "      <td>Chris (William K. Estes Early Career Award Rec...</td>\n",
              "      <td></td>\n",
              "      <td>A Less Simple, but More Complete Model of Choi...</td>\n",
              "      <td></td>\n",
              "      <td>Brown &amp; Heathcote's (2008) Linear Ballistic Ac...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2016</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>**Symposium:** _**Integrating Prior Knowledge ...</td>\n",
              "      <td></td>\n",
              "      <td>Jacobs, Robert Visual working memory (VWM) hel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2016</td>\n",
              "      <td>Sam Gershman</td>\n",
              "      <td></td>\n",
              "      <td>Memory and Structure</td>\n",
              "      <td></td>\n",
              "      <td>When do we modify old memories, and when do we...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e39b12d6-dbd0-4fbe-9338-8020228b5a53')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e39b12d6-dbd0-4fbe-9338-8020228b5a53 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e39b12d6-dbd0-4fbe-9338-8020228b5a53');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-5038f7c0-e435-4b8e-8219-caea6650f04f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5038f7c0-e435-4b8e-8219-caea6650f04f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-5038f7c0-e435-4b8e-8219-caea6650f04f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 128,\n  \"fields\": [\n    {\n      \"column\": \"year\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"2016\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"author(s)\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 124,\n        \"samples\": [\n          \"Glenn Gunzelmann\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"affiliation(s)\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 127,\n        \"samples\": [\n          \"A Factor-Analytic Modeling Approach to ERP Analysis\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"type\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"abstract\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 127,\n        \"samples\": [\n          \"Event-related potentials (ERPs) are recordings of electrical activity along the scalp time-locked to stimulus or response events. ERP studies provide important information about the chronology of mental processes. Because ERP signals are often rare and weak, relative to the large between-subject variability, significance testing of ERP differences across experimental conditions or detecting significant associations between ERPs and behavioral variables of interest poses major challenges for statistical analysis. Noting that ERP time dependence exhibits a block pattern suggesting strong local and long-range autocorrelation components, we propose a factor-analytical modeling of ERP dependence in the multivariate regression framework. Assuming a prior knowledge of the noise-alone intervals, an iterative estimation algorithm is derived jointly for the signal and noise processes. With simulated ERP signals embedded within real ERP noise, the proposed procedure is shown to outperform current methods and is more powerful at discovering time points at which ERPs are significantly different across conditions or are significantly associated with behavioral covariates. The ERP package in R implements the proposed procedure as well as various multiple comparison procedures for ERP analysis.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(f\"/content/drive/MyDrive/math_psych_work/csv/smp{year}_program.csv\", index=False)"
      ],
      "metadata": {
        "id": "65YB5d8WESQZ"
      },
      "execution_count": 33,
      "outputs": []
    }
  ]
}