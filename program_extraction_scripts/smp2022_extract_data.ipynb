{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lizaoh/smp_program_data/blob/main/smp2022_extract_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBXc6uieLC6Y"
      },
      "source": [
        "# Top of Script"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DW0MLlXyhw5G",
        "outputId": "a99ef90d-0166-4c39-8d68-ae9d45c41715"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iwaO2sqpib2d"
      },
      "outputs": [],
      "source": [
        "# Suppresses output from pip installs\n",
        "%%capture\n",
        "\n",
        "!pip install pymupdf\n",
        "!pip install pymupdf-layout\n",
        "!pip install pymupdf4llm\n",
        "!pip install wordfreq\n",
        "!pip install rapidfuzz\n",
        "import glob\n",
        "import os\n",
        "import pathlib\n",
        "import pymupdf\n",
        "import pymupdf.layout\n",
        "import pymupdf4llm\n",
        "import re\n",
        "import regex\n",
        "import pandas as pd\n",
        "import unicodedata\n",
        "import wordfreq\n",
        "from rapidfuzz import process, fuzz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9TqNj0OYhzgb"
      },
      "outputs": [],
      "source": [
        "pdfs_path = '/content/drive/MyDrive/math_psych_work/Conference Programs/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cK6Itu79JGuf"
      },
      "source": [
        "# Functions\n",
        "Created with help from GPT 5.2, but some are my own code just turned into a function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xXzXB83HNC3z"
      },
      "outputs": [],
      "source": [
        "LOCATIONS = [\n",
        "    'United States of America', 'United States', 'Switzerland', 'Japan', 'Bremen',\n",
        "    'Berlin, Germany', 'Heidelberg, Germany', 'Germany', 'Berlin', 'Norway',\n",
        "    'Turkey', 'Belgium', 'Italy', 'Israel', 'New Brunswick, New Jersey',\n",
        "    'Australia', 'The Netherlands', 'USA', 'US', 'Netherlands, The', 'Netherlands',\n",
        "    'United Kingdom', 'Singapore', 'France', 'Dayton OH', 'Dayton', 'India',\n",
        "    'Taiwan, Republic of China', 'Austria', 'Canada', 'Denmark', 'Spain',\n",
        "    'Edmonton', 'Bloomington, Indiana', 'Indiana', 'Russian Federation',\n",
        "    'University Park, Pennsylvania', 'California', 'San Francisco, California',\n",
        "    'Taipei, Taiwan', 'Charlottesville, Virginia', 'New York, New York',\n",
        "    'Toronto, Ontario', 'New Haven, Connecticut', 'Ann Arbor, Michigan', 'Ohio',\n",
        "    'Ottawa, Ontario', 'Houston, Texas', 'UK', 'New Brunswick, Piscataway, NJ',\n",
        "    'Finland', 'Iceland', 'Mexico', 'South Korea'\n",
        "]\n",
        "\n",
        "# compile once\n",
        "LOCATION_RE = re.compile(\n",
        "    r',\\s*(?:' + '|'.join(map(re.escape, LOCATIONS)) + r')\\b',\n",
        "    re.I\n",
        ")\n",
        "\n",
        "def remove_locations(entry: str) -> str:\n",
        "    return LOCATION_RE.sub('', entry).strip()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def reorder_author(author: str) -> str:\n",
        "    \"\"\"\n",
        "    Convert 'Last, First Middle' → 'First Middle Last'\n",
        "    \"\"\"\n",
        "    last, given = author.split(\",\", 1)\n",
        "    return f\"{given.strip()} {last.strip()}\""
      ],
      "metadata": {
        "id": "GksuBFM2A1nC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "CxB8mawESnT_"
      },
      "outputs": [],
      "source": [
        "def remove_page_break_text(text: str) -> str:\n",
        "    if not text:\n",
        "        return text\n",
        "\n",
        "    # Replaces with nothing for the rest\n",
        "    text = re.sub(r'\\n\\n\\d{1,3} \\n\\n', '\\n\\n', text)\n",
        "\n",
        "    return text.strip()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_picture_text(text: str) -> str:\n",
        "    if not text:\n",
        "        return text\n",
        "\n",
        "    text = re.sub(\n",
        "        r'''\n",
        "        \\n\\n\\*\\*==>\\spicture\\s\\[\\d{2}\\sx\\s\\d{2}\\]\\sintentionally\\somitted\\s<==\\*\\*\\n\\n\n",
        "        ''',\n",
        "        '\\n\\n',\n",
        "        text,\n",
        "        flags=re.VERBOSE\n",
        "    )\n",
        "\n",
        "    text = re.sub(\n",
        "        r'''\n",
        "        \\*\\*-----\\sStart\\sof\\spicture\\stext\\s-----\\*\\*\n",
        "        <br>\n",
        "        ''',\n",
        "        '',\n",
        "        text,\n",
        "        flags=re.VERBOSE\n",
        "    )\n",
        "\n",
        "    text = re.sub(\n",
        "        r'''\n",
        "        \\*\\*-----\\sEnd\\sof\\spicture\\stext\\s-----\\*\\*<br>\n",
        "        ''',\n",
        "        '##',\n",
        "        text,\n",
        "        flags=re.VERBOSE\n",
        "    )\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "OlRvTsrPqbPZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "aq4f3JE9IgHD"
      },
      "outputs": [],
      "source": [
        "def clean_text(text, fix_whitespace=False, delete_whitespace=False):\n",
        "    if not text:\n",
        "        return text\n",
        "\n",
        "    text = fix_ligatures(text)\n",
        "    text = remove_page_break_text(text)\n",
        "    # text = remove_picture_text(text)  # there's only on entry with picture\n",
        "                                        # omitted text and the format is a little different\n",
        "\n",
        "    # # Gets rid of breaks in titles\n",
        "    # text = re.sub(r'\\*\\*\\s\\n\\n##\\s\\*\\*', ' ', text)\n",
        "\n",
        "    if fix_whitespace:\n",
        "      text = re.sub(r'\\n\\s+', '\\n\\n', text)\n",
        "\n",
        "    if delete_whitespace:\n",
        "      text = re.sub(r'\\s{2,}', ' ', text)\n",
        "\n",
        "    text = text.strip()\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "WLDsGBzsFnSz"
      },
      "outputs": [],
      "source": [
        "LIGATURE_MAP = {\n",
        "    \"ﬁ\": \"fi\", \"ﬂ\": \"fl\", \"ﬃ\": \"ffi\", \"ﬄ\": \"ffl\", \"ﬀ\": \"ff\", \"ﬅ\": \"ft\", \"ﬆ\": \"st\",\n",
        "    \"Æ\": \"ffi\", \"¨u\": \"ü\", \"¨a\": \"ä\", \"´e\": \"é\", \"`e\": \"è\", \"`a\": \"à\", \"¨o\": \"ö\",\n",
        "    \"˚a\": \"å\", \"c¸\": \"ç\", '“': '\"', '”': '\"', \"’\": \"'\", '˜n': 'ñ', 'ˇs': 'š',\n",
        "    \"âĂŸ\": \"'\", \"``\": '\"', \"↵\": \"ff\", \"✏\": \"ffl\", \"‘\": \"'\"\n",
        "}\n",
        "\n",
        "def fix_ligatures(text):\n",
        "    # Replace known ligatures\n",
        "    for bad, good in LIGATURE_MAP.items():\n",
        "        text = text.replace(bad, good)\n",
        "\n",
        "    # Replace any private-use ligature (common in PDFs)\n",
        "    cleaned_chars = []\n",
        "    for ch in text:\n",
        "        name = unicodedata.name(ch, \"\")\n",
        "        if \"LIGATURE\" in name.upper():\n",
        "            # Try to break it apart: remove spaces and lowercase\n",
        "            base = name.split(\"LIGATURE\")[-1]\n",
        "            base = base.replace(\" \", \"\").lower()\n",
        "            cleaned_chars.append(base)\n",
        "        else:\n",
        "            cleaned_chars.append(ch)\n",
        "\n",
        "    return \"\".join(cleaned_chars)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def rehyphenate_words(text, words_to_hyphenate):\n",
        "    for word, hyphenated_word in words_to_hyphenate:\n",
        "        text = text.replace(word, hyphenated_word)\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "hNTyPQzW06Ko"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checks if valid word using Zipf frequency\n",
        "def is_probably_valid(word, threshold=2.5):\n",
        "    return wordfreq.zipf_frequency(word, \"en\") > threshold  # smaller number cuts off\n",
        "                                                            # more words, bigger is\n",
        "                                                            # more lenient"
      ],
      "metadata": {
        "id": "BZn089Q_06l2"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzyoCbvJK6js"
      },
      "source": [
        "# Program\n",
        "\n",
        "93 entries total (47 talks, 16 fast talks, 9 extended abstracts, and 21 full paper abstracts)\n",
        "\n",
        "Has justified text so need to check hyphenated words at line breaks, affiliations are listed after names after an en dash. Some authors don't have affiliation listed.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "-iaeTkOjqA3-"
      },
      "outputs": [],
      "source": [
        "year = '2022'\n",
        "file_path = pdfs_path + f'smp{year}_program.pdf'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NY0NZXAh696-"
      },
      "source": [
        "## Grab text from the pdf\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "program = pymupdf.open(file_path)   # original PDF\n",
        "program_text = pymupdf4llm.to_markdown(program)"
      ],
      "metadata": {
        "id": "UC8tgNIEt3yJ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "program_text[44_200:46_000]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "bjapdcOFt7BZ",
        "outputId": "27f6c7bf-9f1a-4f2f-cd1d-47fcd99defaa"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'*‘Talk’ abstracts** \\n\\n## **Hybrid-similarity exemplar model for predicting individual-item recognition in a high-dimensional category domain** \\n\\nParticipants learned to classify a set of rock images into geologically-defined science categories. We then investigated the nature of their category-based memory representations by collecting old-new recognition data in a subsequent transfer phase. An exemplar model provided better qualitative accounts of the old-new recognition data than did a prototype or clustering model. However, to account for the variability in recognition probabilities among the old training items themselves, a hybrid-similarity exemplar model was needed that took account of distinctive features present in the items. The study is among the first to use computational models for making detailed quantitative predictions of old-new recognition probabilities for individual items embedded in complex, high-dimensional similarity spaces. \\n\\n**Nosofsky, Robert M.** _Indiana University_ \\n\\n**Meagher, Brian** _Indiana University Bloomington_ \\n\\nSession: _Memory and learning_ – live on Monday, July 11, at 15:00 EDT \\n\\n## **A validation study of paired-word recognition models** \\n\\nHow do people recognize objects they have encountered previously? Cognitive models of recognition memory aim to explain overt behavior (e.g., recognizing an object) using latent psychological processes (e.g., true recognition and pure guessing). Validation studies assess whether the mechanisms underlying cognitive models properly reflect the psychological processes they aim to explain. The present study provides such a validation study for models describing paired-word recognition using selective-influence manipulations. \\n\\nIn a paired-word recognition task, people have to provide a simultaneous'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Find words to re-hyphenate"
      ],
      "metadata": {
        "id": "kLz8RAOqBM9Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pattern = re.compile(r'([A-Za-z]+)-\\n\\s*([A-Za-z]+)')\n",
        "possible_hyphenated_words = []\n",
        "\n",
        "counter = 0\n",
        "for p, page in enumerate(program[28:]):  # these are the pages with abstracts only\n",
        "  text = fix_ligatures(page.get_text('text'))\n",
        "  matches = pattern.findall(text)\n",
        "\n",
        "  for left, right in matches:\n",
        "    word = f\"{left}{right}\"\n",
        "    hyphenated_word = f\"{left}-{right}\"\n",
        "    if not is_probably_valid(word, threshold=2.8):\n",
        "      possible_hyphenated_words.append([word, hyphenated_word])\n",
        "\n",
        "      print(f\"{counter:>3}: Page {p+29:<3} {hyphenated_word:<30} {word}\")\n",
        "      counter += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMdLe69U7GMm",
        "outputId": "8aed7d86-9eb5-40d1-d819-fb5a23b3e0dc"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  0: Page 29  exem-plar                      exemplar\n",
            "  1: Page 29  base-rate                      baserate\n",
            "  2: Page 29  multidimen-sional              multidimensional\n",
            "  3: Page 32  di-mensionality                dimensionality\n",
            "  4: Page 32  jumping-to                     jumpingto\n",
            "  5: Page 33  au-tomates                     automates\n",
            "  6: Page 33  conceptual-izations            conceptualizations\n",
            "  7: Page 33  topic-neutral                  topicneutral\n",
            "  8: Page 34  sub-tractive                   subtractive\n",
            "  9: Page 34  an-thropometrics               anthropometrics\n",
            " 10: Page 35  aggre-gating                   aggregating\n",
            " 11: Page 36  Electroencephalog-raphy        Electroencephalography\n",
            " 12: Page 37  distri-butional                distributional\n",
            " 13: Page 37  elec-troencephalography        electroencephalography\n",
            " 14: Page 37  gen-erative                    generative\n",
            " 15: Page 37  elec-tromyographical           electromyographical\n",
            " 16: Page 37  between-condition              betweencondition\n",
            " 17: Page 39  value-based                    valuebased\n",
            " 18: Page 43  Atten-tional                   Attentional\n",
            " 19: Page 43  re-analysis                    reanalysis\n",
            " 20: Page 49  plau-sibly                     plausibly\n",
            " 21: Page 53  quan-tile                      quantile\n",
            " 22: Page 54  iden-tifiability               identifiability\n",
            " 23: Page 55  Queue-ing                      Queueing\n",
            " 24: Page 57  re-pulsion                     repulsion\n",
            " 25: Page 57  multi-attribute                multiattribute\n",
            " 26: Page 59  Valence-Weighted               ValenceWeighted\n",
            " 27: Page 59  larger-later                   largerlater\n",
            " 28: Page 61  item-specific                  itemspecific\n",
            " 29: Page 61  per-turbations                 perturbations\n",
            " 30: Page 63  psychome-tric                  psychometric\n",
            " 31: Page 64  ex-plorative                   explorative\n",
            " 32: Page 68  best-performing                bestperforming\n",
            " 33: Page 68  Representa-tional              Representational\n",
            " 34: Page 69  mc-stan                        mcstan\n",
            " 35: Page 75  fine-grained                   finegrained\n",
            " 36: Page 75  syl-logistic                   syllogistic\n",
            " 37: Page 75  quanti-fiers                   quantifiers\n",
            " 38: Page 75  gen-eralizability              generalizability\n",
            " 39: Page 75  Heuris-tics                    Heuristics\n",
            " 40: Page 77  phono-logical                  phonological\n",
            " 41: Page 80  declar-ative                   declarative\n",
            " 42: Page 80  decision-making                decisionmaking\n",
            " 43: Page 81  ref-erential                   referential\n",
            " 44: Page 83  Parasura-man                   Parasuraman\n",
            " 45: Page 83  argumenta-tion                 argumentation\n",
            " 46: Page 83  at-tentional                   attentional\n",
            " 47: Page 84  jumping-to                     jumpingto\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pick indices of words to rehyphenate\n",
        "indices = [1, 4, 7, 16, 17, (25, 28), 32, 34, 35, 42, 47]\n",
        "words_to_hyphenate = [\n",
        "    possible_hyphenated_words[i]\n",
        "    for item in indices\n",
        "    for i in ([item] if isinstance(item, int) else range(*item))\n",
        "]"
      ],
      "metadata": {
        "id": "9SiZxnFeRsPA"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word, hyphenated_word in words_to_hyphenate:\n",
        "  print(f'{word:<30} {hyphenated_word}')"
      ],
      "metadata": {
        "id": "o7piQmxhVV4-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20c82802-e224-42cc-aa7c-f77ff0f40931"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "baserate                       base-rate\n",
            "jumpingto                      jumping-to\n",
            "topicneutral                   topic-neutral\n",
            "betweencondition               between-condition\n",
            "valuebased                     value-based\n",
            "multiattribute                 multi-attribute\n",
            "ValenceWeighted                Valence-Weighted\n",
            "largerlater                    larger-later\n",
            "bestperforming                 best-performing\n",
            "mcstan                         mc-stan\n",
            "finegrained                    fine-grained\n",
            "decisionmaking                 decision-making\n",
            "jumpingto                      jumping-to\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split up into talk entries"
      ],
      "metadata": {
        "id": "ROGXQjnEA01_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "program_abstracts_start = program_text.split('‘Talk’ abstracts** \\n\\n## ')[1]\n",
        "\n",
        "# Rehyphenate words that need hyphen at line breaks\n",
        "program_abstracts_start = rehyphenate_words(program_abstracts_start, words_to_hyphenate)\n",
        "\n",
        "# Gets rid of page break and pictured omitted text\n",
        "program_abstracts_start = clean_text(program_abstracts_start, fix_whitespace=True)\n",
        "\n",
        "# Splits each abstract entry\n",
        "abstract_entries = re.split(r'EDT\\s*##\\s(?=\\*\\*)', program_abstracts_start)[:-1]"
      ],
      "metadata": {
        "id": "9e6YaskncXBU"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splits up entries containing multiple entries\n",
        "final_abstract_entries = []\n",
        "\n",
        "for entry in abstract_entries:\n",
        "  if re.search(r\"##\\s+\\*\\*([^,\\n]+)\\*\\*\", entry):\n",
        "    new_split_entry = re.split(r\"\\s\\n\\s*##\\s+(?=\\*\\*[^,\\n]+\\*\\*)\", entry)\n",
        "    final_abstract_entries.extend(new_split_entry)\n",
        "  else:\n",
        "    final_abstract_entries.append(entry)\n",
        "\n",
        "# Filters out a heading for extended abstracts\n",
        "final_abstract_entries = [entry for entry in final_abstract_entries if len(entry) > 100]"
      ],
      "metadata": {
        "id": "WugLdMNSbeb_"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_abstract_entries[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdovRRX2fXPp",
        "outputId": "6ec663b3-a721-42ee-b778-90a45eb82d01"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['**Hybrid-similarity exemplar model for predicting individual-item recognition in a high-dimensional category domain** \\n\\nParticipants learned to classify a set of rock images into geologically-defined science categories. We then investigated the nature of their category-based memory representations by collecting old-new recognition data in a subsequent transfer phase. An exemplar model provided better qualitative accounts of the old-new recognition data than did a prototype or clustering model. However, to account for the variability in recognition probabilities among the old training items themselves, a hybrid-similarity exemplar model was needed that took account of distinctive features present in the items. The study is among the first to use computational models for making detailed quantitative predictions of old-new recognition probabilities for individual items embedded in complex, high-dimensional similarity spaces. \\n\\n**Nosofsky, Robert M.** _Indiana University_ \\n\\n**Meagher, Brian** _Indiana University Bloomington_ \\n\\nSession: _Memory and learning_ – live on Monday, July 11, at 15:00 ',\n",
              " '**A validation study of paired-word recognition models** \\n\\nHow do people recognize objects they have encountered previously? Cognitive models of recognition memory aim to explain overt behavior (e.g., recognizing an object) using latent psychological processes (e.g., true recognition and pure guessing). Validation studies assess whether the mechanisms underlying cognitive models properly reflect the psychological processes they aim to explain. The present study provides such a validation study for models describing paired-word recognition using selective-influence manipulations. \\n\\nIn a paired-word recognition task, people have to provide a simultaneous categorization of randomly paired words as either both being previously studied, only one word being previously studied, or both words being new. To selectively manipulate mnemonic processes, we implemented a strength manipulation (Experiment 1) in which certain words were presented more often during study. To influence decisional processes, we relied on two different base-rate manipulation, one of response categories (Experiment 2), in which certain pair types more frequent during the test phase, and one of overall target and lure frequencies (Experiment 3). We assessed the validity of general recognition theory, a multidimensional signal detection theory model, and the paired two-high threshold model, a discrete-state model. \\n\\nIn line with the literature on single-word recognition, both models captured the strength manipulation using parameters associated with mnemonic processes. Surprisingly, both of the base-rate manipulations were captured by mnemonic parameters as well, even though the extant literature would suggest a selectively influence on parameters associated with decisional processes. We discuss implications for model validity and future directions in paired-word recognition. \\n\\n**Voormann, Anne** \\n\\n**Spektor, Mikhail** _University of Warwick_ \\n\\n**Klauer, Christoph** _University of Freiburg, Germany_ \\n\\nSession: _Memory and learning_ – live on Monday, July 11, at 15:00 ']"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvO659m7ufLG"
      },
      "source": [
        "## Sort authors, affiliations, title, and abstract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "rYSctzOMshAh"
      },
      "outputs": [],
      "source": [
        "parsed_entries = []\n",
        "\n",
        "for e, entry in enumerate(final_abstract_entries):\n",
        "  title, rest_of_entry = re.split(r'\\n\\n', entry, maxsplit=1)\n",
        "\n",
        "  # Title is the only bolded text\n",
        "  title = re.search(r'\\*\\*(.*?)\\*\\*', title).group().strip('**')\n",
        "\n",
        "  no_session = re.sub(\n",
        "      r'\\n\\nSession:\\s*(.*?)\\s*\\d{2}:\\d{2}\\s(EDT)?\\s?',\n",
        "      '',\n",
        "      rest_of_entry)\n",
        "\n",
        "  authors = re.findall(r'\\*\\*([^,\\n*]+,[^,\\n*]+)\\*\\*', no_session)\n",
        "  authors = [reorder_author(author) for author in authors]\n",
        "\n",
        "  affiliations = re.findall(r'_(.*?)_', no_session)\n",
        "  affiliations = [remove_locations(affiliation) for affiliation in affiliations]\n",
        "  if len(set(affiliations)) == 1:\n",
        "    final_affiliations = affiliations[0]\n",
        "  else:\n",
        "    final_affiliations = '; '.join(affiliations)\n",
        "\n",
        "  abstract = re.sub(r'\\*\\*[^,\\n*]+,[^,\\n*]+\\*\\*', '', no_session)\n",
        "  abstract = re.sub(r'_(.*?)_', '', abstract)\n",
        "\n",
        "  parsed_entries.append({\n",
        "      'year': year,\n",
        "      'author(s)': ', '.join(authors),\n",
        "      'affiliation(s)': final_affiliations,\n",
        "      'title': title,\n",
        "      'type': '',\n",
        "      'abstract': clean_text(abstract, delete_whitespace=True)\n",
        "  })"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parsed_entries[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AiS86P0CzCwv",
        "outputId": "5fc765a8-e99a-4716-afb3-05a2697d4ea5"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'year': '2022',\n",
              "  'author(s)': 'Robert M. Nosofsky, Brian Meagher',\n",
              "  'affiliation(s)': 'Indiana University; Indiana University Bloomington',\n",
              "  'title': 'Hybrid-similarity exemplar model for predicting individual-item recognition in a high-dimensional category domain',\n",
              "  'type': '',\n",
              "  'abstract': 'Participants learned to classify a set of rock images into geologically-defined science categories. We then investigated the nature of their category-based memory representations by collecting old-new recognition data in a subsequent transfer phase. An exemplar model provided better qualitative accounts of the old-new recognition data than did a prototype or clustering model. However, to account for the variability in recognition probabilities among the old training items themselves, a hybrid-similarity exemplar model was needed that took account of distinctive features present in the items. The study is among the first to use computational models for making detailed quantitative predictions of old-new recognition probabilities for individual items embedded in complex, high-dimensional similarity spaces.'},\n",
              " {'year': '2022',\n",
              "  'author(s)': 'Anne Voormann, Mikhail Spektor, Christoph Klauer',\n",
              "  'affiliation(s)': 'University of Warwick; University of Freiburg',\n",
              "  'title': 'A validation study of paired-word recognition models',\n",
              "  'type': '',\n",
              "  'abstract': 'How do people recognize objects they have encountered previously? Cognitive models of recognition memory aim to explain overt behavior (e.g., recognizing an object) using latent psychological processes (e.g., true recognition and pure guessing). Validation studies assess whether the mechanisms underlying cognitive models properly reflect the psychological processes they aim to explain. The present study provides such a validation study for models describing paired-word recognition using selective-influence manipulations. In a paired-word recognition task, people have to provide a simultaneous categorization of randomly paired words as either both being previously studied, only one word being previously studied, or both words being new. To selectively manipulate mnemonic processes, we implemented a strength manipulation (Experiment 1) in which certain words were presented more often during study. To influence decisional processes, we relied on two different base-rate manipulation, one of response categories (Experiment 2), in which certain pair types more frequent during the test phase, and one of overall target and lure frequencies (Experiment 3). We assessed the validity of general recognition theory, a multidimensional signal detection theory model, and the paired two-high threshold model, a discrete-state model. In line with the literature on single-word recognition, both models captured the strength manipulation using parameters associated with mnemonic processes. Surprisingly, both of the base-rate manipulations were captured by mnemonic parameters as well, even though the extant literature would suggest a selectively influence on parameters associated with decisional processes. We discuss implications for model validity and future directions in paired-word recognition.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKNl4pKw44lP"
      },
      "source": [
        "# Create df and convert to csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "5IEUDPyalsYH"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(parsed_entries, columns=[\"year\", \"author(s)\", \"affiliation(s)\", \"title\", \"type\", \"abstract\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "AZRpkwpEJ6ut",
        "outputId": "9c04acb3-7b96-4b3e-98c1-c79081cd2526"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   year                                         author(s)  \\\n",
              "0  2022                 Robert M. Nosofsky, Brian Meagher   \n",
              "1  2022  Anne Voormann, Mikhail Spektor, Christoph Klauer   \n",
              "2  2022           Madison Paron, James Paron, Mike Kahana   \n",
              "3  2022     Yiyang Chen, Mario Peruggia, Trisha Van Zandt   \n",
              "4  2022                                        Rahul Bhui   \n",
              "\n",
              "                                      affiliation(s)  \\\n",
              "0  Indiana University; Indiana University Bloomin...   \n",
              "1      University of Warwick; University of Freiburg   \n",
              "2                         University of Pennsylvania   \n",
              "3  University of Kansas; The Ohio State Universit...   \n",
              "4  Massachusetts Institute of Technology; Harvard...   \n",
              "\n",
              "                                               title type  \\\n",
              "0  Hybrid-similarity exemplar model for predictin...        \n",
              "1  A validation study of paired-word recognition ...        \n",
              "2      A context-based model of recall and decisions        \n",
              "3  Mutual interference in working memory updating...        \n",
              "4  Ambiguity and confirmation bias in reward lear...        \n",
              "\n",
              "                                            abstract  \n",
              "0  Participants learned to classify a set of rock...  \n",
              "1  How do people recognize objects they have enco...  \n",
              "2  Existing models of memory posit separate proce...  \n",
              "3  We built a hierarchical Bayesian model for the...  \n",
              "4  We tend to interpret feedback in ways that con...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bff2f2e5-6983-4ee1-9570-84b5bb25c482\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>author(s)</th>\n",
              "      <th>affiliation(s)</th>\n",
              "      <th>title</th>\n",
              "      <th>type</th>\n",
              "      <th>abstract</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2022</td>\n",
              "      <td>Robert M. Nosofsky, Brian Meagher</td>\n",
              "      <td>Indiana University; Indiana University Bloomin...</td>\n",
              "      <td>Hybrid-similarity exemplar model for predictin...</td>\n",
              "      <td></td>\n",
              "      <td>Participants learned to classify a set of rock...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2022</td>\n",
              "      <td>Anne Voormann, Mikhail Spektor, Christoph Klauer</td>\n",
              "      <td>University of Warwick; University of Freiburg</td>\n",
              "      <td>A validation study of paired-word recognition ...</td>\n",
              "      <td></td>\n",
              "      <td>How do people recognize objects they have enco...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2022</td>\n",
              "      <td>Madison Paron, James Paron, Mike Kahana</td>\n",
              "      <td>University of Pennsylvania</td>\n",
              "      <td>A context-based model of recall and decisions</td>\n",
              "      <td></td>\n",
              "      <td>Existing models of memory posit separate proce...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2022</td>\n",
              "      <td>Yiyang Chen, Mario Peruggia, Trisha Van Zandt</td>\n",
              "      <td>University of Kansas; The Ohio State Universit...</td>\n",
              "      <td>Mutual interference in working memory updating...</td>\n",
              "      <td></td>\n",
              "      <td>We built a hierarchical Bayesian model for the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2022</td>\n",
              "      <td>Rahul Bhui</td>\n",
              "      <td>Massachusetts Institute of Technology; Harvard...</td>\n",
              "      <td>Ambiguity and confirmation bias in reward lear...</td>\n",
              "      <td></td>\n",
              "      <td>We tend to interpret feedback in ways that con...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bff2f2e5-6983-4ee1-9570-84b5bb25c482')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bff2f2e5-6983-4ee1-9570-84b5bb25c482 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bff2f2e5-6983-4ee1-9570-84b5bb25c482');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 93,\n  \"fields\": [\n    {\n      \"column\": \"year\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"2022\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"author(s)\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 90,\n        \"samples\": [\n          \"Matthias Gondan, Ayca Altay, Melike Baykal-Gursoy\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"affiliation(s)\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 86,\n        \"samples\": [\n          \"Carleton University\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 93,\n        \"samples\": [\n          \"Attacker behavior detection in critical infrastructure\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"type\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"abstract\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 93,\n        \"samples\": [\n          \"Lone-actor (LA) terrorism has been one of the rising security threats of the last decade. The LA behavior and characteristics research has produced valuable information on demographics, classifications, and warning signs. Nonetheless, commonality among these characteristics does not imply similar outcomes for different attacks and the incident-scene behavior varies. Since the security footage videos of LA attacks are not publicly available, associating incident-scene behavior to the early and preparatory attacker behavior is a challenging research field. Serious games have been utilized to evaluate mitigation strategies to a natural disaster. At GRIST Lab at Rutgers University, we design virtual games to simulate real-world conditions to observe an attacker's reaction to incident-scene dynamics. This study aims to identify short-term target and route selection decisions of the attacker through the data obtained from a virtual game; and in turn to develop better first responder allocation strategies against LA attacks. We implement time-series clustering and classification methods to the behavior differences between an attacker and other civilians based on spatio-temporal data. The findings indicate that these methods will be instrumental in developing LA detection and capture strategies.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 101
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "65YB5d8WESQZ"
      },
      "outputs": [],
      "source": [
        "df.to_csv(f\"/content/drive/MyDrive/math_psych_work/csv/smp{year}_program.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOhhTZac+hUE/uYiaax+n+n",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}