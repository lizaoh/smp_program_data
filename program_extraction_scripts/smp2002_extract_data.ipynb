{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNbslqAuAsoBH/BmV659nCm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lizaoh/smp_program_data/blob/main/smp2002_extract_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Top of Script"
      ],
      "metadata": {
        "id": "KBXc6uieLC6Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DW0MLlXyhw5G",
        "outputId": "8ccf6402-0076-4199-97c0-80bb7131a11a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymupdf\n",
        "!pip install rapidfuzz\n",
        "import glob\n",
        "import os\n",
        "import pathlib\n",
        "import pymupdf\n",
        "import re\n",
        "import pandas as pd\n",
        "import unicodedata\n",
        "from rapidfuzz import process, fuzz"
      ],
      "metadata": {
        "id": "iwaO2sqpib2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92ff3ea4-ecba-404b-d5fb-70cd01125e3a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymupdf in /usr/local/lib/python3.12/dist-packages (1.26.7)\n",
            "Requirement already satisfied: rapidfuzz in /usr/local/lib/python3.12/dist-packages (3.14.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pdfs_path = '/content/drive/MyDrive/math_psych_work/Conference Programs/'"
      ],
      "metadata": {
        "id": "9TqNj0OYhzgb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions\n",
        "Created with help from GPT 5.1, but some are my own code just turned into a function."
      ],
      "metadata": {
        "id": "cK6Itu79JGuf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TITLE_SECTION_MARKERS = ['   ', '---']\n",
        "TALK_TITLE_MARKERS = [r\"\\s{7,}\", r\"[1-9]\\.\"]  # at least 7 consecutive whitespace or numbered entry\n",
        "\n",
        "def group_abstract_entries(text):\n",
        "    entries = []\n",
        "\n",
        "    for page_text in text:\n",
        "      entries_split = re.split(r\"\\n\\s*\\n(?=\\s*(?:[A-Z][\\sA-Za-z]|[0-9]\\.))\", page_text)\n",
        "      for e, entry in enumerate(entries_split):\n",
        "        if entry.isspace():\n",
        "          continue\n",
        "\n",
        "        # Adds each entry\n",
        "        if entry and any(re.search(marker, entry) for marker in TALK_TITLE_MARKERS):\n",
        "          if '---' in entry:\n",
        "            continue\n",
        "          else:\n",
        "            entries.append(entry.strip())\n",
        "\n",
        "        # Adds rest of abstract text broken by page break to its abstract entry\n",
        "        if entry:\n",
        "          first_char = entry.strip()[0]\n",
        "          # if first word is lowercase\n",
        "          if first_char.islower():\n",
        "            entries[-1] += ' ' + entry.strip()\n",
        "          # if first word is uppercase\n",
        "          elif entries and first_char.isupper():\n",
        "            if not any(marker in entry for marker in TITLE_SECTION_MARKERS):\n",
        "              if entries[-1].split(' ')[-1] == 'University':\n",
        "                join_string = ' \\n'\n",
        "              else:\n",
        "                join_string = ' '\n",
        "              entries[-1] += join_string + entry.strip()\n",
        "\n",
        "    return entries"
      ],
      "metadata": {
        "id": "jQRDWC2LGcyC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def group_program_entries(text):\n",
        "    entries = []\n",
        "\n",
        "    # Protect closing parenthesis\n",
        "    text = [entry.replace(')\\n', '))\\n') for entry in text]\n",
        "    # Get rid of period after \"vs\"\n",
        "    text = [entry.replace(' vs. ', ' vs ') for entry in text]\n",
        "\n",
        "    # Split on time\n",
        "    page_entries = []\n",
        "    for page_text in text:\n",
        "        page_entries.extend(\n",
        "            re.split(r\"\\d{1,2}:\\d{2}\\n\", page_text)\n",
        "        )\n",
        "\n",
        "    # Split on ')\\\\n'\n",
        "    second_page_entries = []\n",
        "    for entry in page_entries:\n",
        "        second_page_entries.extend(entry.split(')\\n'))\n",
        "\n",
        "    # Split on numbered list items\n",
        "    final_page_entries = []\n",
        "    for entry in second_page_entries:\n",
        "        final_page_entries.extend(\n",
        "            re.split(r\"[1-9]\\.\\n\", entry)\n",
        "        )\n",
        "\n",
        "    # Filter empties and \"coffee break\" lines\n",
        "    for entry in final_page_entries:\n",
        "        if entry.strip() and \"COFFEE BREAK\" not in entry:\n",
        "            entries.append(entry)\n",
        "\n",
        "    return entries"
      ],
      "metadata": {
        "id": "iqEvV73h5aOd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AFFILIATION_KEYWORDS = [\n",
        "    \"University\", \"College\", \"Department\", \"Center\", \"Institute\",\n",
        "    \"Laboratory\", \"School\", \"Hospital\", \"UC\", \"Centre\", \"Research\",\n",
        "    \"Corporation\", \"Defence\", \"Université\"\n",
        "]\n",
        "\n",
        "def parse_program_entry(year, entry_text):\n",
        "    \"\"\"\n",
        "    Parse a program entry into title, authors, affiliations.\n",
        "    Returns dict with string fields:\n",
        "      - title\n",
        "      - authors (comma-separated)\n",
        "      - affiliations (semicolon-separated)\n",
        "    \"\"\"\n",
        "\n",
        "    # ---------- 1. Normalize ----------\n",
        "    text = entry_text.strip()\n",
        "\n",
        "    # ---------- 2. Extract title ----------\n",
        "    m = re.search(r\"[.?]\", text)\n",
        "    if not m:\n",
        "        return None\n",
        "\n",
        "    title_raw = text[:m.start()]\n",
        "    remainder = text[m.start() + 1:]\n",
        "\n",
        "    title = \" \".join(title_raw.split())\n",
        "\n",
        "    # ---------- 3. Extract affiliations ----------\n",
        "    affiliations = re.findall(r\"\\(([^()]*)\\)\", remainder)\n",
        "\n",
        "    affiliations = [\n",
        "        \" \".join(a.replace(\"\\n\", \" \").split())\n",
        "        for a in affiliations\n",
        "        if any(k in a for k in AFFILIATION_KEYWORDS)\n",
        "    ]\n",
        "\n",
        "    affiliations_str = \"; \".join(affiliations)\n",
        "\n",
        "    # Remove affiliations from remainder\n",
        "    remainder = re.sub(r\"\\([^()]*\\)\", \"\", remainder)\n",
        "\n",
        "    # ---------- 4. Extract authors ----------\n",
        "    remainder = remainder.replace(\"\\n\", \" \")\n",
        "    remainder = remainder.replace(\"&\", \",\")\n",
        "    remainder = re.sub(r\"\\s+\", \" \", remainder)\n",
        "\n",
        "    author_candidates = re.split(r\",|\\band\\b\", remainder)\n",
        "\n",
        "    authors = []\n",
        "    for a in author_candidates:\n",
        "        a = a.strip()\n",
        "        if not a:\n",
        "            continue\n",
        "        if any(k in a for k in AFFILIATION_KEYWORDS):\n",
        "            continue\n",
        "\n",
        "        tokens = a.split()\n",
        "        cap_tokens = sum(t[0].isupper() for t in tokens if t)\n",
        "\n",
        "        if cap_tokens >= 2:\n",
        "            authors.append(a)\n",
        "\n",
        "    authors_str = \", \".join(authors)\n",
        "\n",
        "    return {\n",
        "        \"year\": year,\n",
        "        \"author(s)\": authors_str,\n",
        "        \"affiliation(s)\": affiliations_str,\n",
        "        \"title\": title\n",
        "    }"
      ],
      "metadata": {
        "id": "t0fWgJSqXKPJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(s):\n",
        "    return re.sub(r'\\s+', ' ', s.lower()).strip()"
      ],
      "metadata": {
        "id": "W6PGuwc6e3jZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_author_line(line: str) -> bool:\n",
        "    return (\n",
        "        ',' in line and\n",
        "        any(word in line for word in AFFILIATION_KEYWORDS)\n",
        "    )"
      ],
      "metadata": {
        "id": "BLXw1xIdhDx0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_abstract_line(line: str) -> bool:\n",
        "    return proportion_titlecase(line) < 0.5 and len(line.split()) >= 6"
      ],
      "metadata": {
        "id": "8amFsUsxhEkD"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_abstract_entry(text: str) -> dict:\n",
        "    lines = [ln.strip() for ln in text.split('\\n') if ln.strip()]\n",
        "\n",
        "    author_idx = None\n",
        "    for i, line in enumerate(lines):\n",
        "        if is_author_line(line) and ':' not in line:\n",
        "            author_idx = i\n",
        "            break\n",
        "\n",
        "    if author_idx is None:\n",
        "        return {}\n",
        "\n",
        "    # ---- TITLE ----\n",
        "    title_lines = lines[:author_idx]\n",
        "    title = ' '.join(title_lines)\n",
        "\n",
        "    # ---- AUTHORS + AFFILIATIONS ----\n",
        "    auth_aff_lines = []\n",
        "    i = author_idx\n",
        "    while i < len(lines) and not is_abstract_line(lines[i]):\n",
        "        auth_aff_lines.append(lines[i])\n",
        "        i += 1\n",
        "\n",
        "    auth_aff = ' '.join(auth_aff_lines)\n",
        "\n",
        "    # ---- ABSTRACT ----\n",
        "    abstract_lines = lines[i:]\n",
        "    abstract = ' '.join(abstract_lines)\n",
        "\n",
        "    return {\n",
        "        \"title\": title,\n",
        "        \"authors_affiliations\": auth_aff,\n",
        "        \"abstract\": abstract\n",
        "    }"
      ],
      "metadata": {
        "id": "kr-RUPMJhHqt"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def proportion_titlecase(s: str) -> float:\n",
        "    \"\"\"Return proportion of words starting with uppercase letters.\"\"\"\n",
        "    words = re.findall(r\"[A-Za-z][A-Za-z'-]*\", s)  # ignore numbers/punctuation\n",
        "    if not words:\n",
        "        return 0\n",
        "\n",
        "    upper = sum(1 for w in words if w[0].isupper())\n",
        "    return upper / len(words)"
      ],
      "metadata": {
        "id": "-mgxmoNwMEhs"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LIGATURE_MAP = {\n",
        "    \"ﬁ\": \"fi\",\n",
        "    \"ﬂ\": \"fl\",\n",
        "    \"ﬃ\": \"ffi\",\n",
        "    \"ﬄ\": \"ffl\",\n",
        "    \"ﬀ\": \"ff\",\n",
        "    \"ﬅ\": \"ft\",\n",
        "    \"ﬆ\": \"st\",\n",
        "    \"Æ\": 'ffi'\n",
        "}\n",
        "\n",
        "def fix_ligatures(text):\n",
        "    # Replace known ligatures\n",
        "    for bad, good in LIGATURE_MAP.items():\n",
        "        text = text.replace(bad, good)\n",
        "\n",
        "    # Replace any private-use ligature (common in PDFs)\n",
        "    cleaned_chars = []\n",
        "    for ch in text:\n",
        "        name = unicodedata.name(ch, \"\")\n",
        "        if \"LIGATURE\" in name.upper():\n",
        "            # Try to break it apart: remove spaces and lowercase\n",
        "            base = name.split(\"LIGATURE\")[-1]\n",
        "            base = base.replace(\" \", \"\").lower()\n",
        "            cleaned_chars.append(base)\n",
        "        else:\n",
        "            cleaned_chars.append(ch)\n",
        "\n",
        "    return \"\".join(cleaned_chars)"
      ],
      "metadata": {
        "id": "lKQylTz7C6eC"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Program\n",
        "\n",
        "There are 61 entries total. 59 abstracts (50 talks and 9 posters) and 2 plenary talks.\n",
        "\n"
      ],
      "metadata": {
        "id": "EzyoCbvJK6js"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Grab text from the pdfs"
      ],
      "metadata": {
        "id": "NY0NZXAh696-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "year = '2002'\n",
        "abstracts = pymupdf.open(pdfs_path + f'smp{year}_abstracts.pdf')\n",
        "program = pymupdf.open(pdfs_path + f'smp{year}_program.pdf')\n",
        "\n",
        "# For these, indices are text[page_num][piece_of_text]\n",
        "abstract_text = []\n",
        "program_text = []\n",
        "\n",
        "# Grabs text from each page in the doc\n",
        "for page in abstracts:\n",
        "  abstract_text.append(page.get_text('text'))\n",
        "\n",
        "for page in program[1:]:  # first page is just title page / some info\n",
        "  program_text.append(page.get_text('text'))"
      ],
      "metadata": {
        "id": "-iaeTkOjqA3-"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "program_text[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "UgZrQ3xXWd4-",
        "outputId": "35344922-cf1b-49d1-d460-c74149cedae4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"3/11/2021\\nProgram for the 35th Annual Meeting of the Society for Mathematical Psychology\\nweb.archive.org/web/20070708163316/http://www.users.muohio.edu/thomasrd/program.html\\n2/5\\nMeeting Site \\nMarcum Conference Center \\nEvents \\nThursday Night Reception at the Tavern at the Inn, 7 pm - 10pm.\\nPoster Session and Reception (Cash Bar), Friday Evening 5:30-7pm, Heritage Room at Shriver Center.\\nBanquet 7pm (following Poster Session), Heritage Room at Shriver Center. \\nFriday, July 26, 2002\\n_\\nSensory Processing and Perception\\nAnalysis of Response Time and Accuracy Models\\nof Psychophysics and Decision\\n8:30\\nSpike Timing Variability Limits Motion\\nDiscrimination. Joe Lappin*, Bart Borghuis**,\\nDuje Tadin*, Martin Lankheet**, and Wim van\\nde Grind**\\n(*Vanderbilt Vision Research Center, Vanderbilt\\nUniversity and ** Helmholtz Institute, Utrecht\\nUniversity)\\nAdaptive Techniques for Response Latencies.\\nRagnar Steingrimsson (UC- Irvine)\\n8:55\\nDominance times for binocular rivalry and\\nambiguous motion rivalry share individual\\ndiffferences. Keith D. White (University of\\nFlorida), John D. Pettigrew (University of\\nQueensland)\\nTesting Capacity Hypotheses: Applying\\nProportional Hazards and Frailty Models.\\nMichael J. Wenger, Christof Schuster (University of\\nNotre Dame), James T. Townsend (Indiana\\nUniversity)\\n9:20\\nPerspicuity without depth: 'mental rotation'\\nas correlation. Keith K. Niall (Defence R&D\\nCanada, Toronto)\\nBayesian Analysis of Response Times. T. Van\\nZandt, M. Peruggia, & M. Chen (Ohio State\\nUniversity)\\n9:45\\nA new look at the perception of relative mass\\nin colliding balls: Invariants, similarity, and\\nrules. Andrew L. Cohen (Indiana University)\\nOn Implications of Near Equivalent Models for\\nSignal Detection Theory and Memory Research.\\nLawrence T. DeCarlo (Columbia University)\\n10:10\\nCOFFEE BREAK\\nCOFFEE BREAK\\nCategorization\\nModel Selection and Issues in Statistics\\n10:35\\nA Biologically Plausible Model of Rule-Based\\nCategory Learning. Shawn W. Ell, F. Gregory\\nAshby, Vivian Valentin, Michael Casale, Emily\\nInformation Matrix Goodness-of-Fit Tests for\\nExplanatory Logistic Regression and Neural\\nNets. Richard Golden (University of Texas at\\nDallas), Steven Henley (Martingale Research\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "abstract_text[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "inYGb_fBWb2U",
        "outputId": "306323e3-6308-43d7-e70a-9ddcf43bccfa"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" \\n \\nConference Abstracts \\n35th Annual Meeting of the Society for Mathematical Psychology  \\nJuly 25-28, 2002, Miami University, Oxford, OH \\n \\n \\nSensory Processing and Perception---------------------------------------------------------- \\n \\nSpike Timing Variability Limits Motion Discrimination                           Friday 8:30 a.m. \\n Joe Lappin, Duje Tadin, Vanderbilt University, Bart Borghuis, Martin Lankheet, Wim van de Grind, \\nUtrecht University  \\nThe visible structure of moving stimulus patterns must be fully represented by responses of retinal \\nneurons.  (Entropy cannot be reduced by later cortical mechanisms and cognitive processes.)  Because \\nmotion perception depends on correlations between multiple input signals, discriminations of moving \\nimages should be limited by the temporal reliability of spike trains at the first stages of vision.  To study the \\ntemporal limits of early visual information, we have (a) developed a method to describe the timing \\nvariability of spike trains, (b) evaluated the spike timing variability of cat retinal ganglion and LGN cells in \\nresponse to moving gratings of varied contrast and temporal frequency, (c) analyzed these temporal effects \\non a simple correlational model of motion discrimination, and (d) compared these effects with temporal \\nthresholds for human motion discrimination.  We find that human motion discriminations are temporally \\nlimited in the same manner as the spike trains of early visual neurons.  These and other recent results \\nindicate that limits on the statistical information for motion discrimination are primarily temporal.  \\nEvidently, visually effective motion information is not determined solely by 'motion energy'. \\n \\nDominance times for binocular rivalry and ambiguous motion                 Friday 8:55 a.m. \\n rivalry share individual diffferences \\nKeith D. White, University of Florida, John D. Pettigrew, University of Queensland \\n        Binocular rivalry can be produced by stimulating the left eye with a small patch of drifting vertical \\nlines while stimulating the right eye with a patch of drifting horizontal lines (or vice versa). Typically these \\ndo not fuse perceptually into a plaid; rather, one pattern dominates perception for a few seconds then the \\nother pattern dominates for a few seconds.  Perceptual alternation can also occur absent dichoptic \\nstimulation when viewing an ambiguous figure or ambiguous motion stimuli. It is theoretically important to \\nestablish whether binocular rivalry is closely related to the latter perceptual alternations because in them the \\nconditions do not exist to support competition between monocular neural channels, an explanation \\nproposed for binocular rivalry. Thirty-one undergraduates participated in two 20 min sessions of binocular \\nrivalry and two 20 min sessions of observing Bonneh's reversible sphere, non-dichoptic ambiguous depth \\nfrom motion stimulus.   Mean dominance times were correlated across subjects (motion dominance period \\n= 3.2 * rivalry dominance period, r = .43, p = .01). For most subjects, the individual's histogram of motion \\ndominance periods was similar in shape to his/her own histogram of rivalry dominance periods (average r2 \\n= .39), about 75% as good a predictor as the test-retest reliability between sessions with the same stimuli \\n(average r2 = .52), and a better predictor than any other subjects' histograms (average r2 = .27). These \\ncovariations within individuals in binocular rivalry and in non-dichoptic ambiguous motion rivalry cannot \\nbe explained by competition between monocular neural channels. \\n \\nPerspicuity without depth: 'mental rotation' as correlation                          Friday 9:20 a.m. \\nKeith K. Niall, Defence R&D Canada (Toronto) \\nIn some typical judgments on perspective pictures in psychological experiments, response times \\nmay have less to do with angular orientation in depth than with properties measured in the picture plane \\nitself.  Degree of compression, not depicted angular difference, accounts for changes in comparison \\nresponse times for planar shapes in perspective.  This degree of compression can be evaluated by an \\noperation in the picture plane.  The degree of compression is given by the cosine of the angle of the shape \\nto the picture plane; an elementary operation on the shape's silhouette can be applied to compute that value \\nsquared. The operation is the autocorrelation of the silhouette, and the mean value of that autocorrelation is \\nthe desired value.  The same rule predicts response times in a very different situation, when untrained \\nobservers identify photographs of aircraft models as F-15 or F-16 jets.  A simple rule is found to fit \\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clean up entries"
      ],
      "metadata": {
        "id": "pkzhINNv7fHN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Abstract"
      ],
      "metadata": {
        "id": "3XZtY1-NbO3Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "abstract_strings = []\n",
        "removed_lines = []\n",
        "for page_text in abstract_text:\n",
        "    # Break up characters like 'fi', 'ffi', 'fl', etc.\n",
        "    cleaned_entry = fix_ligatures(page_text)\n",
        "\n",
        "    if not cleaned_entry:  # if no words in entry\n",
        "      continue\n",
        "\n",
        "    abstract_strings.append(cleaned_entry)"
      ],
      "metadata": {
        "id": "4Iry9Dey-BHy"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "abstract_strings[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "ccZIdxFD4YZB",
        "outputId": "f2b6f952-2b62-4147-9c01-c8da81a3b9ba"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" \\n \\nConference Abstracts \\n35th Annual Meeting of the Society for Mathematical Psychology  \\nJuly 25-28, 2002, Miami University, Oxford, OH \\n \\n \\nSensory Processing and Perception---------------------------------------------------------- \\n \\nSpike Timing Variability Limits Motion Discrimination                           Friday 8:30 a.m. \\n Joe Lappin, Duje Tadin, Vanderbilt University, Bart Borghuis, Martin Lankheet, Wim van de Grind, \\nUtrecht University  \\nThe visible structure of moving stimulus patterns must be fully represented by responses of retinal \\nneurons.  (Entropy cannot be reduced by later cortical mechanisms and cognitive processes.)  Because \\nmotion perception depends on correlations between multiple input signals, discriminations of moving \\nimages should be limited by the temporal reliability of spike trains at the first stages of vision.  To study the \\ntemporal limits of early visual information, we have (a) developed a method to describe the timing \\nvariability of spike trains, (b) evaluated the spike timing variability of cat retinal ganglion and LGN cells in \\nresponse to moving gratings of varied contrast and temporal frequency, (c) analyzed these temporal effects \\non a simple correlational model of motion discrimination, and (d) compared these effects with temporal \\nthresholds for human motion discrimination.  We find that human motion discriminations are temporally \\nlimited in the same manner as the spike trains of early visual neurons.  These and other recent results \\nindicate that limits on the statistical information for motion discrimination are primarily temporal.  \\nEvidently, visually effective motion information is not determined solely by 'motion energy'. \\n \\nDominance times for binocular rivalry and ambiguous motion                 Friday 8:55 a.m. \\n rivalry share individual diffferences \\nKeith D. White, University of Florida, John D. Pettigrew, University of Queensland \\n        Binocular rivalry can be produced by stimulating the left eye with a small patch of drifting vertical \\nlines while stimulating the right eye with a patch of drifting horizontal lines (or vice versa). Typically these \\ndo not fuse perceptually into a plaid; rather, one pattern dominates perception for a few seconds then the \\nother pattern dominates for a few seconds.  Perceptual alternation can also occur absent dichoptic \\nstimulation when viewing an ambiguous figure or ambiguous motion stimuli. It is theoretically important to \\nestablish whether binocular rivalry is closely related to the latter perceptual alternations because in them the \\nconditions do not exist to support competition between monocular neural channels, an explanation \\nproposed for binocular rivalry. Thirty-one undergraduates participated in two 20 min sessions of binocular \\nrivalry and two 20 min sessions of observing Bonneh's reversible sphere, non-dichoptic ambiguous depth \\nfrom motion stimulus.   Mean dominance times were correlated across subjects (motion dominance period \\n= 3.2 * rivalry dominance period, r = .43, p = .01). For most subjects, the individual's histogram of motion \\ndominance periods was similar in shape to his/her own histogram of rivalry dominance periods (average r2 \\n= .39), about 75% as good a predictor as the test-retest reliability between sessions with the same stimuli \\n(average r2 = .52), and a better predictor than any other subjects' histograms (average r2 = .27). These \\ncovariations within individuals in binocular rivalry and in non-dichoptic ambiguous motion rivalry cannot \\nbe explained by competition between monocular neural channels. \\n \\nPerspicuity without depth: 'mental rotation' as correlation                          Friday 9:20 a.m. \\nKeith K. Niall, Defence R&D Canada (Toronto) \\nIn some typical judgments on perspective pictures in psychological experiments, response times \\nmay have less to do with angular orientation in depth than with properties measured in the picture plane \\nitself.  Degree of compression, not depicted angular difference, accounts for changes in comparison \\nresponse times for planar shapes in perspective.  This degree of compression can be evaluated by an \\noperation in the picture plane.  The degree of compression is given by the cosine of the angle of the shape \\nto the picture plane; an elementary operation on the shape's silhouette can be applied to compute that value \\nsquared. The operation is the autocorrelation of the silhouette, and the mean value of that autocorrelation is \\nthe desired value.  The same rule predicts response times in a very different situation, when untrained \\nobservers identify photographs of aircraft models as F-15 or F-16 jets.  A simple rule is found to fit \\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Groups text in between lines that start w/ words from left column (\"Poster\", \"Fri\", etc.)\n",
        "fixed_abstract_strings = group_abstract_entries(abstract_strings)"
      ],
      "metadata": {
        "id": "EsSJwcqGFVgV"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fixed_abstract_strings[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "-IWDVMKj0ksi",
        "outputId": "2dd958f0-1513-4ed9-de6f-1a15727d5866"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Spike Timing Variability Limits Motion Discrimination                           Friday 8:30 a.m. \\n Joe Lappin, Duje Tadin, Vanderbilt University, Bart Borghuis, Martin Lankheet, Wim van de Grind, \\nUtrecht University  \\nThe visible structure of moving stimulus patterns must be fully represented by responses of retinal \\nneurons.  (Entropy cannot be reduced by later cortical mechanisms and cognitive processes.)  Because \\nmotion perception depends on correlations between multiple input signals, discriminations of moving \\nimages should be limited by the temporal reliability of spike trains at the first stages of vision.  To study the \\ntemporal limits of early visual information, we have (a) developed a method to describe the timing \\nvariability of spike trains, (b) evaluated the spike timing variability of cat retinal ganglion and LGN cells in \\nresponse to moving gratings of varied contrast and temporal frequency, (c) analyzed these temporal effects \\non a simple correlational model of motion discrimination, and (d) compared these effects with temporal \\nthresholds for human motion discrimination.  We find that human motion discriminations are temporally \\nlimited in the same manner as the spike trains of early visual neurons.  These and other recent results \\nindicate that limits on the statistical information for motion discrimination are primarily temporal.  \\nEvidently, visually effective motion information is not determined solely by 'motion energy'.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Program"
      ],
      "metadata": {
        "id": "eM46ZMKL6Iwq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "program_strings = []\n",
        "for page_text in program_text:\n",
        "    # Break up characters like 'fi', 'ffi', 'fl', etc.\n",
        "    cleaned_entry = fix_ligatures(page_text)\n",
        "\n",
        "    if not cleaned_entry:  # if no words in entry\n",
        "      continue\n",
        "\n",
        "    # program_strings.append(cleaned_entry)\n",
        "\n",
        "    lines = cleaned_entry.split('\\n')\n",
        "    no_header_text = lines[4:]\n",
        "\n",
        "    program_strings.append('\\n'.join(no_header_text))  # turns the word list back into one string"
      ],
      "metadata": {
        "id": "MCLcim8L6IIG"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "program_strings[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "Ox8ROB1B6VWK",
        "outputId": "2503a5d9-7fe8-4cca-ed44-7a2d6e68e748"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Meeting Site \\nMarcum Conference Center \\nEvents \\nThursday Night Reception at the Tavern at the Inn, 7 pm - 10pm.\\nPoster Session and Reception (Cash Bar), Friday Evening 5:30-7pm, Heritage Room at Shriver Center.\\nBanquet 7pm (following Poster Session), Heritage Room at Shriver Center. \\nFriday, July 26, 2002\\n_\\nSensory Processing and Perception\\nAnalysis of Response Time and Accuracy Models\\nof Psychophysics and Decision\\n8:30\\nSpike Timing Variability Limits Motion\\nDiscrimination. Joe Lappin*, Bart Borghuis**,\\nDuje Tadin*, Martin Lankheet**, and Wim van\\nde Grind**\\n(*Vanderbilt Vision Research Center, Vanderbilt\\nUniversity and ** Helmholtz Institute, Utrecht\\nUniversity)\\nAdaptive Techniques for Response Latencies.\\nRagnar Steingrimsson (UC- Irvine)\\n8:55\\nDominance times for binocular rivalry and\\nambiguous motion rivalry share individual\\ndiffferences. Keith D. White (University of\\nFlorida), John D. Pettigrew (University of\\nQueensland)\\nTesting Capacity Hypotheses: Applying\\nProportional Hazards and Frailty Models.\\nMichael J. Wenger, Christof Schuster (University of\\nNotre Dame), James T. Townsend (Indiana\\nUniversity)\\n9:20\\nPerspicuity without depth: 'mental rotation'\\nas correlation. Keith K. Niall (Defence R&D\\nCanada, Toronto)\\nBayesian Analysis of Response Times. T. Van\\nZandt, M. Peruggia, & M. Chen (Ohio State\\nUniversity)\\n9:45\\nA new look at the perception of relative mass\\nin colliding balls: Invariants, similarity, and\\nrules. Andrew L. Cohen (Indiana University)\\nOn Implications of Near Equivalent Models for\\nSignal Detection Theory and Memory Research.\\nLawrence T. DeCarlo (Columbia University)\\n10:10\\nCOFFEE BREAK\\nCOFFEE BREAK\\nCategorization\\nModel Selection and Issues in Statistics\\n10:35\\nA Biologically Plausible Model of Rule-Based\\nCategory Learning. Shawn W. Ell, F. Gregory\\nAshby, Vivian Valentin, Michael Casale, Emily\\nInformation Matrix Goodness-of-Fit Tests for\\nExplanatory Logistic Regression and Neural\\nNets. Richard Golden (University of Texas at\\nDallas), Steven Henley (Martingale Research\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fixed_program_strings = group_program_entries(program_strings)"
      ],
      "metadata": {
        "id": "dQZblZ4O7uX7"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fixed_program_strings[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJmuayjx_M4D",
        "outputId": "42c9019b-5fe5-4b14-d280-2127fcb1d5fa"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Meeting Site \\nMarcum Conference Center \\nEvents \\nThursday Night Reception at the Tavern at the Inn, 7 pm - 10pm.\\nPoster Session and Reception (Cash Bar), Friday Evening 5:30-7pm, Heritage Room at Shriver Center.\\nBanquet 7pm (following Poster Session), Heritage Room at Shriver Center. \\nFriday, July 26, 2002\\n_\\nSensory Processing and Perception\\nAnalysis of Response Time and Accuracy Models\\nof Psychophysics and Decision\\n',\n",
              " 'Spike Timing Variability Limits Motion\\nDiscrimination. Joe Lappin*, Bart Borghuis**,\\nDuje Tadin*, Martin Lankheet**, and Wim van\\nde Grind**\\n(*Vanderbilt Vision Research Center, Vanderbilt\\nUniversity and ** Helmholtz Institute, Utrecht\\nUniversity)',\n",
              " 'Adaptive Techniques for Response Latencies.\\nRagnar Steingrimsson (UC- Irvine)',\n",
              " 'Dominance times for binocular rivalry and\\nambiguous motion rivalry share individual\\ndiffferences. Keith D. White (University of\\nFlorida), John D. Pettigrew (University of\\nQueensland)',\n",
              " 'Testing Capacity Hypotheses: Applying\\nProportional Hazards and Frailty Models.\\nMichael J. Wenger, Christof Schuster (University of\\nNotre Dame), James T. Townsend (Indiana\\nUniversity)']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Collect title, authors, and affiliations from program pdf"
      ],
      "metadata": {
        "id": "9tr-8JiMbh-D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parsed_entries = []\n",
        "\n",
        "for entry in fixed_program_strings:\n",
        "    parsed = parse_program_entry(year, entry)\n",
        "    if parsed:\n",
        "        parsed_entries.append(parsed)"
      ],
      "metadata": {
        "id": "e7Tf9HTf8b-F"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parsed_entries[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Czq6auCqViWO",
        "outputId": "7a843293-1761-457e-8e43-f7615d522120"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'year': '2002',\n",
              "  'author(s)': 'Poster Session, Friday Evening 5:30-7pm, 2002 _ Sensory Processing, Perception Analysis of Response Time, Accuracy Models of Psychophysics',\n",
              "  'affiliation(s)': '',\n",
              "  'title': 'Meeting Site Marcum Conference Center Events Thursday Night Reception at the Tavern at the Inn, 7 pm - 10pm'},\n",
              " {'year': '2002',\n",
              "  'author(s)': 'Joe Lappin*, Bart Borghuis**, Duje Tadin*, Martin Lankheet**, Wim van de Grind**',\n",
              "  'affiliation(s)': '*Vanderbilt Vision Research Center, Vanderbilt University and ** Helmholtz Institute, Utrecht University',\n",
              "  'title': 'Spike Timing Variability Limits Motion Discrimination'},\n",
              " {'year': '2002',\n",
              "  'author(s)': 'Ragnar Steingrimsson',\n",
              "  'affiliation(s)': 'UC- Irvine',\n",
              "  'title': 'Adaptive Techniques for Response Latencies'},\n",
              " {'year': '2002',\n",
              "  'author(s)': 'Keith D. White, John D. Pettigrew',\n",
              "  'affiliation(s)': 'University of Florida; University of Queensland',\n",
              "  'title': 'Dominance times for binocular rivalry and ambiguous motion rivalry share individual diffferences'},\n",
              " {'year': '2002',\n",
              "  'author(s)': 'Michael J. Wenger, Christof Schuster, James T. Townsend',\n",
              "  'affiliation(s)': 'University of Notre Dame; Indiana University',\n",
              "  'title': 'Testing Capacity Hypotheses: Applying Proportional Hazards and Frailty Models'}]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Collect abstracts and convert to df"
      ],
      "metadata": {
        "id": "HHgTGFhK0zlM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lookup = {normalize(e[\"title\"]): e for e in parsed_entries}\n",
        "titles = list(lookup.keys())\n",
        "\n",
        "SIM_THRESHOLD = 70  # conservative\n",
        "\n",
        "for entry in fixed_abstract_strings:\n",
        "    parsed = parse_abstract_entry(entry)\n",
        "\n",
        "    title = parsed.get(\"title\")\n",
        "    if not title:\n",
        "        continue\n",
        "\n",
        "    key = normalize(title)\n",
        "\n",
        "    # 1. Exact match\n",
        "    if key in lookup:\n",
        "        lookup[key][\"abstract\"] = parsed[\"abstract\"]\n",
        "        continue\n",
        "\n",
        "    # 2. Fuzzy fallback\n",
        "    match = process.extractOne(\n",
        "        key,\n",
        "        titles,\n",
        "        scorer=fuzz.token_sort_ratio\n",
        "    )\n",
        "\n",
        "    if match:\n",
        "        matched_key, score, _ = match\n",
        "        if score >= SIM_THRESHOLD:\n",
        "            lookup[matched_key][\"abstract\"] = parsed[\"abstract\"]"
      ],
      "metadata": {
        "id": "T-IG2ZbJRglt"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parsed_entries[1:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0d7_V6oRuUR",
        "outputId": "d78004ff-c8f7-430f-a306-9c696c49851c"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'year': '2002',\n",
              "  'author(s)': 'Joe Lappin*, Bart Borghuis**, Duje Tadin*, Martin Lankheet**, Wim van de Grind**',\n",
              "  'affiliation(s)': '*Vanderbilt Vision Research Center, Vanderbilt University and ** Helmholtz Institute, Utrecht University',\n",
              "  'title': 'Spike Timing Variability Limits Motion Discrimination',\n",
              "  'abstract': \"The visible structure of moving stimulus patterns must be fully represented by responses of retinal neurons.  (Entropy cannot be reduced by later cortical mechanisms and cognitive processes.)  Because motion perception depends on correlations between multiple input signals, discriminations of moving images should be limited by the temporal reliability of spike trains at the first stages of vision.  To study the temporal limits of early visual information, we have (a) developed a method to describe the timing variability of spike trains, (b) evaluated the spike timing variability of cat retinal ganglion and LGN cells in response to moving gratings of varied contrast and temporal frequency, (c) analyzed these temporal effects on a simple correlational model of motion discrimination, and (d) compared these effects with temporal thresholds for human motion discrimination.  We find that human motion discriminations are temporally limited in the same manner as the spike trains of early visual neurons.  These and other recent results indicate that limits on the statistical information for motion discrimination are primarily temporal. Evidently, visually effective motion information is not determined solely by 'motion energy'.\"},\n",
              " {'year': '2002',\n",
              "  'author(s)': 'Ragnar Steingrimsson',\n",
              "  'affiliation(s)': 'UC- Irvine',\n",
              "  'title': 'Adaptive Techniques for Response Latencies',\n",
              "  'abstract': 'Using adaptive procedures to estimate selective points on a psychometric curve rather than the often more complex task of modeling the entire function has become a common practice in psychophysical studies.  In many cases, having estimates for these points provides sufficient information for the researcher and hence represents savings in time and other resources.  Research using latency variables does not readily lend itself to this methodology since response time is regarded as an inherently dependent variable. However, using a well-established inverse relationship that obtains between response times and stimulus intensity, a formal  argument is developed showing that it is possible to determine the stimulus intensity that gives rise to a  fixed median response time—or that of any fixed percentile.  A proposed method employs adaptive techniques to estimate this intensity for a fixed response time and percentile.  In addition to the formal development, the feasibility of using any of three adaptive techniques—transformed Up-Down, Robbins- Monroe process, and PEST—are evaluated using extensive computer simulations. The results of the simulations demonstrate that acceptable results can be obtained in reasonable time and that a particular application of the transformed Up-Down procedure produces the best results.  Finally, this method is used in a simple empirical situation, the results of which are consistent with both theoretically predicted outcomes and the results of the simulations.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create df and convert to csv"
      ],
      "metadata": {
        "id": "BbZgJXHOEapk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Skip first entry because extraneous text\n",
        "df = pd.DataFrame(parsed_entries[1:], columns=[\"year\", \"author(s)\", \"affiliation(s)\", \"title\", \"abstract\"])"
      ],
      "metadata": {
        "id": "5IEUDPyalsYH"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "AZRpkwpEJ6ut",
        "outputId": "240ee159-a68b-43b7-9199-11a8fbad1135"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   year                                          author(s)  \\\n",
              "0  2002  Joe Lappin*, Bart Borghuis**, Duje Tadin*, Mar...   \n",
              "1  2002                               Ragnar Steingrimsson   \n",
              "2  2002                  Keith D. White, John D. Pettigrew   \n",
              "3  2002  Michael J. Wenger, Christof Schuster, James T....   \n",
              "4  2002                                     Keith K. Niall   \n",
              "\n",
              "                                      affiliation(s)  \\\n",
              "0  *Vanderbilt Vision Research Center, Vanderbilt...   \n",
              "1                                         UC- Irvine   \n",
              "2    University of Florida; University of Queensland   \n",
              "3       University of Notre Dame; Indiana University   \n",
              "4                        Defence R&D Canada, Toronto   \n",
              "\n",
              "                                               title  \\\n",
              "0  Spike Timing Variability Limits Motion Discrim...   \n",
              "1         Adaptive Techniques for Response Latencies   \n",
              "2  Dominance times for binocular rivalry and ambi...   \n",
              "3  Testing Capacity Hypotheses: Applying Proporti...   \n",
              "4  Perspicuity without depth: 'mental rotation' a...   \n",
              "\n",
              "                                            abstract  \n",
              "0  The visible structure of moving stimulus patte...  \n",
              "1  Using adaptive procedures to estimate selectiv...  \n",
              "2  Binocular rivalry can be produced by stimulati...  \n",
              "3  Proportional hazards (Cox) regression models w...  \n",
              "4  In some typical judgments on perspective pictu...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e494003d-9c13-41f0-82aa-896c0abbc984\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>author(s)</th>\n",
              "      <th>affiliation(s)</th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2002</td>\n",
              "      <td>Joe Lappin*, Bart Borghuis**, Duje Tadin*, Mar...</td>\n",
              "      <td>*Vanderbilt Vision Research Center, Vanderbilt...</td>\n",
              "      <td>Spike Timing Variability Limits Motion Discrim...</td>\n",
              "      <td>The visible structure of moving stimulus patte...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2002</td>\n",
              "      <td>Ragnar Steingrimsson</td>\n",
              "      <td>UC- Irvine</td>\n",
              "      <td>Adaptive Techniques for Response Latencies</td>\n",
              "      <td>Using adaptive procedures to estimate selectiv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2002</td>\n",
              "      <td>Keith D. White, John D. Pettigrew</td>\n",
              "      <td>University of Florida; University of Queensland</td>\n",
              "      <td>Dominance times for binocular rivalry and ambi...</td>\n",
              "      <td>Binocular rivalry can be produced by stimulati...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2002</td>\n",
              "      <td>Michael J. Wenger, Christof Schuster, James T....</td>\n",
              "      <td>University of Notre Dame; Indiana University</td>\n",
              "      <td>Testing Capacity Hypotheses: Applying Proporti...</td>\n",
              "      <td>Proportional hazards (Cox) regression models w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2002</td>\n",
              "      <td>Keith K. Niall</td>\n",
              "      <td>Defence R&amp;D Canada, Toronto</td>\n",
              "      <td>Perspicuity without depth: 'mental rotation' a...</td>\n",
              "      <td>In some typical judgments on perspective pictu...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e494003d-9c13-41f0-82aa-896c0abbc984')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e494003d-9c13-41f0-82aa-896c0abbc984 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e494003d-9c13-41f0-82aa-896c0abbc984');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-d673d53c-a6b9-488b-b2e4-469c28e13962\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d673d53c-a6b9-488b-b2e4-469c28e13962')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-d673d53c-a6b9-488b-b2e4-469c28e13962 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 57,\n  \"fields\": [\n    {\n      \"column\": \"year\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"2002\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"author(s)\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 57,\n        \"samples\": [\n          \"Joe Lappin*, Bart Borghuis**, Duje Tadin*, Martin Lankheet**, Wim van de Grind**\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"affiliation(s)\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 39,\n        \"samples\": [\n          \"University of Adelaide\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 57,\n        \"samples\": [\n          \"Spike Timing Variability Limits Motion Discrimination\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"abstract\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 55,\n        \"samples\": [\n          \"We propose a goal-based, constructive choice framework as an alternative to multiplicative models of intertemporal and risky choice. In this framework, making a choice is viewed as finding a solution to a design problem (in which constraints are set by a person's goals) rather than maximizing some utility function. We briefly discuss the activation and adoption of goals in risky and intertemporal choice situations. The framework predicts a dissociation between the effects of uncertainty and the effects of delay that allows for a measurement free test of joint independence of the multiplicative model. People are likely to be more sensitive to uncertainty, but less sensitive to delay, for important, long term goals than for less important, short term goals. We show using multiplicative conjoint measurement that the multiplicative model fails the test of joint independence. The conjoint measurement analysis also suggests an experimental design to directly demonstrate and test the uncertainty and delay effects predicted by the goal- based framework. Two experiments based on this design are reported. In Experiment 1, we manipulate the magnitude of the prospects in intertemporal and risky choices. Using monetary and non-monetary prospects, and two different methods of eliciting choices from subjects, we show that joint independence does not hold. The goal-based framework also predicts conditions in which subjects' patterns of choices observed in Experiment 1 can be changed. We implement these conditions in Experiment 2 and show that the subjects' choices do change in the expected direction.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(f\"/content/drive/MyDrive/math_psych_work/smp{year}_program.csv\", index=False)"
      ],
      "metadata": {
        "id": "gAVGpzJLMVCA"
      },
      "execution_count": 51,
      "outputs": []
    }
  ]
}