{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lizaoh/smp_program_data/blob/main/smp2020_extract_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBXc6uieLC6Y"
      },
      "source": [
        "# Top of Script"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DW0MLlXyhw5G",
        "outputId": "d90cd218-4d51-4e08-f357-dd06c2a8e56d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iwaO2sqpib2d"
      },
      "outputs": [],
      "source": [
        "# Suppresses output from pip installs\n",
        "%%capture\n",
        "\n",
        "!pip install pymupdf\n",
        "!pip install pymupdf-layout\n",
        "!pip install pymupdf4llm\n",
        "!pip install wordfreq\n",
        "!pip install rapidfuzz\n",
        "import glob\n",
        "import os\n",
        "import pathlib\n",
        "import pymupdf\n",
        "import pymupdf.layout\n",
        "import pymupdf4llm\n",
        "import re\n",
        "import regex\n",
        "import pandas as pd\n",
        "import unicodedata\n",
        "import wordfreq\n",
        "from rapidfuzz import process, fuzz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9TqNj0OYhzgb"
      },
      "outputs": [],
      "source": [
        "pdfs_path = '/content/drive/MyDrive/math_psych_work/Conference Programs/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cK6Itu79JGuf"
      },
      "source": [
        "# Functions\n",
        "Created with help from GPT 5.2, but some are my own code just turned into a function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xXzXB83HNC3z"
      },
      "outputs": [],
      "source": [
        "LOCATIONS = [\n",
        "    'United States of America', 'United States', 'Switzerland', 'Japan', 'Bremen',\n",
        "    'Berlin, Germany', 'Heidelberg, Germany', 'Germany', 'Berlin', 'Norway',\n",
        "    'Turkey', 'Belgium', 'Italy', 'Israel', 'New Brunswick, New Jersey',\n",
        "    'Australia', 'The Netherlands', 'USA', 'US', 'Netherlands, The', 'Netherlands',\n",
        "    'United Kingdom', 'Singapore', 'France', 'Dayton OH', 'Dayton', 'India',\n",
        "    'Taiwan, Republic of China', 'Austria', 'Canada', 'Denmark', 'Spain',\n",
        "    'Edmonton', 'Bloomington, Indiana', 'Indiana', 'Russian Federation',\n",
        "    'University Park, Pennsylvania', 'California', 'San Francisco, California',\n",
        "    'Taipei, Taiwan', 'Charlottesville, Virginia', 'New York, New York',\n",
        "    'Toronto, Ontario', 'New Haven, Connecticut', 'Ann Arbor, Michigan', 'Ohio',\n",
        "    'Ottawa, Ontario', 'Houston, Texas', 'UK', 'New Brunswick, Piscataway, NJ',\n",
        "    'Finland', 'Iceland', 'Mexico', 'South Korea'\n",
        "]\n",
        "\n",
        "# compile once\n",
        "LOCATION_RE = re.compile(\n",
        "    r',\\s*(?:' + '|'.join(map(re.escape, LOCATIONS)) + r')\\b',\n",
        "    re.I\n",
        ")\n",
        "\n",
        "def remove_locations(entry: str) -> str:\n",
        "    return LOCATION_RE.sub('', entry).strip()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_authors(line: str) -> list[str]:\n",
        "    line = line.strip()\n",
        "\n",
        "    # Only ICCM posters use \"and\" in the list\n",
        "    if ' and ' in line:\n",
        "      line = line.replace(' and ', ', ')\n",
        "      line = line.replace(',', ';')\n",
        "\n",
        "    authors = []\n",
        "\n",
        "    for part in line.split(';'):\n",
        "        part = part.strip()\n",
        "        if not part:\n",
        "            continue\n",
        "\n",
        "        # Convert \"Last, First Middle\" → \"First Middle Last\"\n",
        "        if ',' in part:\n",
        "            last, first = part.split(',', 1)\n",
        "            authors.append(f\"{first.strip()} {last.strip()}\")\n",
        "        else:\n",
        "            authors.append(part)  # fallback, just in case\n",
        "\n",
        "    return authors"
      ],
      "metadata": {
        "id": "QSvY9U3JSjbE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_labeled_authors(text: str):\n",
        "  # Splits authors on commas outside of the brackets for affiliation labels\n",
        "  authors = re.split(r',\\s*(?![^(]*\\))', text)\n",
        "  out = []\n",
        "\n",
        "  for a in authors:\n",
        "      a = a.strip()\n",
        "      if not a:\n",
        "          continue\n",
        "\n",
        "      # Extracts all numbers\n",
        "      indices = [int(x) for x in re.findall(r'\\d+', a)]\n",
        "\n",
        "      # Cleans author names\n",
        "      # Removes parentheses containing digits (e.g., (1), (2))\n",
        "      name = re.sub(r'\\(\\s*\\d+(?:\\s*,\\s*\\d+)*\\s*\\)', '', a)\n",
        "\n",
        "      # Removes empty parentheses\n",
        "      name = re.sub(r'\\(\\s*\\)', '', name)\n",
        "\n",
        "      # Normalizes whitespace\n",
        "      name = re.sub(r'\\s+', ' ', name).strip()\n",
        "\n",
        "      out.append((name, indices))\n",
        "\n",
        "  return out"
      ],
      "metadata": {
        "id": "PP_pZNUQP6Bl"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "W1pzD77VbUy2"
      },
      "outputs": [],
      "source": [
        "def parse_affiliation_dict(aff_text: str) -> dict[int, str]:\n",
        "    out = {}\n",
        "\n",
        "    affs = re.split(r';\\s', aff_text)\n",
        "    for aff in affs:\n",
        "      num = int(aff[0])\n",
        "      aff_name = aff.split(': ', 1)[1]\n",
        "      out[num] = aff_name\n",
        "\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "R8Aq-wH9W_8r"
      },
      "outputs": [],
      "source": [
        "def make_aff_list(authors, aff_dict):\n",
        "    author_names = []\n",
        "    author_affiliations = []\n",
        "\n",
        "    for name, indices in authors:\n",
        "        author_names.append(name)\n",
        "\n",
        "        affs = [\n",
        "            aff_dict[i]\n",
        "            for i in indices\n",
        "            if i in aff_dict\n",
        "        ]\n",
        "\n",
        "        # join multiple affiliations for the SAME author with \" and \"\n",
        "        author_affiliations.append(\" / \".join(affs))\n",
        "\n",
        "    new_authors = \", \".join(author_names)\n",
        "    new_affiliations = \"; \".join(author_affiliations)\n",
        "\n",
        "    return new_authors, new_affiliations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "CxB8mawESnT_"
      },
      "outputs": [],
      "source": [
        "def remove_page_break_text(text: str) -> str:\n",
        "    if not text:\n",
        "        return text\n",
        "\n",
        "    # Replaces with '\\n\\n' if '##' is after the page number\n",
        "    text = re.sub(r'\\n\\n\\d{1,3} \\n\\n(?=##)', '\\n\\n', text)\n",
        "\n",
        "    # Replaces with '\\n\\n##' if '**' is after\n",
        "    text = re.sub(r'\\n\\n\\d{1,3} \\n\\n(?=\\*\\*)', '\\n\\n## ', text)\n",
        "\n",
        "    # Replaces with nothing for the rest\n",
        "    text = re.sub(r'\\n\\n\\d{1,3} \\n\\n', '', text)\n",
        "\n",
        "    return text.strip()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_picture_text(text: str) -> str:\n",
        "    if not text:\n",
        "        return text\n",
        "\n",
        "    text = re.sub(\n",
        "        r'''\n",
        "        \\n\\n\\*\\*==>\\spicture\\s\\[\\d{2}\\sx\\s\\d{2}\\]\\sintentionally\\somitted\\s<==\\*\\*\\n\\n\n",
        "        ''',\n",
        "        '\\n\\n',\n",
        "        text,\n",
        "        flags=re.VERBOSE\n",
        "    )\n",
        "\n",
        "    text = re.sub(\n",
        "        r'''\n",
        "        \\*\\*-----\\sStart\\sof\\spicture\\stext\\s-----\\*\\*\n",
        "        <br>\\n[A-Z][A-Z]<br>\n",
        "        ''',\n",
        "        '',\n",
        "        text,\n",
        "        flags=re.VERBOSE\n",
        "    )\n",
        "\n",
        "    text = re.sub(\n",
        "        r'''\n",
        "        \\*\\*-----\\sEnd\\sof\\spicture\\stext\\s-----\\*\\*<br>\\n\\n\\n#?#?\n",
        "        ''',\n",
        "        '##',\n",
        "        text,\n",
        "        flags=re.VERBOSE\n",
        "    )\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "OlRvTsrPqbPZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topics = [\n",
        "  \"Group Dynamics\", \"Optimal Experimental Design\", \"Systems and Architectures\",\n",
        "  \"Computational Model-Based Cognitive Neuroscience\", \"Cognitive Neuromodeling\",\n",
        "  \"Theory Development\", \"Learning\", \"Optimality in Choice\", \"Joint Modeling\",\n",
        "  \"Psychometrics\", \"Categorization\", \"Decision Making\", \"Memory\",\n",
        "  \"Memory Research Methods\", \"Metascience\", \"Recognition Memory\", \"Judgment\",\n",
        "  \"Statistics\", \"Reaction Time Analysis\", \"Reaction Time Models\",\n",
        "  \"Applied MathPsych\", \"Axiomatics and Formal Analysis\", \"ICCM Session I\",\n",
        "  \"ICCM Session II\", \"ICCM Session III\", \"ICCM Session IV\", \"ICCM Session V\",\n",
        "  \"CT\", \"CS\", \"ICCM Virtual poster abstracts\", \"MathPsych Virtual poster abstracts\"\n",
        "]\n",
        "\n",
        "def get_title(text):\n",
        "  topic_pattern = \"|\".join(re.escape(t) for t in topics)\n",
        "\n",
        "  pattern = rf\"^\\*\\*(?:{topic_pattern})\\*\\*\"\n",
        "\n",
        "  if re.match(pattern, text):\n",
        "    title_index = 1\n",
        "  else:\n",
        "    title_index = 0\n",
        "\n",
        "  title_line = text.split('\\n\\n')[title_index]\n",
        "  title = re.search(r'\\*\\*(.*?)\\*\\*', title_line).group()\n",
        "\n",
        "  return title.strip('**')"
      ],
      "metadata": {
        "id": "-Hkk-tVFFKkD"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "aq4f3JE9IgHD"
      },
      "outputs": [],
      "source": [
        "def clean_text(text, fix_whitespace=False):\n",
        "    if not text:\n",
        "        return text\n",
        "\n",
        "    text = fix_ligatures(text)\n",
        "    text = remove_page_break_text(text)\n",
        "    text = remove_picture_text(text)\n",
        "\n",
        "    # Get rid of breaks inbetween newlines\n",
        "    text = re.sub(r'\\n*<br>\\n*', '\\n\\n', text)\n",
        "\n",
        "    text = text.replace(\"\\'\", \"'\")\n",
        "\n",
        "    if fix_whitespace:\n",
        "      text = re.sub(r'\\n{3,}', '\\n\\n', text)\n",
        "\n",
        "    text = text.strip()\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "WLDsGBzsFnSz"
      },
      "outputs": [],
      "source": [
        "LIGATURE_MAP = {\n",
        "    \"ﬁ\": \"fi\", \"ﬂ\": \"fl\", \"ﬃ\": \"ffi\", \"ﬄ\": \"ffl\", \"ﬀ\": \"ff\", \"ﬅ\": \"ft\", \"ﬆ\": \"st\",\n",
        "    \"Æ\": \"ffi\", \"¨u\": \"ü\", \"¨a\": \"ä\", \"´e\": \"é\", \"`e\": \"è\", \"`a\": \"à\", \"¨o\": \"ö\",\n",
        "    \"˚a\": \"å\", \"c¸\": \"ç\", '“': '\"', '”': '\"', \"’\": \"'\", '˜n': 'ñ', 'ˇs': 'š',\n",
        "    \"âĂŸ\": \"'\", \"``\": '\"', \"↵\": \"ff\", \"✏\": \"ffl\"\n",
        "}\n",
        "\n",
        "def fix_ligatures(text):\n",
        "    # Replace known ligatures\n",
        "    for bad, good in LIGATURE_MAP.items():\n",
        "        text = text.replace(bad, good)\n",
        "\n",
        "    # Replace any private-use ligature (common in PDFs)\n",
        "    cleaned_chars = []\n",
        "    for ch in text:\n",
        "        name = unicodedata.name(ch, \"\")\n",
        "        if \"LIGATURE\" in name.upper():\n",
        "            # Try to break it apart: remove spaces and lowercase\n",
        "            base = name.split(\"LIGATURE\")[-1]\n",
        "            base = base.replace(\" \", \"\").lower()\n",
        "            cleaned_chars.append(base)\n",
        "        else:\n",
        "            cleaned_chars.append(ch)\n",
        "\n",
        "    return \"\".join(cleaned_chars)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def rehyphenate_words(text, words_to_hyphenate):\n",
        "    for word, hyphenated_word in words_to_hyphenate:\n",
        "        text = text.replace(word, hyphenated_word)\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "hNTyPQzW06Ko"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checks if valid word using Zipf frequency\n",
        "def is_probably_valid(word, threshold=2.5):\n",
        "    return wordfreq.zipf_frequency(word, \"en\") > threshold  # smaller number cuts off\n",
        "                                                            # more words, bigger is\n",
        "                                                            # more lenient"
      ],
      "metadata": {
        "id": "BZn089Q_06l2"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzyoCbvJK6js"
      },
      "source": [
        "# Program\n",
        "\n",
        "196 entries total (18 symposium talks, 60 concerted sessions, 60 talks, and 58 posters)\n",
        "\n",
        "I'm not exactly sure what a concerted session is but I think because this was the first virtual one, maybe it's synchronous talks?\n",
        "\n",
        "They're using justified text again, so will have to check the hyphenated words at line breaks.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "-iaeTkOjqA3-"
      },
      "outputs": [],
      "source": [
        "year = '2020'\n",
        "file_path = pdfs_path + f'Smp{year}.pdf'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NY0NZXAh696-"
      },
      "source": [
        "## Grab text from the pdf\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "program = pymupdf.open(file_path)   # original PDF\n",
        "program_text = pymupdf4llm.to_markdown(program)"
      ],
      "metadata": {
        "id": "UC8tgNIEt3yJ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "program_text[61_000:63_000]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "bjapdcOFt7BZ",
        "outputId": "07bb1257-985c-422a-9e7d-ede99f48456d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'**|Business meeting||\\n\\n\\n\\n39 \\n\\n40 \\n\\n## **MathPsych Virtual talk abstracts** \\n\\n## **Group Dynamics** \\n\\n## **Model-based wisdom of the crowd for sequential decisions** \\n\\n## **CS** \\n\\n_**Lee, Michael David; Coon, Jeff; Thomas, Bobby; Westfall, Holly Anne**_ \\n\\n## University of California, Irvine \\n\\nWe use cognitive models to apply the wisdom of the crowd to three sequential decision making problems: bandit problems, optimal stopping problems, and the Balloon Analogue Risk Task (BART). In each of these problems, people make a sequence of choices under uncertainty, with individual differences in decision making that depend on different attitudes toward risk. Each of the problems also has a known optimal decision-making strategy. Standard methods for the wisdom of the crowd, based on taking the modal behavior, are generally not applicable to these problems, because of their sequential nature. For example, the state-space of a bandit problem can be so large that, even for a large crowd of people, there will be game states that no individual encountered, and so there is no behavior to aggregate. We solve this problem using cognitive models, and inferring individual-level parameter values that predict what each individual would do for each sequential decision. The mode of these model-based predicted decisions then defines a crowd decision whose performance can be compared to individual and optimal performance. \\n\\n## **Public policy recommendation by optimizing an unknown social welfare function** \\n\\n## **CS** \\n\\n_**Davis, Alex (1); Guo, Niles (1); Mauter, Meagan (2)**_ \\n\\n1: Carnegie Mellon University; 2: Stanford University \\n\\nA classical utilitarian perspective on public decision-making is that the public should choose an alternative that maximizes some function over the utilities of individuals, called a social welfare function. If the utility function for each decision-maker is cardinal and comparable with other decision-makers, then there are many valid social welfare functions.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Find words to re-hyphenate"
      ],
      "metadata": {
        "id": "kLz8RAOqBM9Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pattern = re.compile(r'([A-Za-z]+)-\\n\\s*([A-Za-z]+)')\n",
        "possible_hyphenated_words = []\n",
        "\n",
        "counter = 0\n",
        "for p, page in enumerate(program[42:]):  # these are the pages with abstracts only\n",
        "  text = fix_ligatures(page.get_text('text'))\n",
        "  matches = pattern.findall(text)\n",
        "\n",
        "  for left, right in matches:\n",
        "    word = f\"{left}{right}\"\n",
        "    hyphenated_word = f\"{left}-{right}\"\n",
        "    if not is_probably_valid(word, threshold=2.8):\n",
        "      possible_hyphenated_words.append([word, hyphenated_word])\n",
        "\n",
        "      print(f\"{counter:>3}: Page {p+42:<3} {hyphenated_word:<30} {word}\")\n",
        "      counter += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMdLe69U7GMm",
        "outputId": "6ddef07d-95f5-4616-f551-a29993597dd1"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  0: Page 43  statisti-cians                 statisticians\n",
            "  1: Page 44  utility-maximizing             utilitymaximizing\n",
            "  2: Page 45  decision-making                decisionmaking\n",
            "  3: Page 46  and-mortar                     andmortar\n",
            "  4: Page 46  com-putationally               computationally\n",
            "  5: Page 48  confus-ability                 confusability\n",
            "  6: Page 51  likelihood-free                likelihoodfree\n",
            "  7: Page 51  brain-behavior                 brainbehavior\n",
            "  8: Page 53  decision-making                decisionmaking\n",
            "  9: Page 61  Pavlo-vian                     Pavlovian\n",
            " 10: Page 63  memory-driven                  memorydriven\n",
            " 11: Page 64  non-independent                nonindependent\n",
            " 12: Page 71  intercorre-lation              intercorrelation\n",
            " 13: Page 72  Wisconsin-Madison              WisconsinMadison\n",
            " 14: Page 72  pre-suppose                    presuppose\n",
            " 15: Page 75  template-matching              templatematching\n",
            " 16: Page 75  integration-to                 integrationto\n",
            " 17: Page 78  Eigen-Net                      EigenNet\n",
            " 18: Page 78  bi-grams                       bigrams\n",
            " 19: Page 79  of-forgetting                  offorgetting\n",
            " 20: Page 80  information-theoretic          informationtheoretic\n",
            " 21: Page 83  tractabil-ity                  tractability\n",
            " 22: Page 83  dis-sociates                   dissociates\n",
            " 23: Page 85  participant-level              participantlevel\n",
            " 24: Page 87  non-target                     nontarget\n",
            " 25: Page 88  ac-cumulators                  accumulators\n",
            " 26: Page 88  drift-diffusion                driftdiffusion\n",
            " 27: Page 88  higher-weighted                higherweighted\n",
            " 28: Page 88  mech-anistic                   mechanistic\n",
            " 29: Page 89  high-value                     highvalue\n",
            " 30: Page 90  mod-eler                       modeler\n",
            " 31: Page 90  model-stimulus                 modelstimulus\n",
            " 32: Page 95  non-decision                   nondecision\n",
            " 33: Page 97  multiple-alternative           multiplealternative\n",
            " 34: Page 97  Thursto-nian                   Thurstonian\n",
            " 35: Page 98  multiple-choice                multiplechoice\n",
            " 36: Page 101 unsys-tematic                  unsystematic\n",
            " 37: Page 102 Agos-tini                      Agostini\n",
            " 38: Page 103 well-known                     wellknown\n",
            " 39: Page 104 stochasti-cally                stochastically\n",
            " 40: Page 105 selec-tivity                   selectivity\n",
            " 41: Page 105 separabil-ity                  separability\n",
            " 42: Page 105 se-lectivity                   selectivity\n",
            " 43: Page 107 Paul-Christian                 PaulChristian\n",
            " 44: Page 107 data-generating                datagenerating\n",
            " 45: Page 110 paired-associates              pairedassociates\n",
            " 46: Page 112 rapid-action                   rapidaction\n",
            " 47: Page 112 supra-second                   suprasecond\n",
            " 48: Page 114 com-putationally               computationally\n",
            " 49: Page 115 infer-ential                   inferential\n",
            " 50: Page 118 cross-linguistic               crosslinguistic\n",
            " 51: Page 118 cross-linguistic               crosslinguistic\n",
            " 52: Page 119 conver-gent                    convergent\n",
            " 53: Page 123 discrim-inability              discriminability\n",
            " 54: Page 125 approx-imations                approximations\n",
            " 55: Page 128 nonpara-metric                 nonparametric\n",
            " 56: Page 128 model-based                    modelbased\n",
            " 57: Page 132 multi-dimensional              multidimensional\n",
            " 58: Page 137 full-face                      fullface\n",
            " 59: Page 138 hypothesis-driven              hypothesisdriven\n",
            " 60: Page 139 activation-related             activationrelated\n",
            " 61: Page 140 user-friendly                  userfriendly\n",
            " 62: Page 141 computation-ally               computationally\n",
            " 63: Page 141 articula-tory                  articulatory\n",
            " 64: Page 145 reimple-mented                 reimplemented\n",
            " 65: Page 146 perceptual-motor               perceptualmotor\n",
            " 66: Page 147 dimen-sionality                dimensionality\n",
            " 67: Page 147 multiple-choice                multiplechoice\n",
            " 68: Page 148 open-loop                      openloop\n",
            " 69: Page 148 stabilisa-tion                 stabilisation\n",
            " 70: Page 151 dopamin-ergic                  dopaminergic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pick indices of words to rehyphenate\n",
        "indices = [(1,3), (6,7), 10, 13, (15,20), 23, 24, 26, 27, 29, (31,33), 35, 38, (43,46), 50, (56,61), 65, 68]\n",
        "words_to_hyphenate = [\n",
        "    possible_hyphenated_words[i]\n",
        "    for item in indices\n",
        "    for i in ([item] if isinstance(item, int) else range(*item))\n",
        "]"
      ],
      "metadata": {
        "id": "9SiZxnFeRsPA"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word, hyphenated_word in words_to_hyphenate:\n",
        "  print(f'{word:<30} {hyphenated_word}')"
      ],
      "metadata": {
        "id": "o7piQmxhVV4-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1b783cd-8368-4c7c-d64f-f3b9616f667b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "utilitymaximizing              utility-maximizing\n",
            "decisionmaking                 decision-making\n",
            "likelihoodfree                 likelihood-free\n",
            "memorydriven                   memory-driven\n",
            "WisconsinMadison               Wisconsin-Madison\n",
            "templatematching               template-matching\n",
            "integrationto                  integration-to\n",
            "EigenNet                       Eigen-Net\n",
            "bigrams                        bi-grams\n",
            "offorgetting                   of-forgetting\n",
            "participantlevel               participant-level\n",
            "nontarget                      non-target\n",
            "driftdiffusion                 drift-diffusion\n",
            "higherweighted                 higher-weighted\n",
            "highvalue                      high-value\n",
            "modelstimulus                  model-stimulus\n",
            "nondecision                    non-decision\n",
            "multiplechoice                 multiple-choice\n",
            "wellknown                      well-known\n",
            "PaulChristian                  Paul-Christian\n",
            "datagenerating                 data-generating\n",
            "pairedassociates               paired-associates\n",
            "crosslinguistic                cross-linguistic\n",
            "modelbased                     model-based\n",
            "multidimensional               multi-dimensional\n",
            "fullface                       full-face\n",
            "hypothesisdriven               hypothesis-driven\n",
            "activationrelated              activation-related\n",
            "perceptualmotor                perceptual-motor\n",
            "openloop                       open-loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split up into talk entries"
      ],
      "metadata": {
        "id": "ROGXQjnEA01_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "program_abstracts_start = program_text.split('\\n\\n## **Group Dynamics** \\n\\n## ')[1]\n",
        "\n",
        "# Rehyphenate words that need hyphen at line breaks\n",
        "program_abstracts_start = rehyphenate_words(program_abstracts_start, words_to_hyphenate)\n",
        "\n",
        "# Adds period to the end of this abstract bc it's missing one\n",
        "program_abstracts_start = program_abstracts_start.replace('spatio-temporal dynamics',\n",
        "                                                          'spatio-temporal dynamics.')\n",
        "# Gets rid of page break and pictured omitted text\n",
        "program_abstracts_start = clean_text(program_abstracts_start, fix_whitespace=True)\n",
        "\n",
        "# Splits each abstract entry\n",
        "abstract_entries = program_abstracts_start.split('. \\n\\n## ')[:-3]\n",
        "abstract_entries = [entry for entry in abstract_entries if len(entry) > 300]"
      ],
      "metadata": {
        "id": "9e6YaskncXBU"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "abstract_entries[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykuse4YyklDb",
        "outputId": "7b27a6f9-c1b5-4901-cedd-b204e5aba0dd"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['**Model-based wisdom of the crowd for sequential decisions** \\n\\n## **CS** \\n\\n_**Lee, Michael David; Coon, Jeff; Thomas, Bobby; Westfall, Holly Anne**_ \\n\\n## University of California, Irvine \\n\\nWe use cognitive models to apply the wisdom of the crowd to three sequential decision making problems: bandit problems, optimal stopping problems, and the Balloon Analogue Risk Task (BART). In each of these problems, people make a sequence of choices under uncertainty, with individual differences in decision making that depend on different attitudes toward risk. Each of the problems also has a known optimal decision-making strategy. Standard methods for the wisdom of the crowd, based on taking the modal behavior, are generally not applicable to these problems, because of their sequential nature. For example, the state-space of a bandit problem can be so large that, even for a large crowd of people, there will be game states that no individual encountered, and so there is no behavior to aggregate. We solve this problem using cognitive models, and inferring individual-level parameter values that predict what each individual would do for each sequential decision. The mode of these model-based predicted decisions then defines a crowd decision whose performance can be compared to individual and optimal performance',\n",
              " \"**Public policy recommendation by optimizing an unknown social welfare function** \\n\\n## **CS** \\n\\n_**Davis, Alex (1); Guo, Niles (1); Mauter, Meagan (2)**_ \\n\\n1: Carnegie Mellon University; 2: Stanford University \\n\\nA classical utilitarian perspective on public decision-making is that the public should choose an alternative that maximizes some function over the utilities of individuals, called a social welfare function. If the utility function for each decision-maker is cardinal and comparable with other decision-makers, then there are many valid social welfare functions. We examine the problem of finding a social welfare function that implicitly best fits society's values, where we assume that a group's decision problem is the same as maximizing an unknown social welfare function implicitly held by the group. While there is a wealth of literature on possible social welfare functional forms based on different assumptions about the preferences of individuals, we propose a new empirical approach that approximates a group's social welfare function based on both individual preferences and group voting behavior. We test the approach's ability to promote compromise on climate-related energy policy among Pittsburgh residents who are plan to vote in the 2020 Democratic Primary. Our three-stage research design first elicits individual preferences, then uses a mean-variance algorithm to approximate a welfare function that fits group voting behavior, then finally makes a recommendation for the group based on that function. In addition to testing whether a group's social welfare function can be learned from individual choices, this study provides a roadmap for solving group recommendation problems more broadly\"]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvO659m7ufLG"
      },
      "source": [
        "## Sort authors, affiliations, title, and abstract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "rYSctzOMshAh"
      },
      "outputs": [],
      "source": [
        "parsed_entries = []\n",
        "\n",
        "for e, entry in enumerate(abstract_entries):\n",
        "  # The easiest place to split is between authors and affiliations\n",
        "  title_auth, affs_abstract = re.split(r'(?<=\\*\\*_)\\s\\n?\\n?#?#?', entry, maxsplit=1)\n",
        "\n",
        "  title = get_title(title_auth)\n",
        "\n",
        "  # Authors surrounded by _**\n",
        "  authors = re.search(r'_\\*\\*(.*?)\\*\\*_', title_auth).group()\n",
        "  authors = parse_authors(authors.strip('_').strip('**'))\n",
        "  authors = ', '. join(authors)\n",
        "\n",
        "  if '**_' in affs_abstract:\n",
        "    affs_abstract = re.split(r'\\*\\*_\\s\\n*#?#?', affs_abstract, maxsplit=1)[1].strip()\n",
        "\n",
        "  affiliations, abstract = affs_abstract.split('\\n\\n', 1)\n",
        "  affiliations = remove_locations(affiliations.strip())\n",
        "  abstract = abstract.strip()\n",
        "\n",
        "  # Fixes authors and affiliations if using numbered labels\n",
        "  if re.search(r'^1', affiliations):\n",
        "    author_label_tuples = parse_labeled_authors(authors)\n",
        "    aff_dict = parse_affiliation_dict(affiliations)\n",
        "    authors, affiliations = make_aff_list(author_label_tuples, aff_dict)\n",
        "\n",
        "  parsed_entries.append({\n",
        "      'year': year,\n",
        "      'author(s)': authors,\n",
        "      'affiliation(s)': affiliations,\n",
        "      'title': title,\n",
        "      'type': '',\n",
        "      'abstract': clean_text(abstract) + '.'\n",
        "  })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Q6ocLO1sha_",
        "outputId": "948648ba-6852-4007-f232-3148fdd9c88a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'year': '2020',\n",
              "  'author(s)': 'Michael David Lee, Jeff Coon, Bobby Thomas, Holly Anne Westfall',\n",
              "  'affiliation(s)': 'University of California, Irvine',\n",
              "  'title': 'Model-based wisdom of the crowd for sequential decisions',\n",
              "  'type': '',\n",
              "  'abstract': 'We use cognitive models to apply the wisdom of the crowd to three sequential decision making problems: bandit problems, optimal stopping problems, and the Balloon Analogue Risk Task (BART). In each of these problems, people make a sequence of choices under uncertainty, with individual differences in decision making that depend on different attitudes toward risk. Each of the problems also has a known optimal decision-making strategy. Standard methods for the wisdom of the crowd, based on taking the modal behavior, are generally not applicable to these problems, because of their sequential nature. For example, the state-space of a bandit problem can be so large that, even for a large crowd of people, there will be game states that no individual encountered, and so there is no behavior to aggregate. We solve this problem using cognitive models, and inferring individual-level parameter values that predict what each individual would do for each sequential decision. The mode of these model-based predicted decisions then defines a crowd decision whose performance can be compared to individual and optimal performance.'},\n",
              " {'year': '2020',\n",
              "  'author(s)': 'Alex Davis, Niles Guo, Meagan Mauter',\n",
              "  'affiliation(s)': 'Carnegie Mellon University; Carnegie Mellon University; Stanford University',\n",
              "  'title': 'Public policy recommendation by optimizing an unknown social welfare function',\n",
              "  'type': '',\n",
              "  'abstract': \"A classical utilitarian perspective on public decision-making is that the public should choose an alternative that maximizes some function over the utilities of individuals, called a social welfare function. If the utility function for each decision-maker is cardinal and comparable with other decision-makers, then there are many valid social welfare functions. We examine the problem of finding a social welfare function that implicitly best fits society's values, where we assume that a group's decision problem is the same as maximizing an unknown social welfare function implicitly held by the group. While there is a wealth of literature on possible social welfare functional forms based on different assumptions about the preferences of individuals, we propose a new empirical approach that approximates a group's social welfare function based on both individual preferences and group voting behavior. We test the approach's ability to promote compromise on climate-related energy policy among Pittsburgh residents who are plan to vote in the 2020 Democratic Primary. Our three-stage research design first elicits individual preferences, then uses a mean-variance algorithm to approximate a welfare function that fits group voting behavior, then finally makes a recommendation for the group based on that function. In addition to testing whether a group's social welfare function can be learned from individual choices, this study provides a roadmap for solving group recommendation problems more broadly.\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "parsed_entries[:2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKNl4pKw44lP"
      },
      "source": [
        "# Create df and convert to csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "5IEUDPyalsYH"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(parsed_entries, columns=[\"year\", \"author(s)\", \"affiliation(s)\", \"title\", \"type\", \"abstract\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "AZRpkwpEJ6ut",
        "outputId": "bc0bedcd-5dcd-471e-958c-94db58eae5d4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   year                                          author(s)  \\\n",
              "0  2020  Michael David Lee, Jeff Coon, Bobby Thomas, Ho...   \n",
              "1  2020               Alex Davis, Niles Guo, Meagan Mauter   \n",
              "2  2020  Murray Bennett, Rachel Mullard, Scott Brown, A...   \n",
              "3  2020                          Keith Ransom, Amy Perfors   \n",
              "4  2020                         Jay I. Myung, Mark A. Pitt   \n",
              "\n",
              "                                      affiliation(s)  \\\n",
              "0                   University of California, Irvine   \n",
              "1  Carnegie Mellon University; Carnegie Mellon Un...   \n",
              "2                            University of Newcastle   \n",
              "3                            University of Melbourne   \n",
              "4                              Ohio State University   \n",
              "\n",
              "                                               title type  \\\n",
              "0  Model-based wisdom of the crowd for sequential...        \n",
              "1  Public policy recommendation by optimizing an ...        \n",
              "2  An Iterated Prospect Theory Model for the Dutc...        \n",
              "3  The polarising effect of epistemic vigilance i...        \n",
              "4     An Introduction to Optimal Experimental Design        \n",
              "\n",
              "                                            abstract  \n",
              "0  We use cognitive models to apply the wisdom of...  \n",
              "1  A classical utilitarian perspective on public ...  \n",
              "2  Dutch auctions are used in many industries. Go...  \n",
              "3  While seeing may be believing for reasoners wi...  \n",
              "4  Progress in science depends on well-designed e...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2284482c-5a5d-48f2-8778-161c3bb9921a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>author(s)</th>\n",
              "      <th>affiliation(s)</th>\n",
              "      <th>title</th>\n",
              "      <th>type</th>\n",
              "      <th>abstract</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020</td>\n",
              "      <td>Michael David Lee, Jeff Coon, Bobby Thomas, Ho...</td>\n",
              "      <td>University of California, Irvine</td>\n",
              "      <td>Model-based wisdom of the crowd for sequential...</td>\n",
              "      <td></td>\n",
              "      <td>We use cognitive models to apply the wisdom of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020</td>\n",
              "      <td>Alex Davis, Niles Guo, Meagan Mauter</td>\n",
              "      <td>Carnegie Mellon University; Carnegie Mellon Un...</td>\n",
              "      <td>Public policy recommendation by optimizing an ...</td>\n",
              "      <td></td>\n",
              "      <td>A classical utilitarian perspective on public ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020</td>\n",
              "      <td>Murray Bennett, Rachel Mullard, Scott Brown, A...</td>\n",
              "      <td>University of Newcastle</td>\n",
              "      <td>An Iterated Prospect Theory Model for the Dutc...</td>\n",
              "      <td></td>\n",
              "      <td>Dutch auctions are used in many industries. Go...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020</td>\n",
              "      <td>Keith Ransom, Amy Perfors</td>\n",
              "      <td>University of Melbourne</td>\n",
              "      <td>The polarising effect of epistemic vigilance i...</td>\n",
              "      <td></td>\n",
              "      <td>While seeing may be believing for reasoners wi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020</td>\n",
              "      <td>Jay I. Myung, Mark A. Pitt</td>\n",
              "      <td>Ohio State University</td>\n",
              "      <td>An Introduction to Optimal Experimental Design</td>\n",
              "      <td></td>\n",
              "      <td>Progress in science depends on well-designed e...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2284482c-5a5d-48f2-8778-161c3bb9921a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2284482c-5a5d-48f2-8778-161c3bb9921a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2284482c-5a5d-48f2-8778-161c3bb9921a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 197,\n  \"fields\": [\n    {\n      \"column\": \"year\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"2020\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"author(s)\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 193,\n        \"samples\": [\n          \"Mark Steyvers, Bob Schafer\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"affiliation(s)\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 149,\n        \"samples\": [\n          \"University of Copenhagen\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 195,\n        \"samples\": [\n          \"Price discounts vs. awarding points \\u2013 Verification of sales promotion effect in Japanese supermarkets\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"type\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"abstract\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 196,\n        \"samples\": [\n          \"A frequent shoppers program is a sales promotion strategy used by retailers worldwide. Awarding points can be said to be similar to price discounts in the sense that a return for the amount of money. However, there are disadvantages to awarding points such as restriction of use, expiration date, and use after the next time. Price discount doesn't have this demerits. From a rational perspective, consumers should be more likely to prefer discounts than points. Which has the higher perceived value between price discounts and equivalent amount points? Regarding this, Nakagawa (2015) showed that the relationship between the perceived value of awarding points and price discounts is switched depending on the amount of purchase. This phenomenon can be explained by mental accounting theory (Thaler, 1985) and magnitude effect. Mental accounting theory is based on the value func- tion of Prospect theory, and when the purchase amount is small, awarding points have higher perceived value than price discounts. Magnitude effect is an effect in which decision making and behavior change depending on the amount of money. When the Purchase amount is large, price discounts have higher perceived value than awarding points. Therefore, we investigated how the perceived value of price discounts and awarding points in a supermarket with changes in the purchase price. This study aims to detect the amount of money where switching subjects preference of price discounts and awarding points by fitting linear or non-linear regression models. As a result, it is possible to consider which sales promotion is effective for each amount.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "65YB5d8WESQZ"
      },
      "outputs": [],
      "source": [
        "df.to_csv(f\"/content/drive/MyDrive/math_psych_work/csv/smp{year}_program.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPJmZnzNrngw/C0DkmT8wa7",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}